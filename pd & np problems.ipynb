{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "986449a8",
   "metadata": {},
   "source": [
    "# Monthly Transactions II\n",
    " \n",
    "Table: Transactions\n",
    "\n",
    "    +----------------+---------+\n",
    "    | Column Name    | Type    |\n",
    "    +----------------+---------+\n",
    "    | id             | int     |\n",
    "    | country        | varchar |\n",
    "    | state          | enum    |\n",
    "    | amount         | int     |\n",
    "    | trans_date     | date    |\n",
    "    +----------------+---------+\n",
    "    id is the column of unique values of this table.\n",
    "    The table has information about incoming transactions.\n",
    "    The state column is an ENUM (category) of type [\"approved\", \"declined\"].\n",
    "Table: Chargebacks\n",
    "\n",
    "    +----------------+---------+\n",
    "    | Column Name    | Type    |\n",
    "    +----------------+---------+\n",
    "    | trans_id       | int     |\n",
    "    | trans_date     | date    |\n",
    "    +----------------+---------+\n",
    "    Chargebacks contains basic information regarding incoming chargebacks from some transactions placed in Transactions table.\n",
    "    trans_id is a foreign key (reference column) to the id column of Transactions table.\n",
    "    Each chargeback corresponds to a transaction made previously even if they were not approved.\n",
    "\n",
    "\n",
    "    Write a solution to find for each month and country: the number of approved transactions and their total amount, the number of chargebacks, and their total amount.\n",
    "\n",
    "    Note: In your solution, given the month and country, ignore rows with all zeros.\n",
    "\n",
    "    Return the result table in any order.\n",
    "\n",
    "    The result format is in the following example.\n",
    "\n",
    " \n",
    "\n",
    "Example 1:\n",
    "\n",
    "Input: \n",
    "Transactions table:\n",
    "\n",
    "    +-----+---------+----------+--------+------------+\n",
    "    | id  | country | state    | amount | trans_date |\n",
    "    +-----+---------+----------+--------+------------+\n",
    "    | 101 | US      | approved | 1000   | 2019-05-18 |\n",
    "    | 102 | US      | declined | 2000   | 2019-05-19 |\n",
    "    | 103 | US      | approved | 3000   | 2019-06-10 |\n",
    "    | 104 | US      | declined | 4000   | 2019-06-13 |\n",
    "    | 105 | US      | approved | 5000   | 2019-06-15 |\n",
    "    +-----+---------+----------+--------+------------+\n",
    "Chargebacks table:\n",
    "\n",
    "    +----------+------------+\n",
    "    | trans_id | trans_date |\n",
    "    +----------+------------+\n",
    "    | 102      | 2019-05-29 |\n",
    "    | 101      | 2019-06-30 |\n",
    "    | 105      | 2019-09-18 |\n",
    "    +----------+------------+\n",
    "Output: \n",
    "\n",
    "    +---------+---------+----------------+-----------------+------------------+-------------------+\n",
    "    | month   | country | approved_count | approved_amount | chargeback_count | chargeback_amount |\n",
    "    +---------+---------+----------------+-----------------+------------------+-------------------+\n",
    "    | 2019-05 | US      | 1              | 1000            | 1                | 2000              |\n",
    "    | 2019-06 | US      | 2              | 8000            | 1                | 1000              |\n",
    "    | 2019-09 | US      | 0              | 0               | 1                | 5000              |\n",
    "    +---------+---------+----------------+-----------------+------------------+-------------------+\n",
    " \n",
    "Initial Ideas\n",
    "\n",
    "    The goal of the monthly_transactions function is to process two data tables: one for transactions and another for chargebacks. The function aims to summarize the number of approved transactions and chargebacks by month and country. The output should reflect counts and amounts for both approved transactions and chargebacks, allowing for an effective comparison.\n",
    "\n",
    "Steps\n",
    "\n",
    "    Data Preparation: Convert the transaction dates to a consistent format representing year and month (YYYY-MM).\n",
    "    Filtering Approved Transactions: Keep only the rows where transactions have an approved status.\n",
    "    Aggregation of Approved Transactions: Group by month and country, counting the number of approved transactions and summing their amounts.\n",
    "    Processing Chargebacks: Merge chargebacks with transactions to include relevant transaction details, and group by month and country to aggregate chargeback data.\n",
    "    Combining Results: Merge the summary of approved transactions with the chargeback summary, filling any missing values with zeros.\n",
    "    Formatting the Output: Ensure the output month format is correct and return the final DataFrame.    \n",
    "    \n",
    "Edge Cases\n",
    "\n",
    "    No Transactions: If the transactions DataFrame is empty, the output should only contain chargeback information if available.\n",
    "    No Chargebacks: If the chargebacks DataFrame is empty, the output should reflect only approved transactions with chargeback counts and amounts set to zero.\n",
    "    Same Month for Multiple Transactions: Ensure that the aggregation works correctly when multiple transactions or chargebacks occur in the same month.\n",
    "    \n",
    "Complexity Analysis\n",
    "\n",
    "    Time Complexity: The function primarily involves filtering and aggregating DataFrames, resulting in a complexity of O(n log n) due to the grouping and aggregation operations, where n is the number of transactions and chargebacks.\n",
    "    Space Complexity: The space complexity is O(m + k), where m is the number of unique months for transactions and chargebacks, and k is the number of countries.\n",
    "    \n",
    "Follow-Up Questions and Answers\n",
    "Q: What would happen if there are duplicate transactions?\n",
    "\n",
    "    A: The function assumes that transactions are unique by id. Duplicate entries could skew the results, so it’s advisable to handle duplicates before processing.\n",
    "Q: How would you modify the function to handle multiple countries?\n",
    "\n",
    "    A: The function already supports multiple countries through its grouping operations. Additional countries would be naturally included in the aggregation.\n",
    "Q: How can we extend this function to include a comparison with previous months?\n",
    "\n",
    "    A: We could add additional logic to calculate differences between months by storing the previous month’s totals in a separate DataFrame and then performing a join or calculation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be387a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def monthly_transactions(transactions: pd.DataFrame, chargebacks: pd.DataFrame) -> pd.DataFrame:\n",
    "    transactions['trans_date'] = pd.to_datetime(transactions['trans_date'])\n",
    "    chargebacks['trans_date'] = pd.to_datetime(chargebacks['trans_date'])\n",
    "\n",
    "    # Step 1: Format transaction dates to month format\n",
    "    transactions['trans_date'] = transactions['trans_date'].dt.strftime('%y-%m')\n",
    "    \n",
    "    # Step 2: Merge chargebacks with transactions\n",
    "    chargebacks = chargebacks.merge(transactions, left_on='trans_id', right_on='id', how='inner')[['trans_id','trans_date','country','amount']]\n",
    "\n",
    "    # Step 3: Filter approved transactions\n",
    "    transactions = transactions[transactions['state'] == 'approved']\n",
    "    \n",
    "    # Step 4: Group approved transactions\n",
    "    result = transactions.groupby(['trans_date', 'country']).agg(\n",
    "        approved_count=('state', 'count'),\n",
    "        approved_amount=('amount', 'sum')\n",
    "    ).reset_index().rename(columns={'trans_date': 'month'})\n",
    "\n",
    "    # Step 5: Process chargebacks\n",
    "    chargebacks['month'] = chargebacks['trans_date'].dt.strftime('%y-%m')\n",
    "    chargebacks = chargebacks.groupby(['month', 'country']).agg(\n",
    "        chargeback_count=('trans_id', 'count'),\n",
    "        chargeback_amount=('amount', 'sum')\n",
    "    ).reset_index()\n",
    "    \n",
    "    # Step 6: Combine results\n",
    "    combine_df = result.merge(chargebacks, on=['month', 'country'], how='outer').fillna(0)\n",
    "    \n",
    "    # Formatting month\n",
    "    combine_df['month'] = '20' + combine_df['month']\n",
    "    \n",
    "    return combine_df\n",
    "\n",
    "# Example input data\n",
    "transactions_data = {\n",
    "    'id': [101, 102, 103, 104, 105],\n",
    "    'country': ['US', 'US', 'US', 'US', 'US'],\n",
    "    'state': ['approved', 'declined', 'approved', 'declined', 'approved'],\n",
    "    'amount': [1000, 2000, 3000, 4000, 5000],\n",
    "    'trans_date': ['2019-05-18', '2019-05-19', '2019-06-10', '2019-06-13', '2019-06-15']\n",
    "}\n",
    "\n",
    "chargebacks_data = {\n",
    "    'trans_id': [102, 101, 105],\n",
    "    'trans_date': ['2019-05-29', '2019-06-30', '2019-09-18']\n",
    "}\n",
    "\n",
    "# Create DataFrames\n",
    "transactions_df = pd.DataFrame(transactions_data)\n",
    "chargebacks_df = pd.DataFrame(chargebacks_data)\n",
    "\n",
    "# Get monthly transactions\n",
    "result_df = monthly_transactions(transactions_df, chargebacks_df)\n",
    "print(result_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1352e932",
   "metadata": {},
   "source": [
    "# Game Play Analysis III\n",
    " \n",
    "Table: Activity\n",
    "\n",
    "    +--------------+---------+\n",
    "    | Column Name  | Type    |\n",
    "    +--------------+---------+\n",
    "    | player_id    | int     |\n",
    "    | device_id    | int     |\n",
    "    | event_date   | date    |\n",
    "    | games_played | int     |\n",
    "    +--------------+---------+\n",
    "    (player_id, event_date) is the primary key (column with unique values) of this table.\n",
    "    This table shows the activity of players of some games.\n",
    "    Each row is a record of a player who logged in and played a number of games (possibly 0) before logging out on someday using some device.\n",
    "\n",
    "\n",
    "    Write a solution to report for each player and date, how many games played so far by the player. That is, the total number of games played by the player until that date. Check the example for clarity.\n",
    "\n",
    "    Return the result table in any order.\n",
    "\n",
    "    The result format is in the following example.\n",
    "\n",
    " \n",
    "\n",
    "Example 1:\n",
    "\n",
    "Input: \n",
    "Activity table:\n",
    "\n",
    "    +-----------+-----------+------------+--------------+\n",
    "    | player_id | device_id | event_date | games_played |\n",
    "    +-----------+-----------+------------+--------------+\n",
    "    | 1         | 2         | 2016-03-01 | 5            |\n",
    "    | 1         | 2         | 2016-05-02 | 6            |\n",
    "    | 1         | 3         | 2017-06-25 | 1            |\n",
    "    | 3         | 1         | 2016-03-02 | 0            |\n",
    "    | 3         | 4         | 2018-07-03 | 5            |\n",
    "    +-----------+-----------+------------+--------------+\n",
    "Output: \n",
    "\n",
    "    +-----------+------------+---------------------+\n",
    "    | player_id | event_date | games_played_so_far |\n",
    "    +-----------+------------+---------------------+\n",
    "    | 1         | 2016-03-01 | 5                   |\n",
    "    | 1         | 2016-05-02 | 11                  |\n",
    "    | 1         | 2017-06-25 | 12                  |\n",
    "    | 3         | 2016-03-02 | 0                   |\n",
    "    | 3         | 2018-07-03 | 5                   |\n",
    "    +-----------+------------+---------------------+\n",
    "Explanation: \n",
    "\n",
    "    For the player with id 1, 5 + 6 = 11 games played by 2016-05-02, and 5 + 6 + 1 = 12 games played by 2017-06-25.\n",
    "    For the player with id 3, 0 + 5 = 5 games played by 2018-07-03.\n",
    "    Note that for each player we only care about the days when the player logged in.\n",
    "\n",
    "Explanation of the Code\n",
    "\n",
    "    Sorting: The first step sorts the DataFrame by player_id and event_date. This is essential because we need to calculate the cumulative sum of games played in chronological order for each player.\n",
    "\n",
    "    Cumulative Sum Calculation: We use the groupby method to group the data by player_id and then apply cumsum() on the games_played column. This calculates the cumulative number of games played by each player up to each event date.\n",
    "\n",
    "    Selecting Relevant Columns: After computing the cumulative sum, we create a new DataFrame called result that contains only the player_id, event_date, and the newly computed games_played_so_far.\n",
    "\n",
    "Edge Cases\n",
    "\n",
    "    No Activity: If the activity DataFrame is empty, the function will return an empty DataFrame.\n",
    "    Multiple Entries on the Same Day: If a player logs multiple entries on the same day, the cumulative sum will consider all entries for that day.\n",
    "    Different Players: The implementation inherently supports multiple players, ensuring that the cumulative sums are calculated independently for each player.\n",
    "    \n",
    "Complexity Analysis\n",
    "\n",
    "    Time Complexity: The sorting operation dominates the complexity, making it O(n log n), where n is the number of rows in the DataFrame. The grouping and cumulative sum operation is O(n).\n",
    "    Space Complexity: The space complexity is O(n) for storing the cumulative sums in the new column.\n",
    "\n",
    "Follow-Up Questions and Answers\n",
    "Q: How would the function handle players with no games played?\n",
    "\n",
    "    A: The function will correctly output zero for those players on their event dates.\n",
    "Q: Can this function be adapted for more detailed metrics?\n",
    "\n",
    "    A: Yes, it could be expanded to include metrics like average games played per session or total session time, requiring additional data.\n",
    "Q: What would happen if games_played contained negative values?\n",
    "\n",
    "    A: The cumulative sum would still calculate, but negative values could lead to incorrect totals. Data validation would be necessary to handle such cases.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f67a85fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   player_id event_date  games_played_so_far\n",
      "0          1 2016-03-01                    5\n",
      "1          1 2016-05-02                   11\n",
      "2          1 2017-06-25                   12\n",
      "3          3 2016-03-02                    0\n",
      "4          3 2018-07-03                    5\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def gameplay_analysis(activity: pd.DataFrame) -> pd.DataFrame:\n",
    "    # Step 1: Sort the DataFrame by player_id and event_date\n",
    "    activity = activity.sort_values(by=['player_id', 'event_date'])\n",
    "    \n",
    "    # Step 2: Group by player_id and calculate the cumulative sum of games_played\n",
    "    activity['games_played_so_far'] = activity.groupby('player_id')['games_played'].cumsum()\n",
    "    \n",
    "    # Step 3: Select the relevant columns for output\n",
    "    result = activity[['player_id', 'event_date', 'games_played_so_far']]\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Example usage\n",
    "activity_data = {\n",
    "    'player_id': [1, 1, 1, 3, 3],\n",
    "    'device_id': [2, 2, 3, 1, 4],\n",
    "    'event_date': ['2016-03-01', '2016-05-02', '2017-06-25', '2016-03-02', '2018-07-03'],\n",
    "    'games_played': [5, 6, 1, 0, 5]\n",
    "}\n",
    "\n",
    "# Create DataFrame\n",
    "activity_df = pd.DataFrame(activity_data)\n",
    "activity_df['event_date'] = pd.to_datetime(activity_df['event_date'])\n",
    "\n",
    "# Get the result\n",
    "result_df = gameplay_analysis(activity_df)\n",
    "print(result_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a01fc4",
   "metadata": {},
   "source": [
    "# Count Student Number in Departments\n",
    " \n",
    "Table: Student\n",
    "\n",
    "    +--------------+---------+\n",
    "    | Column Name  | Type    |\n",
    "    +--------------+---------+\n",
    "    | student_id   | int     |\n",
    "    | student_name | varchar |\n",
    "    | gender       | varchar |\n",
    "    | dept_id      | int     |\n",
    "    +--------------+---------+\n",
    "    student_id is the primary key (column with unique values) for this table.\n",
    "    dept_id is a foreign key (reference column) to dept_id in the Department tables.\n",
    "    Each row of this table indicates the name of a student, their gender, and the id of their department.\n",
    "\n",
    "\n",
    "Table: Department\n",
    "\n",
    "    +-------------+---------+\n",
    "    | Column Name | Type    |\n",
    "    +-------------+---------+\n",
    "    | dept_id     | int     |\n",
    "    | dept_name   | varchar |\n",
    "    +-------------+---------+\n",
    "    dept_id is the primary key (column with unique values) for this table.\n",
    "    Each row of this table contains the id and the name of a department.\n",
    "\n",
    "\n",
    "    Write a solution to report the respective department name and number of students majoring in each department for all departments in the Department table (even ones with no current students).\n",
    "\n",
    "    Return the result table ordered by student_number in descending order. In case of a tie, order them by dept_name alphabetically.\n",
    "\n",
    "    The result format is in the following example.\n",
    "\n",
    " \n",
    "\n",
    "Example 1:\n",
    "\n",
    "Input: \n",
    "Student table:\n",
    "\n",
    "    +------------+--------------+--------+---------+\n",
    "    | student_id | student_name | gender | dept_id |\n",
    "    +------------+--------------+--------+---------+\n",
    "    | 1          | Jack         | M      | 1       |\n",
    "    | 2          | Jane         | F      | 1       |\n",
    "    | 3          | Mark         | M      | 2       |\n",
    "    +------------+--------------+--------+---------+\n",
    "Department table:\n",
    "\n",
    "    +---------+-------------+\n",
    "    | dept_id | dept_name   |\n",
    "    +---------+-------------+\n",
    "    | 1       | Engineering |\n",
    "    | 2       | Science     |\n",
    "    | 3       | Law         |\n",
    "    +---------+-------------+\n",
    "Output: \n",
    "\n",
    "    +-------------+----------------+\n",
    "    | dept_name   | student_number |\n",
    "    +-------------+----------------+\n",
    "    | Engineering | 2              |\n",
    "    | Science     | 1              |\n",
    "    | Law         | 0              |\n",
    "    +-------------+----------------+\n",
    "    \n",
    "Initial Ideas\n",
    "\n",
    "    The problem requires counting students in each department and ensuring that departments with no students are included in the output. This suggests a need for a left join between the Student and Department tables to retain all department records.\n",
    "\n",
    "Steps\n",
    "\n",
    "    Group and Count: First, group the Student DataFrame by dept_id to count the number of students in each department.\n",
    "    Merge: Perform a left join with the Department DataFrame to associate department names with their respective student counts.\n",
    "    Handle Missing Values: Replace NaN values in the student_number column with 0 to reflect departments with no students.\n",
    "    Sort: Order the results by student_number in descending order, and alphabetically by dept_name for ties.\n",
    "    Select Relevant Columns: Return only the dept_name and student_number columns.\n",
    "    \n",
    "Edge Cases\n",
    "\n",
    "    No Students: If the Student table is empty, all departments should return with student_number as 0.\n",
    "    No Departments: If the Department table is empty, the result should also be an empty DataFrame.\n",
    "    All Departments Have Students: The output should still correctly count and sort as specified.\n",
    "    Multiple Entries for the Same Student: Each student should be counted once; duplicates in the Student table should not inflate the counts.\n",
    "\n",
    "Complexity\n",
    "\n",
    "    Time Complexity: The overall complexity is O(n + m log m) where n is the number of students and m is the number of departments, mainly due to the sorting step.\n",
    "    Space Complexity: The space complexity is O(m + n) because we create additional DataFrames to hold counts and results.\n",
    "\n",
    "Follow-Up Questions and Answers\n",
    "\n",
    "Q: How would you modify this to include more details about students?\n",
    "\n",
    "    A: We could include additional columns from the Student DataFrame by modifying the merge and groupby operations to keep track of gender or other attributes.\n",
    "Q: What if we wanted to group students by gender within each department?\n",
    "\n",
    "    A: We would group the Student DataFrame by both dept_id and gender and then count students for each combination before merging with the Department table.\n",
    "Q: How would you handle cases where student data may be invalid (e.g., null values)?\n",
    "\n",
    "    A: We could add data cleaning steps before processing, such as dropping rows with null values in critical columns like dept_id.\n",
    "Q: Can you suggest ways to optimize performance for very large datasets?\n",
    "\n",
    "    A: Indexing the dept_id column in both DataFrames can improve join performance. Also, using more efficient data types or data storage formats (like Parquet) may help reduce memory usage and speed up operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55bab704",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     dept_name  student_number\n",
      "0  Engineering               2\n",
      "1      Science               1\n",
      "2          Law               0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def count_students(student: pd.DataFrame, department: pd.DataFrame) -> pd.DataFrame:\n",
    "    # Step 1: Group by department ID in the student DataFrame and count students\n",
    "    student_count = student.groupby('dept_id').size().reset_index(name='student_number')\n",
    "    \n",
    "    # Step 2: Merge the student count with the department DataFrame\n",
    "    result = pd.merge(department, student_count, how='left', left_on='dept_id', right_on='dept_id')\n",
    "    \n",
    "    # Step 3: Fill NaN values with 0 for departments without students\n",
    "    result['student_number'] = result['student_number'].fillna(0).astype(int)\n",
    "    \n",
    "    # Step 4: Sort the results by student_number descending, then by dept_name alphabetically\n",
    "    result = result.sort_values(by=['student_number', 'dept_name'], ascending=[False, True])\n",
    "    \n",
    "    # Step 5: Select relevant columns for output\n",
    "    return result[['dept_name', 'student_number']]\n",
    "\n",
    "# Sample Input Data\n",
    "student_data = {\n",
    "    'student_id': [1, 2, 3],\n",
    "    'student_name': ['Jack', 'Jane', 'Mark'],\n",
    "    'gender': ['M', 'F', 'M'],\n",
    "    'dept_id': [1, 1, 2]\n",
    "}\n",
    "\n",
    "department_data = {\n",
    "    'dept_id': [1, 2, 3],\n",
    "    'dept_name': ['Engineering', 'Science', 'Law']\n",
    "}\n",
    "\n",
    "# Creating DataFrames\n",
    "student_df = pd.DataFrame(student_data)\n",
    "department_df = pd.DataFrame(department_data)\n",
    "\n",
    "# Running the function\n",
    "output_df = count_students(student_df, department_df)\n",
    "\n",
    "# Displaying the output\n",
    "print(output_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "590c8683",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
