{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43544db1",
   "metadata": {},
   "source": [
    "# Project Employees III\n",
    " \n",
    "Table: Project\n",
    "\n",
    "    +-------------+---------+\n",
    "    | Column Name | Type    |\n",
    "    +-------------+---------+\n",
    "    | project_id  | int     |\n",
    "    | employee_id | int     |\n",
    "    +-------------+---------+\n",
    "(project_id, employee_id) is the primary key (combination of columns with unique values) of this table.\n",
    "employee_id is a foreign key (reference column) to Employee table.\n",
    "\n",
    "Each row of this table indicates that the employee with employee_id is working on the project with project_id.\n",
    " \n",
    "\n",
    "Table: Employee\n",
    "\n",
    "    +------------------+---------+\n",
    "    | Column Name      | Type    |\n",
    "    +------------------+---------+\n",
    "    | employee_id      | int     |\n",
    "    | name             | varchar |\n",
    "    | experience_years | int     |\n",
    "    +------------------+---------+\n",
    "employee_id is the primary key (column with unique values) of this table.\n",
    "Each row of this table contains information about one employee.\n",
    " \n",
    "\n",
    "Write a solution to report the most experienced employees in each project. In case of a tie, report all employees with the maximum number of experience years.\n",
    "\n",
    "Return the result table in any order.\n",
    "\n",
    "The result format is in the following example.\n",
    "\n",
    " \n",
    "\n",
    "Example 1:\n",
    "\n",
    "Input: \n",
    "Project table:\n",
    "\n",
    "    +-------------+-------------+\n",
    "    | project_id  | employee_id |\n",
    "    +-------------+-------------+\n",
    "    | 1           | 1           |\n",
    "    | 1           | 2           |\n",
    "    | 1           | 3           |\n",
    "    | 2           | 1           |\n",
    "    | 2           | 4           |\n",
    "    +-------------+-------------+\n",
    "    \n",
    "Employee table:\n",
    "\n",
    "    +-------------+--------+------------------+\n",
    "    | employee_id | name   | experience_years |\n",
    "    +-------------+--------+------------------+\n",
    "    | 1           | Khaled | 3                |\n",
    "    | 2           | Ali    | 2                |\n",
    "    | 3           | John   | 3                |\n",
    "    | 4           | Doe    | 2                |\n",
    "    +-------------+--------+------------------+\n",
    "Output: \n",
    "\n",
    "    +-------------+---------------+\n",
    "    | project_id  | employee_id   |\n",
    "    +-------------+---------------+\n",
    "    | 1           | 1             |\n",
    "    | 1           | 3             |\n",
    "    | 2           | 1             |\n",
    "    +-------------+---------------+\n",
    "Explanation: Both employees with id 1 and 3 have the most experience among the employees of the first project. For the second project, the employee with id 1 has the most experience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64534577",
   "metadata": {},
   "outputs": [],
   "source": [
    "SELECT p.project_id, p.employee_id\n",
    "FROM Project p\n",
    "JOIN Employee e ON p.employee_id = e.employee_id\n",
    "WHERE (p.project_id, e.experience_years) IN (\n",
    "    SELECT p2.project_id, MAX(e2.experience_years)\n",
    "    FROM Project p2\n",
    "    JOIN Employee e2 ON p2.employee_id = e2.employee_id\n",
    "    GROUP BY p2.project_id\n",
    ");\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f56a6392",
   "metadata": {},
   "source": [
    "Explanation:\n",
    "- This solution works by leveraging SQL’s ability to handle filtering with IN for multiple columns, making it concise and performant:\n",
    "\n",
    "- Complexity: The solution has a complexity mainly driven by the subquery filtering, which should work efficiently on indexed tables.\n",
    "\n",
    "- Edge Cases: We handle cases where multiple employees have the same maximum experience years in a project by including all matching rows with the WHERE (project_id, experience_years) IN condition. This approach guarantees that if there are ties, they will all be returned."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def22be6",
   "metadata": {},
   "source": [
    "# Project Employees II\n",
    "Table: Project\n",
    "\n",
    "    +-------------+---------+\n",
    "    | Column Name | Type    |\n",
    "    +-------------+---------+\n",
    "    | project_id  | int     |\n",
    "    | employee_id | int     |\n",
    "    +-------------+---------+\n",
    "\n",
    "(project_id, employee_id) is the primary key (combination of columns with unique values) of this table.\n",
    "employee_id is a foreign key (reference column) to Employee table.\n",
    "Each row of this table indicates that the employee with employee_id is working on the project with project_id.\n",
    " \n",
    "\n",
    "Table: Employee\n",
    "\n",
    "    +------------------+---------+\n",
    "    | Column Name      | Type    |\n",
    "    +------------------+---------+\n",
    "    | employee_id      | int     |\n",
    "    | name             | varchar |\n",
    "    | experience_years | int     |\n",
    "    +------------------+---------+\n",
    "employee_id is the primary key (column with unique values) of this table.\n",
    "Each row of this table contains information about one employee.\n",
    " \n",
    "\n",
    "Write a solution to report all the projects that have the most employees.\n",
    "\n",
    "Return the result table in any order.\n",
    "\n",
    "The result format is in the following example.\n",
    "\n",
    " \n",
    "\n",
    "Example 1:\n",
    "\n",
    "Input: \n",
    "Project table:\n",
    "\n",
    "    +-------------+-------------+\n",
    "    | project_id  | employee_id |\n",
    "    +-------------+-------------+\n",
    "    | 1           | 1           |\n",
    "    | 1           | 2           |\n",
    "    | 1           | 3           |\n",
    "    | 2           | 1           |\n",
    "    | 2           | 4           |\n",
    "    +-------------+-------------+\n",
    "Employee table:\n",
    "\n",
    "    +-------------+--------+------------------+\n",
    "    | employee_id | name   | experience_years |\n",
    "    +-------------+--------+------------------+\n",
    "    | 1           | Khaled | 3                |\n",
    "    | 2           | Ali    | 2                |\n",
    "    | 3           | John   | 1                |\n",
    "    | 4           | Doe    | 2                |\n",
    "    +-------------+--------+------------------+\n",
    "Output: \n",
    "\n",
    "    +-------------+\n",
    "    | project_id  |\n",
    "    +-------------+\n",
    "    | 1           |\n",
    "    +-------------+\n",
    "Explanation: The first project has 3 employees while the second one has 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "518966ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "SELECT project_id\n",
    "FROM Project\n",
    "GROUP BY project_id\n",
    "HAVING COUNT(employee_id) = (\n",
    "    SELECT MAX(employee_count)\n",
    "    FROM (\n",
    "        SELECT project_id, COUNT(employee_id) AS employee_count\n",
    "        FROM Project\n",
    "        GROUP BY project_id\n",
    "    ) AS ProjectCounts\n",
    ");\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "488e54d8",
   "metadata": {},
   "source": [
    "Complexity Analysis\n",
    "\n",
    "Time Complexity:\n",
    "\n",
    "    Inner Subquery: The inner subquery has a time complexity of  O(n), where n is the number of rows in the Project table. This is because it scans all rows to group and count them.\n",
    "\n",
    "    Outer Query: The outer query also has a time complexity of O(n), as it re-groups and filters based on the maximum count.\n",
    "\n",
    "    Overall Complexity: Approximately O(n), making this efficient for typical datasets, especially with indexing on project_id.\n",
    "\n",
    "Space Complexity:\n",
    "\n",
    "    Temporary Space: The space complexity is O(m), where m is the number of unique project_ids, as it temporarily stores the ProjectCounts result.\n",
    "\n",
    "Edge Cases\n",
    "\n",
    "    - All Projects Have the Same Employee Count: If all projects have the same number of employees, the query returns all project_ids, as they all meet the maximum count condition.\n",
    "    - Single Project: If there’s only one project, the query simply returns that project’s ID, as it inherently has the maximum count.\n",
    "    - Projects with Zero Employees: If any project has zero employees, it won’t be included in the result since the count is zero, which typically won’t match the maximum.\n",
    "    - Ties for Maximum Count: If multiple projects share the maximum employee count, they’ll all be included in the result, as each meets the maximum threshold.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c6a4e29",
   "metadata": {},
   "source": [
    "# Article Views I\n",
    " \n",
    "Table: Views\n",
    "\n",
    "    +---------------+---------+\n",
    "    | Column Name   | Type    |\n",
    "    +---------------+---------+\n",
    "    | article_id    | int     |\n",
    "    | author_id     | int     |\n",
    "    | viewer_id     | int     |\n",
    "    | view_date     | date    |\n",
    "    +---------------+---------+\n",
    "There is no primary key (column with unique values) for this table, the table may have duplicate rows.\n",
    "Each row of this table indicates that some viewer viewed an article (written by some author) on some date. \n",
    "Note that equal author_id and viewer_id indicate the same person.\n",
    " \n",
    "\n",
    "Write a solution to find all the authors that viewed at least one of their own articles.\n",
    "\n",
    "Return the result table sorted by id in ascending order.\n",
    "\n",
    "The result format is in the following example.\n",
    "\n",
    " \n",
    "\n",
    "Example 1:\n",
    "\n",
    "Input: \n",
    "Views table:\n",
    "    \n",
    "    +------------+-----------+-----------+------------+\n",
    "    | article_id | author_id | viewer_id | view_date  |\n",
    "    +------------+-----------+-----------+------------+\n",
    "    | 1          | 3         | 5         | 2019-08-01 |\n",
    "    | 1          | 3         | 6         | 2019-08-02 |\n",
    "    | 2          | 7         | 7         | 2019-08-01 |\n",
    "    | 2          | 7         | 6         | 2019-08-02 |\n",
    "    | 4          | 7         | 1         | 2019-07-22 |\n",
    "    | 3          | 4         | 4         | 2019-07-21 |\n",
    "    | 3          | 4         | 4         | 2019-07-21 |\n",
    "    +------------+-----------+-----------+------------+\n",
    "\n",
    "Output: \n",
    "\n",
    "    +------+\n",
    "    | id   |\n",
    "    +------+\n",
    "    | 4    |\n",
    "    | 7    |\n",
    "    +------+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4609a2bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "SELECT DISTINCT author_id AS id\n",
    "FROM Views\n",
    "WHERE author_id = viewer_id\n",
    "ORDER BY id ASC;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "827c0944",
   "metadata": {},
   "source": [
    "Explanation\n",
    "\n",
    "Problem Breakdown:\n",
    "\n",
    "    We need to identify authors who have viewed at least one of their own articles. This means we’re looking for records where the author_id is the same as the viewer_id.\n",
    "\n",
    "    The result should return only unique author_ids in ascending order.\n",
    "\n",
    "Query Explanation:\n",
    "\n",
    "    SELECT DISTINCT author_id AS id:We use SELECT DISTINCT to ensure that each author appears only once in the result, regardless of how many times they viewed their articles.\n",
    "    \n",
    "    We rename author_id as id to match the required output format.\n",
    "    \n",
    "    FROM Views: We retrieve data from the Views table, which contains all article view records, including article_id, author_id, viewer_id, and view_date.\n",
    "    \n",
    "    WHERE author_id = viewer_id: This condition filters the rows to include only those where the author_id matches the viewer_id, meaning the author viewed their own article.\n",
    "    \n",
    "    ORDER BY id ASC: Finally, we sort the result by id (the author’s ID) in ascending order to meet the problem’s output requirements.\n",
    "\n",
    "Complexity Analysis\n",
    "\n",
    "Time Complexity:\n",
    "\n",
    "    The query has a time complexity of O(n), where n is the number of rows in the Views table, as it performs a scan to filter rows where author_id = viewer_id and a distinct selection.\n",
    "\n",
    "Space Complexity:\n",
    "\n",
    "    The space complexity is O(k), where k is the number of distinct author_ids that match the condition, as we store the unique results temporarily.\n",
    "\n",
    "Edge Cases\n",
    "\n",
    "    No Matching Rows: If there are no rows where author_id = viewer_id, the result will be an empty table.\n",
    "\n",
    "    Multiple Views by the Same Author: If an author views their article multiple times, DISTINCT ensures they appear only once in the result.\n",
    "\n",
    "    Single Record Table: If the Views table has only one row and it meets the author_id = viewer_id condition, the query will return just that author’s ID."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aace34d",
   "metadata": {},
   "source": [
    "# Consecutive Numbers\n",
    " \n",
    "Table: Logs\n",
    "\n",
    "    +-------------+---------+\n",
    "    | Column Name | Type    |\n",
    "    +-------------+---------+\n",
    "    | id          | int     |\n",
    "    | num         | varchar |\n",
    "    +-------------+---------+\n",
    "In SQL, id is the primary key for this table.\n",
    "id is an autoincrement column starting from 1.\n",
    " \n",
    "\n",
    "Find all numbers that appear at least three times consecutively.\n",
    "\n",
    "Return the result table in any order.\n",
    "\n",
    "The result format is in the following example.\n",
    "\n",
    " \n",
    "\n",
    "Example 1:\n",
    "\n",
    "Input: \n",
    "Logs table:\n",
    "\n",
    "    +----+-----+\n",
    "    | id | num |\n",
    "    +----+-----+\n",
    "    | 1  | 1   |\n",
    "    | 2  | 1   |\n",
    "    | 3  | 1   |\n",
    "    | 4  | 2   |\n",
    "    | 5  | 1   |\n",
    "    | 6  | 2   |\n",
    "    | 7  | 2   |\n",
    "    +----+-----+\n",
    "Output: \n",
    "\n",
    "    +-----------------+\n",
    "    | ConsecutiveNums |\n",
    "    +-----------------+\n",
    "    | 1               |\n",
    "    +-----------------+\n",
    "Explanation: 1 is the only number that appears consecutively for at least three times."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c3ce0d",
   "metadata": {},
   "source": [
    "Steps and Explanation:\n",
    "    \n",
    "    Identify Consecutive Repetitions: We need to check whether each number (num) in the Logs table appears consecutively three or more times. Consecutive means that each appearance follows immediately after the previous one in the order of id.\n",
    "\n",
    "Create Conditions for Consecutive Rows: For any given row with id = i, we’ll check:\n",
    "\n",
    "    - if num at i is the same as num at i+1\n",
    "    - and num at i+1 is the same as num at i+2.\n",
    "    - If both of these conditions are true, then we have identified a number that appears consecutively three times starting from id = i.\n",
    "\n",
    "SQL Query: We can write a query that uses a JOIN or WHERE clause to find consecutive rows.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37e1393",
   "metadata": {},
   "outputs": [],
   "source": [
    "SELECT DISTINCT l1.num AS ConsecutiveNums\n",
    "FROM Logs l1, Logs l2, Logs l3\n",
    "WHERE l1.num = l2.num \n",
    "  AND l2.num = l3.num \n",
    "  AND l1.id = l2.id - 1 \n",
    "  AND l2.id = l3.id - 1;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2962b45f",
   "metadata": {},
   "source": [
    "Explanation of the SQL Query:\n",
    "    \n",
    "    - l1, l2, and l3 are aliases for the Logs table, representing three consecutive rows.\n",
    "    \n",
    "    - The WHERE clause checks:\n",
    "        - l1.num = l2.num and l2.num = l3.num: This ensures that the same number appears in three consecutive rows.\n",
    "        - l1.id = l2.id - 1 and l2.id = l3.id - 1: This ensures the rows are consecutive based on the id field.\n",
    "    \n",
    "    - SELECT DISTINCT l1.num returns the unique numbers that meet the criteria.\n",
    "    \n",
    "Edge Cases:\n",
    "\n",
    "    Fewer than Three Rows: If the table has fewer than three rows, we can’t have any number appearing three times consecutively.\n",
    "\n",
    "    Non-Consecutive Repetitions: If a number appears multiple times but not in consecutive rows (e.g., with different numbers in between), it should not be included in the result.\n",
    "\n",
    "    Multiple Sets of Consecutive Repetitions: If the same number appears consecutively in two different sequences (e.g., three times in one part and three times in another part), it should still be included only once due to DISTINCT.\n",
    "    \n",
    "Complexity Analysis:\n",
    "\n",
    "    Time Complexity: O(n) assuming an indexed query with id being unique, as we are scanning through the table and filtering based on adjacent rows.\n",
    "\n",
    "    Space Complexity: O(m) where m is the number of unique numbers that appear consecutively three times, since we're storing these results.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8416d9cc",
   "metadata": {},
   "source": [
    "# Get Highest Answer Rate Question \n",
    "\n",
    "Table: SurveyLog\n",
    "\n",
    "    +-------------+------+\n",
    "    | Column Name | Type |\n",
    "    +-------------+------+\n",
    "    | id          | int  |\n",
    "    | action      | ENUM |\n",
    "    | question_id | int  |\n",
    "    | answer_id   | int  |\n",
    "    | q_num       | int  |\n",
    "    | timestamp   | int  |\n",
    "    +-------------+------+\n",
    "- This table may contain duplicate rows.\n",
    "- action is an ENUM (category) of the type: \"show\", \"answer\", or \"skip\".\n",
    "- Each row of this table indicates the user with ID = id has taken an action with the question question_id at time timestamp.\n",
    "- If the action taken by the user is \"answer\", answer_id will contain the id of that answer, otherwise, it will be null.\n",
    "- q_num is the numeral order of the question in the current session.\n",
    " \n",
    "\n",
    "The answer rate for a question is the number of times a user answered the question by the number of times a user showed the question.\n",
    "\n",
    "Write a solution to report the question that has the highest answer rate. If multiple questions have the same maximum answer rate, report the question with the smallest question_id.\n",
    "\n",
    "The result format is in the following example.\n",
    "\n",
    " \n",
    "\n",
    "Example 1:\n",
    "\n",
    "Input: \n",
    "SurveyLog table:\n",
    "\n",
    "    +----+--------+-------------+-----------+-------+-----------+\n",
    "    | id | action | question_id | answer_id | q_num | timestamp |\n",
    "    +----+--------+-------------+-----------+-------+-----------+\n",
    "    | 5  | show   | 285         | null      | 1     | 123       |\n",
    "    | 5  | answer | 285         | 124124    | 1     | 124       |\n",
    "    | 5  | show   | 369         | null      | 2     | 125       |\n",
    "    | 5  | skip   | 369         | null      | 2     | 126       |\n",
    "    +----+--------+-------------+-----------+-------+-----------+\n",
    "Output: \n",
    "\n",
    "    +------------+\n",
    "    | survey_log |\n",
    "    +------------+\n",
    "    | 285        |\n",
    "    +------------+\n",
    "Explanation: \n",
    "\n",
    "    Question 285 was showed 1 time and answered 1 time. The answer rate of question 285 is 1.0\n",
    "    Question 369 was showed 1 time and was not answered. The answer rate of question 369 is 0.0\n",
    "    Question 285 has the highest answer rate.\n",
    "    \n",
    "    \n",
    "Steps and Explanation:\n",
    "\n",
    "Filter the show and answer Actions:\n",
    "\n",
    "    We need to count how many times each question was shown and how many times it was answered.\n",
    "    In the SurveyLog table, a show action means the question was displayed to a user, and an answer action means the user provided an answer to that question.\n",
    "    \n",
    "Aggregate Counts by Question:\n",
    "\n",
    "    We can use conditional aggregation to count show and answer actions for each question_id.\n",
    "    \n",
    "Calculate the Answer Rate:\n",
    "\n",
    "    The answer rate for each question is calculated as the count of answers divided by the count of shows.\n",
    "    To avoid division by zero, we handle cases where a question was shown but never answered.\n",
    "    \n",
    "Select the Question with the Highest Answer Rate:\n",
    "\n",
    "    We need to find the question with the maximum answer rate. If multiple questions have the same answer rate, we return the question with the smallest question_id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d84dee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your MySQL query statement below\n",
    "SELECT question_id as survey_log\n",
    "FROM (\n",
    "    SELECT \n",
    "        question_id,\n",
    "        SUM(action = 'answer') / SUM(action = 'show') AS answer_rate\n",
    "    FROM SurveyLog\n",
    "    GROUP BY question_id\n",
    ") AS AnswerRates\n",
    "ORDER BY answer_rate DESC, question_id ASC\n",
    "LIMIT 1;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a44441ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PostgreSQL\n",
    "SELECT question_id AS survey_log\n",
    "FROM (\n",
    "    SELECT \n",
    "        question_id,\n",
    "        SUM(CASE WHEN action = 'answer' THEN 1 ELSE 0 END) * 1.0 / \n",
    "        NULLIF(SUM(CASE WHEN action = 'show' THEN 1 ELSE 0 END), 0) AS answer_rate\n",
    "    FROM SurveyLog\n",
    "    GROUP BY question_id\n",
    ") AS AnswerRates\n",
    "ORDER BY answer_rate DESC, question_id ASC\n",
    "LIMIT 1;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91dfc9e3",
   "metadata": {},
   "source": [
    "Explanation of the SQL Query:\n",
    "\n",
    "Inner Query (AnswerRates):\n",
    "\n",
    "    SUM(action = 'answer') counts how many times each question was answered. This works because MySQL treats TRUE as 1 and FALSE as 0.\n",
    "    SUM(action = 'show') counts how many times each question was shown.\n",
    "    The answer_rate is calculated by dividing the answer count by the show count for each question_id.\n",
    "    We GROUP BY question_id to calculate these values per question.\n",
    "    \n",
    "Outer Query:\n",
    "\n",
    "    ORDER BY answer_rate DESC, question_id ASC: This sorts the results by answer rate in descending order so that the highest rate is at the top. If there are ties, it uses question_id in ascending order to select the smallest question_id.\n",
    "    LIMIT 1 ensures we return only the question with the highest answer rate and, in the case of ties, the smallest question_id.\n",
    "    \n",
    "Edge Cases:\n",
    "\n",
    "    Questions Never Shown: Questions that were answered but never shown should not be included, but they won’t appear because we divide by SUM(action = 'show').\n",
    "    No Answers: If a question was shown but never answered, the answer rate will be 0. This question may be included if it has the highest rate in cases where no questions are answered.\n",
    "    Multiple Questions with the Same Answer Rate: When multiple questions have the same answer rate, this query will pick the question with the smallest question_id.\n",
    "    \n",
    "Complexity Analysis:\n",
    "\n",
    "    Time Complexity:  O(n), where n is the number of rows in the SurveyLog table. The GROUP BY operation iterates over each row, and the ORDER BY with LIMIT is efficient given it’s just selecting one row.\n",
    "    Space Complexity: O(m), where m is the number of unique question_ids, as we store these results in temporary memory for sorting and filtering."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "012ed9d1",
   "metadata": {},
   "source": [
    "# Apples & Oranges\n",
    " \n",
    "Table: Sales\n",
    "\n",
    "    +---------------+---------+\n",
    "    | Column Name   | Type    |\n",
    "    +---------------+---------+\n",
    "    | sale_date     | date    |\n",
    "    | fruit         | enum    | \n",
    "    | sold_num      | int     | \n",
    "    +---------------+---------+\n",
    "(sale_date, fruit) is the primary key (combination of columns with unique values) of this table.\n",
    "This table contains the sales of \"apples\" and \"oranges\" sold each day.\n",
    " \n",
    "\n",
    "Write a solution to report the difference between the number of apples and oranges sold each day.\n",
    "\n",
    "Return the result table ordered by sale_date.\n",
    "\n",
    "The result format is in the following example.\n",
    "\n",
    " \n",
    "\n",
    "Example 1:\n",
    "\n",
    "Input: \n",
    "Sales table:\n",
    "\n",
    "    +------------+------------+-------------+\n",
    "    | sale_date  | fruit      | sold_num    |\n",
    "    +------------+------------+-------------+\n",
    "    | 2020-05-01 | apples     | 10          |\n",
    "    | 2020-05-01 | oranges    | 8           |\n",
    "    | 2020-05-02 | apples     | 15          |\n",
    "    | 2020-05-02 | oranges    | 15          |\n",
    "    | 2020-05-03 | apples     | 20          |\n",
    "    | 2020-05-03 | oranges    | 0           |\n",
    "    | 2020-05-04 | apples     | 15          |\n",
    "    | 2020-05-04 | oranges    | 16          |\n",
    "    +------------+------------+-------------+\n",
    "Output: \n",
    "\n",
    "    +------------+--------------+\n",
    "    | sale_date  | diff         |\n",
    "    +------------+--------------+\n",
    "    | 2020-05-01 | 2            |\n",
    "    | 2020-05-02 | 0            |\n",
    "    | 2020-05-03 | 20           |\n",
    "    | 2020-05-04 | -1           |\n",
    "    +------------+--------------+\n",
    "    \n",
    "Explanation: \n",
    "\n",
    "    Day 2020-05-01, 10 apples and 8 oranges were sold (Difference  10 - 8 = 2).\n",
    "    Day 2020-05-02, 15 apples and 15 oranges were sold (Difference 15 - 15 = 0).\n",
    "    Day 2020-05-03, 20 apples and 0 oranges were sold (Difference 20 - 0 = 20).\n",
    "    Day 2020-05-04, 15 apples and 16 oranges were sold (Difference 15 - 16 = -1).\n",
    "\n",
    "Steps and Explanation:\n",
    "\n",
    "    Aggregate Sales by Date: We'll need to sum the sold_num for apples and oranges separately for each sale_date.\n",
    "    Calculate the Difference: Once we have the total sold numbers for both fruits for each date, we can calculate the difference by subtracting the total number of oranges sold from the total number of apples sold.\n",
    "    Order the Results: Finally, we will order the results by sale_date to ensure the output is in the correct chronological order.\n",
    "    \n",
    "    \n",
    "Explanation of the SQL Query:\n",
    "\n",
    "SUM with CASE:\n",
    "\n",
    "    SUM(CASE WHEN fruit = 'apples' THEN sold_num ELSE 0 END): This sums up the sold_num for apples only. If the fruit is not apples, it adds 0.\n",
    "    SUM(CASE WHEN fruit = 'oranges' THEN sold_num ELSE 0 END): Similarly, this sums up the sold_num for oranges.\n",
    "    Calculating the Difference:\n",
    "\n",
    "    The difference is calculated by subtracting the total number of oranges sold from the total number of apples sold for each date.\n",
    "    \n",
    "GROUP BY:\n",
    "    \n",
    "    GROUP BY sale_date: This groups the results by each date, so we get a single result row for each date.\n",
    "ORDER BY:\n",
    "    \n",
    "    ORDER BY sale_date: This sorts the final results in chronological order by the sale date.\n",
    "    \n",
    "Edge Cases:\n",
    "\n",
    "    Dates with Only One Fruit: If a date has only apples or only oranges sold, the difference will reflect that, such as being positive or negative or even zero.\n",
    "\n",
    "    No Sales Data for a Date: If there are no sales recorded for a date in the table, that date won't appear in the output at all since it does not satisfy the GROUP BY clause.\n",
    "\n",
    "    Handling Null Values: In this query, null values for sold_num in the original table are not an issue since we're using conditional aggregation that defaults to 0.\n",
    "\n",
    "Complexity Analysis:\n",
    "\n",
    "    Time Complexity: O(n), where n is the number of rows in the Sales table. The query scans through the entire table once to aggregate data.\n",
    "    Space Complexity: O(d), where d is the number of unique sale_dates, since we are storing results for each distinct date in the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d574b405",
   "metadata": {},
   "outputs": [],
   "source": [
    "SELECT sale_date,\n",
    "       SUM(CASE WHEN fruit = 'apples' THEN sold_num ELSE 0 END) -\n",
    "       SUM(CASE WHEN fruit = 'oranges' THEN sold_num ELSE 0 END) AS diff\n",
    "FROM Sales\n",
    "GROUP BY sale_date\n",
    "ORDER BY sale_date;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e466b9b",
   "metadata": {},
   "source": [
    "# Winning Candidate\n",
    " \n",
    "Table: Candidate\n",
    "\n",
    "    +-------------+----------+\n",
    "    | Column Name | Type     |\n",
    "    +-------------+----------+\n",
    "    | id          | int      |\n",
    "    | name        | varchar  |\n",
    "    +-------------+----------+\n",
    "id is the column with unique values for this table.\n",
    "\n",
    "Each row of this table contains information about the id and the name of a candidate.\n",
    " \n",
    "\n",
    "Table: Vote\n",
    "\n",
    "    +-------------+------+\n",
    "    | Column Name | Type |\n",
    "    +-------------+------+\n",
    "    | id          | int  |\n",
    "    | candidateId | int  |\n",
    "    +-------------+------+\n",
    "id is an auto-increment primary key (column with unique values).\n",
    "candidateId is a foreign key (reference column) to id from the Candidate table.\n",
    "\n",
    "Each row of this table determines the candidate who got the ith vote in the elections.\n",
    " \n",
    "\n",
    "Write a solution to report the name of the winning candidate (i.e., the candidate who got the largest number of votes).\n",
    "\n",
    "The test cases are generated so that exactly one candidate wins the elections.\n",
    "\n",
    "The result format is in the following example.\n",
    "\n",
    " \n",
    "\n",
    "Example 1:\n",
    "\n",
    "Input: \n",
    "Candidate table:\n",
    "\n",
    "    +----+------+\n",
    "    | id | name |\n",
    "    +----+------+\n",
    "    | 1  | A    |\n",
    "    | 2  | B    |\n",
    "    | 3  | C    |\n",
    "    | 4  | D    |\n",
    "    | 5  | E    |\n",
    "    +----+------+\n",
    "Vote table:\n",
    "\n",
    "    +----+-------------+\n",
    "    | id | candidateId |\n",
    "    +----+-------------+\n",
    "    | 1  | 2           |\n",
    "    | 2  | 4           |\n",
    "    | 3  | 3           |\n",
    "    | 4  | 2           |\n",
    "    | 5  | 5           |\n",
    "    +----+-------------+\n",
    "    \n",
    "Output: \n",
    "\n",
    "+------+\n",
    "| name |\n",
    "+------+\n",
    "| B    |\n",
    "+------+\n",
    "\n",
    "Explanation: \n",
    "    Candidate B has 2 votes. Candidates C, D, and E have 1 vote each.\n",
    "    The winner is candidate B.\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be407a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "SELECT c.name\n",
    "FROM Candidate c\n",
    "JOIN (\n",
    "    SELECT candidateId, COUNT(*) AS vote_count\n",
    "    FROM Vote\n",
    "    GROUP BY candidateId\n",
    ") v ON c.id = v.candidateId\n",
    "ORDER BY v.vote_count DESC\n",
    "LIMIT 1;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "202f61c5",
   "metadata": {},
   "source": [
    "Steps:\n",
    "\n",
    "    Count the Votes: We will count the number of votes each candidate received by joining the Vote table with the Candidate table based on the candidate's ID.\n",
    "    Determine the Winner: After counting the votes, we will find the candidate with the maximum number of votes. Given that the problem states there is always one winner, we don't need to handle ties.\n",
    "    Return the Name of the Winning Candidate: Finally, we will return the name of the winning candidate.\n",
    "    \n",
    "Edge Cases:\n",
    "\n",
    "    Exactly One Candidate Wins: The problem specifies that there will always be exactly one winner, so we do not need to account for ties or situations where no votes are cast.\n",
    "    Candidates with No Votes: Candidates who have not received any votes will not appear in the results from the inner query, so they will not affect the final output.\n",
    "    No Votes Cast: Although not applicable per the problem's constraints, if there were no votes, the query would return an empty result.\n",
    "    \n",
    "Complexity Analysis:\n",
    "\n",
    "    Time Complexity: O(n+m), where n is the number of rows in the Vote table and m is the number of rows in the Candidate table. The inner query iterates through all votes, and the join operation checks against all candidates.\n",
    "    Space Complexity: O(k), where k is the number of unique candidates. The inner query results need to be stored temporarily before joining with the Candidate table."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "701e3dbb",
   "metadata": {},
   "source": [
    "# Report Contiguous Dates\n",
    " \n",
    "Table: Failed\n",
    "\n",
    "    +--------------+---------+\n",
    "    | Column Name  | Type    |\n",
    "    +--------------+---------+\n",
    "    | fail_date    | date    |\n",
    "    +--------------+---------+\n",
    "    \n",
    "fail_date is the primary key (column with unique values) for this table.\n",
    "\n",
    "This table contains the days of failed tasks.\n",
    " \n",
    "\n",
    "Table: Succeeded\n",
    "\n",
    "    +--------------+---------+\n",
    "    | Column Name  | Type    |\n",
    "    +--------------+---------+\n",
    "    | success_date | date    |\n",
    "    +--------------+---------+\n",
    "success_date is the primary key (column with unique values) for this table.\n",
    "\n",
    "This table contains the days of succeeded tasks.\n",
    " \n",
    "\n",
    "A system is running one task every day. Every task is independent of the previous tasks. The tasks can fail or succeed.\n",
    "\n",
    "Write a solution to report the period_state for each continuous interval of days in the period from 2019-01-01 to 2019-12-31.\n",
    "\n",
    "period_state is 'failed' if tasks in this interval failed or 'succeeded' if tasks in this interval succeeded. \n",
    "Interval of days are retrieved as start_date and end_date.\n",
    "\n",
    "Return the result table ordered by start_date.\n",
    "\n",
    "The result format is in the following example.\n",
    "\n",
    " \n",
    "\n",
    "Example 1:\n",
    "\n",
    "Input: \n",
    "Failed table:\n",
    "\n",
    "    +-------------------+\n",
    "    | fail_date         |\n",
    "    +-------------------+\n",
    "    | 2018-12-28        |\n",
    "    | 2018-12-29        |\n",
    "    | 2019-01-04        |\n",
    "    | 2019-01-05        |\n",
    "    +-------------------+\n",
    "    \n",
    "Succeeded table:\n",
    "\n",
    "    +-------------------+\n",
    "    | success_date      |\n",
    "    +-------------------+\n",
    "    | 2018-12-30        |\n",
    "    | 2018-12-31        |\n",
    "    | 2019-01-01        |\n",
    "    | 2019-01-02        |\n",
    "    | 2019-01-03        |\n",
    "    | 2019-01-06        |\n",
    "    +-------------------+\n",
    "    \n",
    "Output: \n",
    "\n",
    "    +--------------+--------------+--------------+\n",
    "    | period_state | start_date   | end_date     |\n",
    "    +--------------+--------------+--------------+\n",
    "    | succeeded    | 2019-01-01   | 2019-01-03   |\n",
    "    | failed       | 2019-01-04   | 2019-01-05   |\n",
    "    | succeeded    | 2019-01-06   | 2019-01-06   |\n",
    "    +--------------+--------------+--------------+\n",
    "    \n",
    "Explanation: \n",
    "\n",
    "    The report ignored the system state in 2018 as we care about the system in the period 2019-01-01 to 2019-12-31.\n",
    "    From 2019-01-01 to 2019-01-03 all tasks succeeded and the system state was \"succeeded\".\n",
    "    From 2019-01-04 to 2019-01-05 all tasks failed and the system state was \"failed\".\n",
    "    From 2019-01-06 to 2019-01-06 all tasks succeeded and the system state was \"succeeded\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "972d2ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "SELECT stats AS period_state, MIN(day) AS start_date, MAX(day) AS end_date\n",
    "FROM (\n",
    "    SELECT \n",
    "        day, \n",
    "        RANK() OVER (ORDER BY day) AS overall_ranking, \n",
    "        stats, \n",
    "        rk, \n",
    "        (RANK() OVER (ORDER BY day) - rk) AS inv\n",
    "    FROM (\n",
    "        SELECT fail_date AS day, 'failed' AS stats, RANK() OVER (ORDER BY fail_date) AS rk\n",
    "        FROM Failed\n",
    "        WHERE fail_date BETWEEN '2019-01-01' AND '2019-12-31'\n",
    "        UNION \n",
    "        SELECT success_date AS day, 'succeeded' AS stats, RANK() OVER (ORDER BY success_date) AS rk\n",
    "        FROM Succeeded\n",
    "        WHERE success_date BETWEEN '2019-01-01' AND '2019-12-31'\n",
    "    ) t\n",
    ") c\n",
    "GROUP BY inv, stats\n",
    "ORDER BY start_date;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f00ccb7b",
   "metadata": {},
   "source": [
    "Breakdown of the SQL Query\n",
    "\n",
    "Inner Query (Union of Failures and Successes):\n",
    "\n",
    "    Combines dates from the Failed and Succeeded tables within the specified date range (2019).\n",
    "    Uses UNION to merge both tables into one result set with a common structure.\n",
    "    Assigns ranks to each date within their respective states.\n",
    "\n",
    "Ranking and Calculating Inversions:\n",
    "\n",
    "    The ranks help in identifying the sequence of days, facilitating the detection of continuous intervals.\n",
    "    The inv calculation allows the grouping of continuous days of the same state by subtracting the rk from the overall ranking.\n",
    "\n",
    "Grouping by State:\n",
    "\n",
    "    Aggregates the results to summarize the continuous periods of each state, utilizing MIN and MAX to find the range of dates for each state.\n",
    "\n",
    "Final Output:\n",
    "\n",
    "    Returns the period state, start date, and end date for each continuous period, ordered by start_date.\n",
    "    \n",
    "Edge Cases Considered\n",
    "\n",
    "    No Data for 2019: If both Failed and Succeeded tables have no entries for the year 2019, the output will be empty, as there are no dates to evaluate.\n",
    "    Continuous Successes or Failures: If all tasks are either successful or failed for the entire year, the output will consist of a single row capturing the entire range of the year (e.g., all succeeded from 2019-01-01 to 2019-12-31).\n",
    "    Interleaved Dates: If there are entries with multiple successes and failures on the same day, the ranks will correctly allow for the periods to be recognized and separated, ensuring accurate output.\n",
    "    Dates Without Both States: If a day appears in one state but not the other, the query will still generate results for those continuous periods, ensuring that no gaps are overlooked.\n",
    "\n",
    "Edge Date Handling:\n",
    "\n",
    "    The query explicitly filters dates to fall within the year 2019, thus it does not include entries from the previous or following year, avoiding incorrect aggregations.\n",
    "    \n",
    "Complexity Analysis\n",
    "\n",
    "Time Complexity: \n",
    "\n",
    "    The time complexity of this query is O(N log N), where N is the total number of entries across both the Failed and Succeeded tables. This is primarily due to the use of the RANK() function, which involves sorting the records by date.\n",
    "    The final grouping and aggregation step (using GROUP BY) also contributes to the overall complexity but is generally linear with respect to the number of groups formed.\n",
    "\n",
    "    Space Complexity: \n",
    "    The space complexity is O(N), as the query needs to store the combined results from both tables, including the calculated ranks and states.\n",
    "    The result set in memory grows with the number of unique days present in the input tables, which can affect the overall space requirement depending on the distribution of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c754e34",
   "metadata": {},
   "source": [
    "# Page Recommendations II\n",
    " \n",
    "Table: Friendship\n",
    "\n",
    "    +---------------+---------+\n",
    "    | Column Name   | Type    |\n",
    "    +---------------+---------+\n",
    "    | user1_id      | int     |\n",
    "    | user2_id      | int     |\n",
    "    +---------------+---------+\n",
    "\n",
    "    (user1_id, user2_id) is the primary key (combination of columns with unique values) for this table.\n",
    "\n",
    "    Each row of this table indicates that the users user1_id and user2_id are friends.\n",
    " \n",
    "\n",
    "Table: Likes\n",
    "\n",
    "    +-------------+---------+\n",
    "    | Column Name | Type    |\n",
    "    +-------------+---------+\n",
    "    | user_id     | int     |\n",
    "    | page_id     | int     |\n",
    "    +-------------+---------+\n",
    "    (user_id, page_id) is the primary key (combination of columns with unique values) for this table.\n",
    "    Each row of this table indicates that user_id likes page_id.\n",
    " \n",
    "\n",
    "    You are implementing a page recommendation system for a social media website. Your system will recommend a page to user_id if the page is liked by at least one friend of user_id and is not liked by user_id.\n",
    "\n",
    "    Write a solution to find all the possible page recommendations for every user. Each recommendation should appear as a row in the result table with these columns:\n",
    "\n",
    "    user_id: The ID of the user that your system is making the recommendation to.\n",
    "    page_id: The ID of the page that will be recommended to user_id.\n",
    "    friends_likes: The number of the friends of user_id that like page_id.\n",
    "    Return the result table in any order.\n",
    "\n",
    "The result format is in the following example.\n",
    "\n",
    " \n",
    "\n",
    "Example 1:\n",
    "\n",
    "Input: \n",
    "Friendship table:\n",
    "\n",
    "    +----------+----------+\n",
    "    | user1_id | user2_id |\n",
    "    +----------+----------+\n",
    "    | 1        | 2        |\n",
    "    | 1        | 3        |\n",
    "    | 1        | 4        |\n",
    "    | 2        | 3        |\n",
    "    | 2        | 4        |\n",
    "    | 2        | 5        |\n",
    "    | 6        | 1        |\n",
    "    +----------+----------+\n",
    "    \n",
    "Likes table:\n",
    "\n",
    "    +---------+---------+\n",
    "    | user_id | page_id |\n",
    "    +---------+---------+\n",
    "    | 1       | 88      |\n",
    "    | 2       | 23      |\n",
    "    | 3       | 24      |\n",
    "    | 4       | 56      |\n",
    "    | 5       | 11      |\n",
    "    | 6       | 33      |\n",
    "    | 2       | 77      |\n",
    "    | 3       | 77      |\n",
    "    | 6       | 88      |\n",
    "    +---------+---------+\n",
    "Output: \n",
    "\n",
    "    +---------+---------+---------------+\n",
    "    | user_id | page_id | friends_likes |\n",
    "    +---------+---------+---------------+\n",
    "    | 1       | 77      | 2             |\n",
    "    | 1       | 23      | 1             |\n",
    "    | 1       | 24      | 1             |\n",
    "    | 1       | 56      | 1             |\n",
    "    | 1       | 33      | 1             |\n",
    "    | 2       | 24      | 1             |\n",
    "    | 2       | 56      | 1             |\n",
    "    | 2       | 11      | 1             |\n",
    "    | 2       | 88      | 1             |\n",
    "    | 3       | 88      | 1             |\n",
    "    | 3       | 23      | 1             |\n",
    "    | 4       | 88      | 1             |\n",
    "    | 4       | 77      | 1             |\n",
    "    | 4       | 23      | 1             |\n",
    "    | 5       | 77      | 1             |\n",
    "    | 5       | 23      | 1             |\n",
    "    +---------+---------+---------------+\n",
    "    \n",
    "Explanation: \n",
    "\n",
    "Take user 1 as an example:\n",
    "  - User 1 is friends with users 2, 3, 4, and 6.\n",
    "  - Recommended pages are 23 (user 2 liked it), 24 (user 3 liked it), 56 (user 3 liked it), 33 (user 6 liked it), and 77 (user 2 and user 3 liked it).\n",
    "  - Note that page 88 is not recommended because user 1 already liked it.\n",
    "\n",
    "Another example is user 6:\n",
    "  - User 6 is friends with user 1.\n",
    "  - User 1 only liked page 88, but user 6 already liked it. Hence, user 6 has no recommendations.\n",
    "\n",
    "You can recommend pages for users 2, 3, 4, and 5 using a similar process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2115a566",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your MySQL query statement below\n",
    "SELECT user1_id as user_id,page_id,COUNT(user_id) as friends_likes\n",
    "FROM\n",
    "(\n",
    "    SELECT a.user1_id,b.user_id,b.page_id # user, all user friends, page_id\n",
    "    FROM Friendship as a\n",
    "    JOIN Likes as b\n",
    "    ON a.user2_id=b.user_id\n",
    "    UNION SELECT a.user2_id,b.user_id,b.page_id\n",
    "    FROM Friendship as a\n",
    "    JOIN Likes as b\n",
    "    ON a.user1_id=b.user_id\n",
    ") a\n",
    "WHERE CONCAT(user1_id,\",\",page_id) NOT IN\n",
    "(SELECT CONCAT(user_id,\",\",page_id) FROM Likes)\n",
    "GROUP BY user1_id,page_id;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92fdc241",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write your PostgreSQL query statement below\n",
    "SELECT user1_id AS user_id, page_id, COUNT(user_id) AS friends_likes\n",
    "FROM (\n",
    "    SELECT a.user1_id, b.user_id, b.page_id   \n",
    "    FROM Friendship AS a\n",
    "    JOIN Likes AS b ON a.user2_id = b.user_id\n",
    "    UNION\n",
    "    SELECT a.user2_id, b.user_id, b.page_id\n",
    "    FROM Friendship AS a\n",
    "    JOIN Likes AS b ON a.user1_id = b.user_id\n",
    ") AS a\n",
    "WHERE user1_id || ',' || page_id NOT IN (\n",
    "    SELECT user_id || ',' || page_id FROM Likes\n",
    ")\n",
    "GROUP BY user1_id, page_id;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56fa2b1c",
   "metadata": {},
   "source": [
    "Breakdown of the SQL Query\n",
    "\n",
    "Selecting the Required Columns:\n",
    "\n",
    "    The query selects user1_id (aliased as user_id), page_id, and counts the number of friends who liked each page using COUNT(user_id) (aliased as friends_likes). This provides the necessary output structure for the recommendations.\n",
    "    \n",
    "Inner Query (Union of Friendships and Likes):\n",
    "\n",
    "    The inner query performs two JOIN operations between the Friendship table (aliased as a) and the Likes table (aliased as b):\n",
    "        The first SELECT statement joins where user2_id from the Friendship table matches the user_id from the Likes table, capturing pages liked by friends of user1_id.\n",
    "        The second SELECT statement does the opposite, joining on user1_id to include the cases where user2_id is the friend of the user.\n",
    "    The use of UNION ensures that all unique combinations of users, their friends, and the pages liked are captured.\n",
    "    \n",
    "Filtering Out Liked Pages:\n",
    "\n",
    "    The WHERE clause filters the results to exclude any page that the user (represented by user1_id) has already liked. It does this by checking if the combination of user1_id and page_id is present in the Likes table using a NOT IN subquery.\n",
    "    The CONCAT function is used to create a unique identifier for each user-page combination, simplifying the comparison.\n",
    "    \n",
    "Grouping and Counting:\n",
    "\n",
    "    The GROUP BY user1_id, page_id clause aggregates the results by user and page, allowing the COUNT(user_id) to calculate the number of friends who liked each recommended page.\n",
    "    This step summarizes how many friends of each user liked each page, forming the basis of the recommendations.\n",
    "\n",
    "Example Explanation\n",
    "Using the provided data:\n",
    "\n",
    "For User 1:\n",
    "\n",
    "    Friends: User 2, 3, 4, 6\n",
    "    Recommended pages:\n",
    "    Page 23 (liked by User 2)\n",
    "    Page 24 (liked by User 3)\n",
    "    Page 56 (liked by User 4)\n",
    "    Page 33 (liked by User 6)\n",
    "    Page 77 (liked by User 2 and User 3)\n",
    "    Not recommended: Page 88 (liked by User 1)\n",
    "For User 6:\n",
    "\n",
    "    Friends: User 1\n",
    "    No recommendations, as User 1's only liked page (88) is already liked by User 6.\n",
    "\n",
    "Edge Cases Considered\n",
    "\n",
    "    No Friendships: If there are no entries in the Friendship table, the output will be empty, as no recommendations can be made.\n",
    "    No Likes: If the Likes table has no entries for a user, they will not receive any recommendations, resulting in an empty output for that user.\n",
    "    Mutual Likes: If a user and their friend have mutual likes on certain pages, those pages won't appear in the recommendations, ensuring that the system suggests only unliked pages.\n",
    "    Multiple Likes for a Page: If multiple friends like the same page, the count will correctly reflect the total number of friends who liked that page.\n",
    "    \n",
    "Complexity Analysis\n",
    "\n",
    "    Time Complexity: The time complexity of this query is approximately O(N + M), where N is the number of friendships and M is the number of likes. The UNION operation processes both tables, and the GROUP BY operation aggregates the results.\n",
    "    Space Complexity: The space complexity is O(P), where P is the number of unique pages being recommended. The intermediate results will occupy memory based on the size of the result set, which is determined by the number of user-page combinations generated from the friends' likes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b33da400",
   "metadata": {},
   "source": [
    "# Finding the Topic of Each Post\n",
    " \n",
    "Table: Keywords\n",
    "\n",
    "    +-------------+---------+\n",
    "    | Column Name | Type    |\n",
    "    +-------------+---------+\n",
    "    | topic_id    | int     |\n",
    "    | word        | varchar |\n",
    "    +-------------+---------+\n",
    "    (topic_id, word) is the primary key (combination of columns with unique values) for this table.\n",
    "    Each row of this table contains the id of a topic and a word that is used to express this topic.\n",
    "    There may be more than one word to express the same topic and one word may be used to express multiple topics.\n",
    "\n",
    "\n",
    "Table: Posts\n",
    "\n",
    "    +-------------+---------+\n",
    "    | Column Name | Type    |\n",
    "    +-------------+---------+\n",
    "    | post_id     | int     |\n",
    "    | content     | varchar |\n",
    "    +-------------+---------+\n",
    "    post_id is the primary key (column with unique values) for this table.\n",
    "    Each row of this table contains the ID of a post and its content.\n",
    "    Content will consist only of English letters and spaces.\n",
    " \n",
    "\n",
    "    Leetcode has collected some posts from its social media website and is interested in finding the topics of each post. Each topic can be expressed by one or more keywords. If a keyword of a certain topic exists in the content of a post (case insensitive) then the post has this topic.\n",
    "\n",
    "    Write a solution to find the topics of each post according to the following rules:\n",
    "\n",
    "    If the post does not have keywords from any topic, its topic should be \"Ambiguous!\".\n",
    "    If the post has at least one keyword of any topic, its topic should be a string of the IDs of its topics sorted in ascending order and separated by commas ','. The string should not contain duplicate IDs.\n",
    "    Return the result table in any order.\n",
    "\n",
    "The result format is in the following example.\n",
    "\n",
    " \n",
    "\n",
    "Example 1:\n",
    "\n",
    "Input: \n",
    "Keywords table:\n",
    "\n",
    "    +----------+----------+\n",
    "    | topic_id | word     |\n",
    "    +----------+----------+\n",
    "    | 1        | handball |\n",
    "    | 1        | football |\n",
    "    | 3        | WAR      |\n",
    "    | 2        | Vaccine  |\n",
    "    +----------+----------+\n",
    "    \n",
    "Posts table:\n",
    "\n",
    "    +---------+------------------------------------------------------------------------+\n",
    "    | post_id | content                                                                |\n",
    "    +---------+------------------------------------------------------------------------+\n",
    "    | 1       | We call it soccer They call it football hahaha                         |\n",
    "    | 2       | Americans prefer basketball while Europeans love handball and football |\n",
    "    | 3       | stop the war and play handball                                         |\n",
    "    | 4       | warning I planted some flowers this morning and then got vaccinated    |\n",
    "    +---------+------------------------------------------------------------------------+\n",
    "Output: \n",
    "\n",
    "    +---------+------------+\n",
    "    | post_id | topic      |\n",
    "    +---------+------------+\n",
    "    | 1       | 1          |\n",
    "    | 2       | 1          |\n",
    "    | 3       | 1,3        |\n",
    "    | 4       | Ambiguous! |\n",
    "    +---------+------------+\n",
    "    \n",
    "Explanation: \n",
    "\n",
    "    1: \"We call it soccer They call it football hahaha\"\n",
    "    \"football\" expresses topic 1. There is no other word that expresses any other topic.\n",
    "\n",
    "    2: \"Americans prefer basketball while Europeans love handball and football\"\n",
    "    \"handball\" expresses topic 1. \"football\" expresses topic 1. \n",
    "    There is no other word that expresses any other topic.\n",
    "\n",
    "    3: \"stop the war and play handball\"\n",
    "    \"war\" expresses topic 3. \"handball\" expresses topic 1.\n",
    "    There is no other word that expresses any other topic.\n",
    "\n",
    "    4: \"warning I planted some flowers this morning and then got vaccinated\"\n",
    "    There is no word in this sentence that expresses any topic. Note that \"warning\" is different from \"war\" although they have a common prefix. \n",
    "    This post is ambiguous.\n",
    "\n",
    "    Note that it is okay to have one word that expresses more than one topic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f7d3705",
   "metadata": {},
   "outputs": [],
   "source": [
    "SELECT \n",
    "    P.post_id, \n",
    "    IFNULL(GROUP_CONCAT(DISTINCT K.topic_id ORDER BY K.topic_id), 'Ambiguous!') AS topic\n",
    "FROM Posts AS P\n",
    "LEFT JOIN Keywords AS K\n",
    "ON CONCAT(' ', LOWER(P.content), ' ') LIKE CONCAT('% ', LOWER(K.word), ' %')\n",
    "GROUP BY P.post_id;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebc41816",
   "metadata": {},
   "source": [
    "Breakdown of the MySQL Query\n",
    "\n",
    "Selecting Required Columns:\n",
    "\n",
    "    The query selects P.post_id from the Posts table.\n",
    "    The topic column is derived from the GROUP_CONCAT function, which concatenates distinct topic_ids associated with each post.\n",
    "    \n",
    "Handling Topics with IFNULL:\n",
    "\n",
    "    The IFNULL function is used to return 'Ambiguous!' if there are no topic_ids found for a post. This ensures that posts without any matching keywords clearly indicate ambiguity.\n",
    "\n",
    "Joining Keywords with Posts:\n",
    "\n",
    "    A LEFT JOIN connects the Posts table (P) with the Keywords table (K).\n",
    "    The join condition uses a LIKE statement to match keywords in a case-insensitive manner. The CONCAT function adds spaces around both the post content and the keyword, ensuring that only whole words are matched (e.g., it prevents partial matches like 'hand' in 'handball').\n",
    "    \n",
    "Grouping and Concatenating Results:\n",
    "\n",
    "    The results are grouped by P.post_id, ensuring that each post appears only once in the output.\n",
    "    GROUP_CONCAT(DISTINCT K.topic_id ORDER BY K.topic_id) is used to combine multiple topic IDs into a single string, ordered by topic_id.\n",
    "    \n",
    "Explanation of Edge Cases and Complexity Analysis\n",
    "\n",
    "Edge Cases Considered:\n",
    "\n",
    "    No Keywords Match: If a post contains no keywords from the Keywords table, the IFNULL function ensures that the output will be 'Ambiguous!'.\n",
    "    Multiple Topics: If a post contains keywords that map to different topics, all distinct topic IDs will be concatenated and returned.\n",
    "    Non-distinct Keywords: If a post includes multiple instances of the same keyword, they will only be counted once due to the use of DISTINCT in GROUP_CONCAT.\n",
    "\n",
    "Complexity Analysis:\n",
    "\n",
    "    Time Complexity: The time complexity is approximately O(M * N), where M is the number of posts and N is the number of keywords. This complexity arises from the need to check each keyword against the content of each post.\n",
    "    Space Complexity: The space complexity is O(P + K), where P is the number of posts and K is the number of unique topic IDs that might need to be stored in memory for concatenation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f99c6b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your PostgreSQL query statement below\n",
    "\n",
    "with words as (\n",
    "    Select\n",
    "    post_id,\n",
    "    unnest(string_to_array(lower(content),' ')) as content\n",
    "    from\n",
    "    Posts\n",
    "),\n",
    "valid as (\n",
    "    Select distinct\n",
    "    post_id, \n",
    "    topic_id\n",
    "    from\n",
    "    words w \n",
    "    left join keywords kw on w.content = lower(kw.word)\n",
    "    order by post_id, topic_id\n",
    "),\n",
    "combine as \n",
    "(\n",
    "    Select \n",
    "    post_id,\n",
    "    string_agg(topic_id::text,',') as topic\n",
    "    from \n",
    "    valid\n",
    "    group by post_id\n",
    ")\n",
    "select\n",
    "post_id,\n",
    "case when topic is null then 'Ambiguous!'\n",
    "else topic end as topic\n",
    "from\n",
    "combine\n",
    "order by post_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25397ce7",
   "metadata": {},
   "source": [
    "Explanation of the Query\n",
    "\n",
    "This query determines relevant topics for each post based on keyword matches within the post content. It’s structured in multiple Common Table Expressions (CTEs) to break down each transformation and aggregation step.\n",
    "\n",
    "words CTE:\n",
    "\n",
    "    Purpose: Split each post's content into individual words (lowercased) so that they can be matched with keywords.\n",
    "    Operation: unnest(string_to_array(...)) splits the content into an array of words, then unnests them into separate rows for each post_id.\n",
    "    Complexity: Assuming there are n posts and each post has an average of m words, this step has O(n * m) complexity due to unnesting each word in each post.\n",
    "\n",
    "valid CTE:\n",
    "\n",
    "    Purpose: Identify valid topic matches by joining the words from each post with keywords.\n",
    "    Operation: A LEFT JOIN between words and keywords is performed to find matches between the lowercased word and the keywords.\n",
    "    Complexity: For k keywords and n * m rows from words, the join has approximately O((n * m) * k) complexity, assuming no indexing optimizations.\n",
    "    \n",
    "Output: Produces distinct combinations of post_id and topic_id, ensuring that each relevant topic for a post appears only once.\n",
    "\n",
    "combine CTE:\n",
    "\n",
    "    Purpose: Aggregate topic IDs for each post_id into a single comma-separated string.\n",
    "    Operation: Uses STRING_AGG to concatenate the distinct topic_ids for each post_id.\n",
    "    Complexity: Since combine processes O(n) post IDs and aggregates topics per post, the complexity here is roughly O(n).\n",
    "Final SELECT Statement:\n",
    "\n",
    "    Purpose: Produce the final output where each post_id has either a list of associated topics or the label \"Ambiguous!\" if no topics were found.\n",
    "    Operation: Uses a CASE statement to replace NULL topic lists with \"Ambiguous!\".\n",
    "    Complexity: This step is O(n) as it scans each post ID to check for NULL values.\n",
    "    Complexity Summary\n",
    "    The overall time complexity of the query is dominated by the valid CTE join, giving an approximate total complexity of O(n * m * k).\n",
    "\n",
    "Edge Cases\n",
    "\n",
    "No Keywords Match a Post:\n",
    "\n",
    "    If a post contains no words that match any keywords, it will have no topic_id in the valid CTE, and the final output will show \"Ambiguous!\" for that post_id.\n",
    "Case Sensitivity:\n",
    "\n",
    "    All comparisons are case-insensitive due to the use of LOWER() on both content and keywords. This prevents case mismatches from affecting the output.\n",
    "Empty Content:\n",
    "\n",
    "    Posts with empty content fields will have no rows generated in words and will ultimately appear as \"Ambiguous!\" in the final output.\n",
    "Multiple Matches per Post:\n",
    "\n",
    "    Posts containing multiple Tinstances of the same keyword still show only one instance per topic due to the use of DISTINCT in the valid CTE. his avoids duplicate topic_ids in the final list.\n",
    "No Topics in Keywords Table:\n",
    "\n",
    "    If the keywords table is empty, all posts will be marked as \"Ambiguous!\" since no matches can occur.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae8cc892",
   "metadata": {},
   "source": [
    "# Number of Comments per Post\n",
    " \n",
    "Table: Submissions\n",
    "\n",
    "    +---------------+----------+\n",
    "    | Column Name   | Type     |\n",
    "    +---------------+----------+\n",
    "    | sub_id        | int      |\n",
    "    | parent_id     | int      |\n",
    "    +---------------+----------+\n",
    "This table may have duplicate rows.\n",
    "Each row can be a post or comment on the post.\n",
    "parent_id is null for posts.\n",
    "parent_id for comments is sub_id for another post in the table.\n",
    " \n",
    "\n",
    "Write a solution to find the number of comments per post. The result table should contain post_id and its corresponding number_of_comments.\n",
    "\n",
    "The Submissions table may contain duplicate comments. You should count the number of unique comments per post.\n",
    "\n",
    "The Submissions table may contain duplicate posts. You should treat them as one post.\n",
    "\n",
    "The result table should be ordered by post_id in ascending order.\n",
    "\n",
    "The result format is in the following example.\n",
    "\n",
    " \n",
    "\n",
    "Example 1:\n",
    "\n",
    "Input: \n",
    "Submissions table:\n",
    "\n",
    "    +---------+------------+\n",
    "    | sub_id  | parent_id  |\n",
    "    +---------+------------+\n",
    "    | 1       | Null       |\n",
    "    | 2       | Null       |\n",
    "    | 1       | Null       |\n",
    "    | 12      | Null       |\n",
    "    | 3       | 1          |\n",
    "    | 5       | 2          |\n",
    "    | 3       | 1          |\n",
    "    | 4       | 1          |\n",
    "    | 9       | 1          |\n",
    "    | 10      | 2          |\n",
    "    | 6       | 7          |\n",
    "    +---------+------------+\n",
    "Output: \n",
    "\n",
    "    +---------+--------------------+\n",
    "    | post_id | number_of_comments |\n",
    "    +---------+--------------------+\n",
    "    | 1       | 3                  |\n",
    "    | 2       | 2                  |\n",
    "    | 12      | 0                  |\n",
    "    +---------+--------------------+\n",
    "Explanation: \n",
    "The post with id 1 has three comments in the table with id 3, 4, and 9. The comment with id 3 is repeated in the table, we counted it only once.\n",
    "The post with id 2 has two comments in the table with id 5 and 10.\n",
    "The post with id 12 has no comments in the table.\n",
    "The comment with id 6 is a comment on a deleted post with id 7 so we ignored it.\n",
    "\n",
    "Explanation\n",
    "\n",
    "Identify Unique Posts:\n",
    "\n",
    "    The unique_posts CTE extracts unique parent_ids to find posts that have comments. We filter out any NULL values, ensuring that we only consider valid posts.\n",
    "    \n",
    "Count Unique Comments:\n",
    "\n",
    "    The comment_counts CTE counts the unique comments associated with each post (via parent_id). We ensure to count distinct comments using COUNT(DISTINCT sub_id), grouping the results by parent_id.\n",
    "    \n",
    "Post Identification:\n",
    "\n",
    "    The primary selection now directly generates unique post IDs by selecting distinct sub_ids from the Submissions table where parent_id is NULL. This ensures we are considering only those IDs that represent posts, which corresponds to the expected output structure.\n",
    "    \n",
    "Combine Results:\n",
    "\n",
    "    A LEFT JOIN is performed between the unique post IDs and the comment counts. The COALESCE function is used to return 0 for posts with no comments.\n",
    "    \n",
    "Order Results:\n",
    "\n",
    "    Finally, results are ordered by post_id in ascending order.\n",
    "    \n",
    "Edge Cases\n",
    "\n",
    "    Posts with No Comments: Posts without any comments (e.g., post_id 12) should appear with a count of 0.\n",
    "    Handling Duplicate Comments: The counting should ensure that if multiple identical comments are associated with a post, they are counted only once.\n",
    "    Null Parent IDs: The query must correctly filter out NULL values from the parent_id column to focus solely on valid posts.\n",
    "    \n",
    "Complexity Analysis\n",
    "\n",
    "    Time Complexity: The revised solution maintains a time complexity of O(n + m), where n is the number of rows in the Submissions table and m is the number of unique posts. The key operations include:\n",
    "        Extracting unique parent_ids and counting distinct sub_ids.\n",
    "        Joining the results to aggregate comments.\n",
    "        Space Complexity: The space complexity is O(m + k), where m is the number of unique posts and k is the number of unique comments stored in the temporary structures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17833fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "-- Write your PostgreSQL query statement below\n",
    "WITH unique_posts AS (\n",
    "    SELECT DISTINCT parent_id AS post_id\n",
    "    FROM Submissions\n",
    "    WHERE parent_id IS NOT NULL\n",
    "),\n",
    "comment_counts AS (\n",
    "    SELECT parent_id AS post_id, COUNT(DISTINCT sub_id) AS number_of_comments\n",
    "    FROM Submissions\n",
    "    WHERE parent_id IS NOT NULL\n",
    "    GROUP BY parent_id\n",
    ")\n",
    "SELECT \n",
    "    p.post_id,\n",
    "    COALESCE(c.number_of_comments, 0) AS number_of_comments\n",
    "FROM \n",
    "    (SELECT DISTINCT sub_id AS post_id FROM Submissions WHERE parent_id IS NULL) p\n",
    "LEFT JOIN \n",
    "    comment_counts c ON p.post_id = c.post_id\n",
    "ORDER BY \n",
    "    p.post_id;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae7c9966",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your MySQL query statement below\n",
    "WITH unique_posts AS (\n",
    "    SELECT DISTINCT parent_id AS post_id\n",
    "    FROM Submissions\n",
    "    WHERE parent_id IS NOT NULL\n",
    "),\n",
    "comment_counts AS (\n",
    "    SELECT parent_id AS post_id, COUNT(DISTINCT sub_id) AS number_of_comments\n",
    "    FROM Submissions\n",
    "    WHERE parent_id IS NOT NULL\n",
    "    GROUP BY parent_id\n",
    ")\n",
    "SELECT \n",
    "    p.post_id,\n",
    "    COALESCE(c.number_of_comments, 0) AS number_of_comments\n",
    "FROM \n",
    "    (SELECT DISTINCT sub_id AS post_id FROM Submissions WHERE parent_id IS NULL) p\n",
    "LEFT JOIN \n",
    "    comment_counts c ON p.post_id = c.post_id\n",
    "ORDER BY \n",
    "    p.post_id;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae5bd43",
   "metadata": {},
   "source": [
    "# Strong Friendship\n",
    " \n",
    "Table: Friendship\n",
    "\n",
    "    +-------------+------+\n",
    "    | Column Name | Type |\n",
    "    +-------------+------+\n",
    "    | user1_id    | int  |\n",
    "    | user2_id    | int  |\n",
    "    +-------------+------+\n",
    "    (user1_id, user2_id) is the primary key (combination of columns with unique values) for this table.\n",
    "    Each row of this table indicates that the users user1_id and user2_id are friends.\n",
    "    Note that user1_id < user2_id.\n",
    " \n",
    "\n",
    "    A friendship between a pair of friends x and y is strong if x and y have at least three common friends.\n",
    "\n",
    "    Write a solution to find all the strong friendships.\n",
    "\n",
    "    Note that the result table should not contain duplicates with user1_id < user2_id.\n",
    "\n",
    "    Return the result table in any order.\n",
    "\n",
    "    The result format is in the following example.\n",
    "\n",
    " \n",
    "\n",
    "Example 1:\n",
    "\n",
    "Input: \n",
    "Friendship table:\n",
    "\n",
    "    +----------+----------+\n",
    "    | user1_id | user2_id |\n",
    "    +----------+----------+\n",
    "    | 1        | 2        |\n",
    "    | 1        | 3        |\n",
    "    | 2        | 3        |\n",
    "    | 1        | 4        |\n",
    "    | 2        | 4        |\n",
    "    | 1        | 5        |\n",
    "    | 2        | 5        |\n",
    "    | 1        | 7        |\n",
    "    | 3        | 7        |\n",
    "    | 1        | 6        |\n",
    "    | 3        | 6        |\n",
    "    | 2        | 6        |\n",
    "    +----------+----------+\n",
    "Output: \n",
    "\n",
    "    +----------+----------+---------------+\n",
    "    | user1_id | user2_id | common_friend |\n",
    "    +----------+----------+---------------+\n",
    "    | 1        | 2        | 4             |\n",
    "    | 1        | 3        | 3             |\n",
    "    +----------+----------+---------------+\n",
    "\n",
    "Explanation: \n",
    "\n",
    "    Users 1 and 2 have 4 common friends (3, 4, 5, and 6).\n",
    "    Users 1 and 3 have 3 common friends (2, 6, and 7).\n",
    "    We did not include the friendship of users 2 and 3 because they only have two common friends (1 and 6).\n",
    "    \n",
    "\n",
    "This SQL code is designed to find pairs of users who are friends and share at least three common friends. Below is an explanation of the code, including ideas, steps, edge cases, and complexity analysis.\n",
    "\n",
    "Explanation of the Code\n",
    "\n",
    "Common Table Expression (CTE) f:\n",
    " \n",
    "    The CTE f generates a list of friendships by selecting user pairs from the Friendship table.\n",
    "    The first query retrieves user1_id and user2_id directly, while the second query reverses the order, ensuring that friendships are bidirectional (i.e., friendship between user1 and user2 is represented both as (user1, user2) and (user2, user1)).\n",
    "    \n",
    "Main Query:\n",
    " \n",
    "    This part selects user pairs from the original Friendship table (a).\n",
    "    It joins the CTE f to find pairs of friends and their corresponding common friends.\n",
    "    The join conditions:\n",
    "        The first join (f b) finds friends of user1_id.\n",
    "        The second join (f c) matches user2_id with the second user's friends.\n",
    "    The count(c.user2_id) counts the common friends between user1 and user2.\n",
    "    Finally, it groups results by user pairs and filters for those pairs having at least three common friends using the HAVING clause.\n",
    "    \n",
    "Ideas\n",
    "\n",
    "    The purpose of this query is to identify friendships with a significant connection through mutual friends, which can be useful for social network analysis, recommendations, or understanding user connectivity in social platforms.\n",
    "    The approach leverages SQL's ability to handle sets and joins to efficiently determine relationships between data points.\n",
    "    \n",
    "Steps to Execute the Query\n",
    "\n",
    "    Define the common friends using a CTE to normalize the friendship data.\n",
    "    Join the friendship data back to the CTE to find pairs of friends and their common friends.\n",
    "    Count the number of common friends for each pair.\n",
    "    Filter the results to only include pairs with three or more common friends.\n",
    "    \n",
    "Edge Cases\n",
    "\n",
    "    No Common Friends: If no pairs have at least three common friends, the result will be an empty set.\n",
    "    Self-Friendships: If a user is listed as their own friend, this could affect counts if not handled correctly (typically, self-references should be excluded).\n",
    "    Duplicate Entries: If the Friendship table contains duplicate entries for the same friendship, this could inflate the count of common friends unless distinct pairs are ensured.\n",
    "    Zero Friendship Records: If there are no entries in the Friendship table, the query will return an empty result set.\n",
    "Complexity Analysis\n",
    "\n",
    "Time Complexity: The complexity mainly arises from the joins and the counting of common friends. Assuming n is the number of rows in the Friendship table:\n",
    "\n",
    "    The CTE f will create approximately 2n rows.\n",
    "    The joins could lead to n^2 complexity in the worst case (if every user is friends with every other user).\n",
    "    The final grouping and counting will also contribute to complexity, leading to an overall time complexity of O(n^ 2) in the worst-case scenario.\n",
    "\n",
    "Space Complexity: The CTE f uses space proportional to the number of friendships (up to 2n rows), plus additional space for the join results. Thus, space complexity can also reach  O(n)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d2828c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your MySQL/postgresSQL query statement below\n",
    "with f as (\n",
    "    select user1_id, user2_id \n",
    "    from Friendship\n",
    "    \n",
    "    union \n",
    "    \n",
    "    select user2_id user1_id, user1_id user2_id\n",
    "    from Friendship\n",
    ")\n",
    "\n",
    "select a.user1_id, a.user2_id, count(c.user2_id) common_friend\n",
    "from Friendship a \n",
    "join f b \n",
    "on a.user1_id = b.user1_id  \n",
    "join f c \n",
    "on a.user2_id = c.user1_id  \n",
    "and b.user2_id = c.user2_id  \n",
    "group by a.user1_id, a.user2_id\n",
    "having count(c.user2_id) >= 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4153673a",
   "metadata": {},
   "source": [
    "# Fix Names in a Table\n",
    " \n",
    "Table: Users\n",
    "\n",
    "    +----------------+---------+\n",
    "    | Column Name    | Type    |\n",
    "    +----------------+---------+\n",
    "    | user_id        | int     |\n",
    "    | name           | varchar |\n",
    "    +----------------+---------+\n",
    "user_id is the primary key (column with unique values) for this table.\n",
    "This table contains the ID and the name of the user. The name consists of only lowercase and uppercase characters.\n",
    " \n",
    "\n",
    "Write a solution to fix the names so that only the first character is uppercase and the rest are lowercase.\n",
    "\n",
    "Return the result table ordered by user_id.\n",
    "\n",
    "The result format is in the following example.\n",
    "\n",
    " \n",
    "\n",
    "Example 1:\n",
    "\n",
    "Input: \n",
    "Users table:\n",
    "    \n",
    "    +---------+-------+\n",
    "    | user_id | name  |\n",
    "    +---------+-------+\n",
    "    | 1       | aLice |\n",
    "    | 2       | bOB   |\n",
    "    +---------+-------+\n",
    "Output: \n",
    "\n",
    "    +---------+-------+\n",
    "    | user_id | name  |\n",
    "    +---------+-------+\n",
    "    | 1       | Alice |\n",
    "    | 2       | Bob   |\n",
    "    +---------+-------+\n",
    "    \n",
    "Explanation\n",
    "\n",
    "    UPPER(SUBSTRING(name, 1, 1)): This part of the query takes the first character of the name and converts it to uppercase.\n",
    "\n",
    "    SUBSTRING(name, 1, 1) extracts the first character of the name.\n",
    "    LOWER(SUBSTRING(name, 2)): This converts the rest of the name to lowercase.\n",
    "\n",
    "    SUBSTRING(name, 2) extracts the substring starting from the second character to the end.\n",
    "    CONCAT(...): This function combines the uppercase first character with the lowercase substring to form the corrected name.\n",
    "\n",
    "    ORDER BY user_id: Finally, the results are ordered by the user_id to meet the specified output format.\n",
    "    \n",
    "Edge Cases\n",
    "\n",
    "    Empty Strings: If the name field is an empty string (''), the query should handle it gracefully. The output should remain an empty string.\n",
    "    Null Values: If there are NULL values in the name column, the query should ensure that these are handled properly. The result could return NULL for those entries.\n",
    "    Single Character Names: Names consisting of a single character (e.g., 'a', 'b') should be transformed correctly to 'A', 'B'.\n",
    "    Names Already Correctly Formatted: If names are already in the correct format (e.g., 'Alice', 'Bob'), the query should leave them unchanged.\n",
    "    Leading/Trailing Spaces: Names with leading or trailing whitespace (e.g., ' Alice ' or 'Bob ') should ideally be trimmed. You may want to include a TRIM() function to handle this.\n",
    "    Case Variations: Names with unusual casing (e.g., 'aLiCe', 'bOB', or even mixed case like 'AlIce') should all be transformed to the proper format.\n",
    "    \n",
    "Complexity Analysis\n",
    "\n",
    "Time Complexity:\n",
    "\n",
    "    The time complexity for this query is generally O(n), where n is the number of rows in the Users table. This is because the query processes each row to apply the string functions.\n",
    "    Each string manipulation (like SUBSTRING, UPPER, and LOWER) generally operates in constant time with respect to the length of the string. Therefore, the overall complexity remains linear with respect to the number of rows.\n",
    "Space Complexity:\n",
    "\n",
    "    The space complexity is O(n) for the output, where n is again the number of rows in the Users table. This is due to the need to store the transformed names for each user in the result set.\n",
    "    If the database engine uses temporary storage for intermediate results, that might also contribute to additional space usage, but it is typically bounded by the size of the output."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e410d15a",
   "metadata": {},
   "source": [
    "Average Time of Process per Machine\n",
    " \n",
    "Table: Activity\n",
    "\n",
    "    +----------------+---------+\n",
    "    | Column Name    | Type    |\n",
    "    +----------------+---------+\n",
    "    | machine_id     | int     |\n",
    "    | process_id     | int     |\n",
    "    | activity_type  | enum    |\n",
    "    | timestamp      | float   |\n",
    "    +----------------+---------+\n",
    "    The table shows the user activities for a factory website.\n",
    "    (machine_id, process_id, activity_type) is the primary key (combination of columns with unique values) of this table.\n",
    "    machine_id is the ID of a machine.\n",
    "    process_id is the ID of a process running on the machine with ID machine_id.\n",
    "    activity_type is an ENUM (category) of type ('start', 'end').\n",
    "    timestamp is a float representing the current time in seconds.\n",
    "    'start' means the machine starts the process at the given timestamp and 'end' means the machine ends the process at the given timestamp.\n",
    "    The 'start' timestamp will always be before the 'end' timestamp for every (machine_id, process_id) pair.\n",
    "    It is guaranteed that each (machine_id, process_id) pair has a 'start' and 'end' timestamp.\n",
    " \n",
    "\n",
    "    There is a factory website that has several machines each running the same number of processes. Write a solution to find the average time each machine takes to complete a process.\n",
    "\n",
    "    The time to complete a process is the 'end' timestamp minus the 'start' timestamp. The average time is calculated by the total time to complete every process on the machine divided by the number of processes that were run.\n",
    "\n",
    "    The resulting table should have the machine_id along with the average time as processing_time, which should be rounded to 3 decimal places.\n",
    "\n",
    "    Return the result table in any order.\n",
    "\n",
    "    The result format is in the following example.\n",
    "\n",
    " \n",
    "\n",
    "Example 1:\n",
    "\n",
    "Input: \n",
    "Activity table:\n",
    "\n",
    "    +------------+------------+---------------+-----------+\n",
    "    | machine_id | process_id | activity_type | timestamp |\n",
    "    +------------+------------+---------------+-----------+\n",
    "    | 0          | 0          | start         | 0.712     |\n",
    "    | 0          | 0          | end           | 1.520     |\n",
    "    | 0          | 1          | start         | 3.140     |\n",
    "    | 0          | 1          | end           | 4.120     |\n",
    "    | 1          | 0          | start         | 0.550     |\n",
    "    | 1          | 0          | end           | 1.550     |\n",
    "    | 1          | 1          | start         | 0.430     |\n",
    "    | 1          | 1          | end           | 1.420     |\n",
    "    | 2          | 0          | start         | 4.100     |\n",
    "    | 2          | 0          | end           | 4.512     |\n",
    "    | 2          | 1          | start         | 2.500     |\n",
    "    | 2          | 1          | end           | 5.000     |\n",
    "    +------------+------------+---------------+-----------+\n",
    "Output: \n",
    "\n",
    "    +------------+-----------------+\n",
    "    | machine_id | processing_time |\n",
    "    +------------+-----------------+\n",
    "    | 0          | 0.894           |\n",
    "    | 1          | 0.995           |\n",
    "    | 2          | 1.456           |\n",
    "    +------------+-----------------+\n",
    "Explanation: \n",
    "\n",
    "    There are 3 machines running 2 processes each.\n",
    "    Machine 0's average time is ((1.520 - 0.712) + (4.120 - 3.140)) / 2 = 0.894\n",
    "    Machine 1's average time is ((1.550 - 0.550) + (1.420 - 0.430)) / 2 = 0.995\n",
    "    Machine 2's average time is ((4.512 - 4.100) + (5.000 - 2.500)) / 2 = 1.456.\n",
    "    \n",
    "Explanation of the Query\n",
    "\n",
    "Inner Subquery:\n",
    "\n",
    "    The inner subquery calculates the start and end timestamps for each process for each machine.\n",
    "    It selects the machine_id and process_id.\n",
    "    The MAX function retrieves the end timestamp for each process (when activity_type is 'end').\n",
    "    The MIN function retrieves the start timestamp for each process (when activity_type is 'start').\n",
    "    The results are grouped by machine_id and process_id to get a unique start and end time for each process.\n",
    "Outer Query:\n",
    "\n",
    "    The outer query computes the average processing time by subtracting the start_time from the end_time.\n",
    "    It rounds the average processing time to three decimal places using the ROUND function.\n",
    "    Finally, it groups the results by machine_id to return the average processing time for each machine.\n",
    "    \n",
    "Edge Cases to Consider\n",
    "\n",
    "    Incomplete Data: If there are processes without corresponding start or end entries, they will not contribute to the average calculation.\n",
    "    Duplicate Entries: Ensure that there are no duplicate entries for the same process that could distort the calculations.\n",
    "    No Processes: If a machine has no recorded processes, it will not appear in the result.\n",
    "    Invalid Timestamps: Define how to handle invalid timestamps, such as negative values or cases where the end timestamp is earlier than the start timestamp.\n",
    "\n",
    "Complexity Analysis\n",
    "\n",
    "Time Complexity:\n",
    "\n",
    "    The time complexity is still O(n), where n is the number of rows in the Activity table. We process each row to calculate the necessary timestamps and averages.\n",
    "\n",
    "Space Complexity:\n",
    "\n",
    "    The space complexity remains O(m), where m is the number of unique processes (or machines) being tracked. This is due to the temporary storage for processing times in the inner subquery before calculating the final averages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be615204",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your MySQL query statement below\n",
    "SELECT \n",
    "    machine_id,\n",
    "    ROUND(AVG(end_time - start_time), 3) AS processing_time\n",
    "FROM (\n",
    "    SELECT \n",
    "        machine_id,\n",
    "        process_id,\n",
    "        MAX(CASE WHEN activity_type = 'end' THEN timestamp END) AS end_time,\n",
    "        MIN(CASE WHEN activity_type = 'start' THEN timestamp END) AS start_time\n",
    "    FROM \n",
    "        Activity\n",
    "    GROUP BY \n",
    "        machine_id, process_id\n",
    ") AS ProcessTimes\n",
    "GROUP BY \n",
    "    machine_id;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7512a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your PostgreSQL query statement below\n",
    "SELECT \n",
    "    machine_id,\n",
    "    ROUND(AVG(end_time - start_time)::decimal, 3) AS processing_time\n",
    "FROM (\n",
    "    SELECT \n",
    "        machine_id,\n",
    "        process_id,\n",
    "        MAX(CASE WHEN activity_type = 'end' THEN timestamp END) AS end_time,\n",
    "        MIN(CASE WHEN activity_type = 'start' THEN timestamp END) AS start_time\n",
    "    FROM \n",
    "        Activity\n",
    "    GROUP BY \n",
    "        machine_id, process_id\n",
    ") AS ProcessTimes\n",
    "GROUP BY \n",
    "    machine_id;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4826e2fe",
   "metadata": {},
   "source": [
    "# ads Performance\n",
    " \n",
    "Table: Ads\n",
    "\n",
    "    +---------------+---------+\n",
    "    | Column Name   | Type    |\n",
    "    +---------------+---------+\n",
    "    | ad_id         | int     |\n",
    "    | user_id       | int     |\n",
    "    | action        | enum    |\n",
    "    +---------------+---------+\n",
    "    (ad_id, user_id) is the primary key (combination of columns with unique values) for this table.\n",
    "    Each row of this table contains the ID of an Ad, the ID of a user, and the action taken by this user regarding this Ad.\n",
    "    The action column is an ENUM (category) type of ('Clicked', 'Viewed', 'Ignored').\n",
    "\n",
    "\n",
    "    A company is running Ads and wants to calculate the performance of each Ad.\n",
    "\n",
    "    Performance of the Ad is measured using Click-Through Rate (CTR) where:\n",
    "\n",
    "    CTR = (Number of Clicks + Number of Views/ Number of Clicks) ×100\n",
    "\n",
    " \n",
    "    Write a solution to find the ctr of each Ad. Round ctr to two decimal points.\n",
    "\n",
    "    Return the result table ordered by ctr in descending order and by ad_id in ascending order in case of a tie.\n",
    "\n",
    "    The result format is in the following example.\n",
    "\n",
    " \n",
    "\n",
    "Example 1:\n",
    "\n",
    "Input: \n",
    "Ads table:\n",
    "\n",
    "    +-------+---------+---------+\n",
    "    | ad_id | user_id | action  |\n",
    "    +-------+---------+---------+\n",
    "    | 1     | 1       | Clicked |\n",
    "    | 2     | 2       | Clicked |\n",
    "    | 3     | 3       | Viewed  |\n",
    "    | 5     | 5       | Ignored |\n",
    "    | 1     | 7       | Ignored |\n",
    "    | 2     | 7       | Viewed  |\n",
    "    | 3     | 5       | Clicked |\n",
    "    | 1     | 4       | Viewed  |\n",
    "    | 2     | 11      | Viewed  |\n",
    "    | 1     | 2       | Clicked |\n",
    "    +-------+---------+---------+\n",
    "Output: \n",
    "\n",
    "    +-------+-------+\n",
    "    | ad_id | ctr   |\n",
    "    +-------+-------+\n",
    "    | 1     | 66.67 |\n",
    "    | 3     | 50.00 |\n",
    "    | 2     | 33.33 |\n",
    "    | 5     | 0.00  |\n",
    "    +-------+-------+\n",
    "Explanation: \n",
    "\n",
    "    for ad_id = 1, ctr = (2/(2+1)) * 100 = 66.67\n",
    "    for ad_id = 2, ctr = (1/(1+2)) * 100 = 33.33\n",
    "    for ad_id = 3, ctr = (1/(1+1)) * 100 = 50.00\n",
    "    for ad_id = 5, ctr = 0.00, Note that ad_id = 5 has no clicks or views.\n",
    "    Note that we do not care about Ignored Ads.\n",
    "    \n",
    "1. Problem Understanding and Key Idea\n",
    "    We need to calculate the click-through rate (CTR) for each ad.\n",
    "    CTR formula: \n",
    "    CTR = (Number of Clicks + Number of Views/ Number of Clicks) ×100\n",
    "    Goal: Output each ad's CTR, ordered by CTR in descending order and by ad_id ascending when CTRs are tied.\n",
    "    \n",
    "2. Steps to Approach the Problem\n",
    "    Step 1: Filter only relevant actions (Clicked and Viewed) because Ignored doesn’t affect CTR.\n",
    "    Step 2: For each ad_id, count the number of Clicked and Viewed actions:\n",
    "        Use CASE statements to count the number of clicks (action = 'Clicked') and views (action = 'Viewed').\n",
    "    Step 3: Calculate CTR by dividing the number of clicks by the sum of clicks and views.\n",
    "    Step 4: Round CTR to two decimal points, and handle division by zero by defaulting CTR to 0 for ads with no views or clicks.\n",
    "    Step 5: Order results by ctr in descending order, then by ad_id in ascending order.\n",
    "    \n",
    "3. SQL Solution\n",
    "    Here’s the SQL query that follows these steps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed3b4bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "SELECT \n",
    "    ad_id,\n",
    "    ROUND(COALESCE(SUM(CASE WHEN action = 'Clicked' THEN 1 ELSE 0 END) * 100.0 /\n",
    "           NULLIF(SUM(CASE WHEN action IN ('Clicked', 'Viewed') THEN 1 ELSE 0 END), 0), 0), 2) AS ctr\n",
    "FROM Ads\n",
    "GROUP BY ad_id\n",
    "ORDER BY ctr DESC, ad_id ASC;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da441575",
   "metadata": {},
   "source": [
    "4. Edge Cases\n",
    "    No Clicked or Viewed Actions: If an ad has no relevant actions, CTR should be 0. This is handled by NULLIF, which avoids division by zero.\n",
    "    Ads with Only Viewed Actions: If an ad has only views but no clicks, CTR should also be 0.\n",
    "    Ads with Only Clicked Actions: If an ad has only clicks, CTR will be 100% (since there are no views to lower it).\n",
    "    Ties in CTR: Multiple ads with the same CTR should be sorted by ad_id in ascending order.\n",
    "    \n",
    "5. Complexity Analysis\n",
    "    Time Complexity: O(N) where N is the number of rows in the Ads table, as we are grouping and aggregating by ad_id.\n",
    "    Space Complexity: O(M) where M is the number of unique ad_ids, as we need space to store counts for each ad.\n",
    "\n",
    "6. Follow-Up Questions\n",
    "\n",
    "    Q1: What if we wanted to track additional metrics for each ad, such as the total number of users who ignored it?\n",
    "    Answer: We could modify the query to include an additional CASE statement to count Ignored actions and return that as a separate column. This would allow us to track all actions (Clicked, Viewed, Ignored) in a single query.\n",
    "\n",
    "    Q2: How would you modify the query if the Ads table were extremely large?\n",
    "    Answer: We could create an index on ad_id and action to improve the performance of grouping and filtering actions. Alternatively, if this calculation needs to be done frequently, storing CTR values in a separate summary table that gets updated periodically (e.g., nightly) would reduce query time.\n",
    "\n",
    "    Q3: How would you handle rounding to more or fewer decimal places?\n",
    "    Answer: We can change the rounding precision by modifying the ROUND function. For example, ROUND(..., 1) for one decimal place or ROUND(..., 3) for three.\n",
    "\n",
    "    Q4: What would happen if there were duplicate rows with the same ad_id, user_id, and action?\n",
    "    Answer: Duplicates could inflate the counts, leading to inaccurate CTR calculations. To prevent this, we could add a DISTINCT clause within the SUM function or ensure data integrity by removing duplicates before aggregation.\n",
    "\n",
    "    Q5: What if the business wants a rolling CTR for each ad (e.g., over the last 7 days)?\n",
    "    Answer: We could add a date column to the Ads table and use it to filter records by date (e.g., WHERE date >= DATE_SUB(CURRENT_DATE, INTERVAL 7 DAY)). This would calculate CTR based on a recent timeframe."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cae8bcc2",
   "metadata": {},
   "source": [
    "# Page Recommendations\n",
    " \n",
    "Table: Friendship\n",
    "\n",
    "    +---------------+---------+\n",
    "    | Column Name   | Type    |\n",
    "    +---------------+---------+\n",
    "    | user1_id      | int     |\n",
    "    | user2_id      | int     |\n",
    "    +---------------+---------+\n",
    "    (user1_id, user2_id) is the primary key (combination of columns with unique values) for this table.\n",
    "    Each row of this table indicates that there is a friendship relation between user1_id and user2_id.\n",
    " \n",
    "\n",
    "Table: Likes\n",
    "\n",
    "    +-------------+---------+\n",
    "    | Column Name | Type    |\n",
    "    +-------------+---------+\n",
    "    | user_id     | int     |\n",
    "    | page_id     | int     |\n",
    "    +-------------+---------+\n",
    "    (user_id, page_id) is the primary key (combination of columns with unique values) for this table.\n",
    "    Each row of this table indicates that user_id likes page_id.\n",
    "\n",
    "\n",
    "    Write a solution to recommend pages to the user with user_id = 1 using the pages that your friends liked. It should not recommend pages you already liked.\n",
    "\n",
    "    Return result table in any order without duplicates.\n",
    "\n",
    "    The result format is in the following example.\n",
    "\n",
    " \n",
    "\n",
    "Example 1:\n",
    "\n",
    "Input: \n",
    "Friendship table:\n",
    "\n",
    "    +----------+----------+\n",
    "    | user1_id | user2_id |\n",
    "    +----------+----------+\n",
    "    | 1        | 2        |\n",
    "    | 1        | 3        |\n",
    "    | 1        | 4        |\n",
    "    | 2        | 3        |\n",
    "    | 2        | 4        |\n",
    "    | 2        | 5        |\n",
    "    | 6        | 1        |\n",
    "    +----------+----------+\n",
    "Likes table:\n",
    "\n",
    "    +---------+---------+\n",
    "    | user_id | page_id |\n",
    "    +---------+---------+\n",
    "    | 1       | 88      |\n",
    "    | 2       | 23      |\n",
    "    | 3       | 24      |\n",
    "    | 4       | 56      |\n",
    "    | 5       | 11      |\n",
    "    | 6       | 33      |\n",
    "    | 2       | 77      |\n",
    "    | 3       | 77      |\n",
    "    | 6       | 88      |\n",
    "    +---------+---------+\n",
    "Output: \n",
    "\n",
    "    +------------------+\n",
    "    | recommended_page |\n",
    "    +------------------+\n",
    "    | 23               |\n",
    "    | 24               |\n",
    "    | 56               |\n",
    "    | 33               |\n",
    "    | 77               |\n",
    "    +------------------+\n",
    "Explanation: \n",
    "\n",
    "    User one is friend with users 2, 3, 4 and 6.\n",
    "    Suggested pages are 23 from user 2, 24 from user 3, 56 from user 3 and 33 from user 6.\n",
    "    Page 77 is suggested from both user 2 and user 3.\n",
    "    Page 88 is not suggested because user 1 already likes it.\n",
    "    \n",
    "    \n",
    "1. Understanding the Relationships\n",
    "    Friendship Table: Indicates who is friends with whom.\n",
    "    Likes Table: Indicates which pages each user likes.\n",
    "    Goal: Find all unique pages liked by friends of user_id = 1, excluding pages that user_id = 1 already likes.\n",
    "2. Steps to Approach the Solution\n",
    "    Step 1: Identify friends of user_id = 1. We need both directions (user1_id and user2_id) in the Friendship table since friendships are bi-directional.\n",
    "    Step 2: Find pages liked by these friends (from the Likes table).\n",
    "    Step 3: Exclude pages that user_id = 1 already likes.\n",
    "3. SQL Solution\n",
    "    The solution joins tables to find recommended pages, then filters out pages already liked by user_id = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081b36e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "WITH Friends AS (\n",
    "    SELECT \n",
    "        CASE \n",
    "            WHEN user1_id = 1 THEN user2_id \n",
    "            ELSE user1_id \n",
    "        END AS friend_id\n",
    "    FROM Friendship\n",
    "    WHERE 1 IN (user1_id, user2_id)\n",
    "),\n",
    "FriendLikes AS (\n",
    "    SELECT DISTINCT \n",
    "        L.page_id\n",
    "    FROM Likes L\n",
    "    JOIN Friends F ON L.user_id = F.friend_id\n",
    "),\n",
    "UserLikes AS (\n",
    "    SELECT \n",
    "        page_id\n",
    "    FROM Likes\n",
    "    WHERE user_id = 1\n",
    ")\n",
    "SELECT \n",
    "    page_id AS recommended_page\n",
    "FROM FriendLikes\n",
    "WHERE page_id NOT IN (SELECT page_id FROM UserLikes);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec8bfe80",
   "metadata": {},
   "source": [
    "Explanation\n",
    "\n",
    "    Friends CTE: Identifies all friends of user_id = 1 by selecting user2_id if user1_id is 1, or user1_id if user2_id is 1.\n",
    "    FriendLikes CTE: Joins Friends with the Likes table to find all pages liked by friends.\n",
    "    UserLikes CTE: Selects pages that user_id = 1 already likes from the Likes table.\n",
    "    Final Query: Selects pages liked by friends (FriendLikes) that are not in UserLikes (i.e., pages that user_id = 1 hasn’t liked).\n",
    "    \n",
    "4. Edge Cases\n",
    "    No Friends: If user_id = 1 has no friends, there will be no recommendations.\n",
    "    Friends with No Likes: If friends haven’t liked any pages, the output will be empty.\n",
    "    All Pages Already Liked: If user_id = 1 has already liked all pages that friends like, there will be no recommendations.\n",
    "    \n",
    "5. Complexity Analysis\n",
    "    Time Complexity: O(F+L), where  F is the number of friendships and L is the number of likes. Each CTE involves scanning or joining tables, but proper indexing on user_id and page_id can optimize performance.\n",
    "    Space Complexity: O(F+L), as we store intermediate CTE results.\n",
    "6. Follow-Up Questions\n",
    "\n",
    "    Q1: What if the user wants recommendations based on only a subset of friends, such as close friends?\n",
    "    Answer: We could add an additional column (e.g., friendship_level) in the Friendship table and filter Friends based on this level.\n",
    "    Q2: How would you handle large datasets for this query?\n",
    "    Answer: Adding indexes on user_id and page_id in both Friendship and Likes tables would improve join performance. For very large datasets, a materialized view or periodic pre-calculated recommendation table could be created.\n",
    "    Q3: What if we need to rank the recommended pages by popularity among friends?\n",
    "    Answer: In FriendLikes, count likes for each page_id and order by the count in descending order."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df70cc51",
   "metadata": {},
   "source": [
    "# Trips and Users\n",
    " \n",
    "Table: Trips\n",
    "\n",
    "    +-------------+----------+\n",
    "    | Column Name | Type     |\n",
    "    +-------------+----------+\n",
    "    | id          | int      |\n",
    "    | client_id   | int      |\n",
    "    | driver_id   | int      |\n",
    "    | city_id     | int      |\n",
    "    | status      | enum     |\n",
    "    | request_at  | varchar  |     \n",
    "    +-------------+----------+\n",
    "    id is the primary key (column with unique values) for this table.\n",
    "    The table holds all taxi trips. Each trip has a unique id, while client_id and driver_id are foreign keys to the users_id at the Users table.\n",
    "    Status is an ENUM (category) type of ('completed', 'cancelled_by_driver', 'cancelled_by_client').\n",
    "\n",
    "\n",
    "Table: Users\n",
    "\n",
    "    +-------------+----------+\n",
    "    | Column Name | Type     |\n",
    "    +-------------+----------+\n",
    "    | users_id    | int      |\n",
    "    | banned      | enum     |\n",
    "    | role        | enum     |\n",
    "    +-------------+----------+\n",
    "    users_id is the primary key (column with unique values) for this table.\n",
    "    The table holds all users. Each user has a unique users_id, and role is an ENUM type of ('client', 'driver', 'partner').\n",
    "    banned is an ENUM (category) type of ('Yes', 'No').\n",
    "\n",
    "\n",
    "    The cancellation rate is computed by dividing the number of canceled (by client or driver) requests with unbanned users by the total number of requests with unbanned users on that day.\n",
    "\n",
    "    Write a solution to find the cancellation rate of requests with unbanned users (both client and driver must not be banned) each day between \"2013-10-01\" and \"2013-10-03\". Round Cancellation Rate to two decimal points.\n",
    "\n",
    "    Return the result table in any order.\n",
    "\n",
    "    The result format is in the following example.\n",
    "\n",
    " \n",
    "\n",
    "Example 1:\n",
    "\n",
    "Input: \n",
    "Trips table:\n",
    "\n",
    "    +----+-----------+-----------+---------+---------------------+------------+\n",
    "    | id | client_id | driver_id | city_id | status              | request_at |\n",
    "    +----+-----------+-----------+---------+---------------------+------------+\n",
    "    | 1  | 1         | 10        | 1       | completed           | 2013-10-01 |\n",
    "    | 2  | 2         | 11        | 1       | cancelled_by_driver | 2013-10-01 |\n",
    "    | 3  | 3         | 12        | 6       | completed           | 2013-10-01 |\n",
    "    | 4  | 4         | 13        | 6       | cancelled_by_client | 2013-10-01 |\n",
    "    | 5  | 1         | 10        | 1       | completed           | 2013-10-02 |\n",
    "    | 6  | 2         | 11        | 6       | completed           | 2013-10-02 |\n",
    "    | 7  | 3         | 12        | 6       | completed           | 2013-10-02 |\n",
    "    | 8  | 2         | 12        | 12      | completed           | 2013-10-03 |\n",
    "    | 9  | 3         | 10        | 12      | completed           | 2013-10-03 |\n",
    "    | 10 | 4         | 13        | 12      | cancelled_by_driver | 2013-10-03 |\n",
    "    +----+-----------+-----------+---------+---------------------+------------+\n",
    "Users table:\n",
    "\n",
    "    +----------+--------+--------+\n",
    "    | users_id | banned | role   |\n",
    "    +----------+--------+--------+\n",
    "    | 1        | No     | client |\n",
    "    | 2        | Yes    | client |\n",
    "    | 3        | No     | client |\n",
    "    | 4        | No     | client |\n",
    "    | 10       | No     | driver |\n",
    "    | 11       | No     | driver |\n",
    "    | 12       | No     | driver |\n",
    "    | 13       | No     | driver |\n",
    "    +----------+--------+--------+\n",
    "Output: \n",
    "\n",
    "    +------------+-------------------+\n",
    "    | Day        | Cancellation Rate |\n",
    "    +------------+-------------------+\n",
    "    | 2013-10-01 | 0.33              |\n",
    "    | 2013-10-02 | 0.00              |\n",
    "    | 2013-10-03 | 0.50              |\n",
    "    +------------+-------------------+\n",
    "Explanation: \n",
    "\n",
    "On 2013-10-01:\n",
    "  - There were 4 requests in total, 2 of which were canceled.\n",
    "  - However, the request with Id=2 was made by a banned client (User_Id=2), so it is ignored in the calculation.\n",
    "  - Hence there are 3 unbanned requests in total, 1 of which was canceled.\n",
    "  - The Cancellation Rate is (1 / 3) = 0.33\n",
    "On 2013-10-02:\n",
    "  - There were 3 requests in total, 0 of which were canceled.\n",
    "  - The request with Id=6 was made by a banned client, so it is ignored.\n",
    "  - Hence there are 2 unbanned requests in total, 0 of which were canceled.\n",
    "  - The Cancellation Rate is (0 / 2) = 0.00\n",
    "On 2013-10-03:\n",
    "  - There were 3 requests in total, 1 of which was canceled.\n",
    "  - The request with Id=8 was made by a banned client, so it is ignored.\n",
    "  - Hence there are 2 unbanned request in total, 1 of which were canceled.\n",
    "  - The Cancellation Rate is (1 / 2) = 0.50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57336245",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your MySQL query statement below\n",
    "select Day, round(canceled/total, 2) as `Cancellation Rate`  from(\n",
    "select request_at as Day, \n",
    "\n",
    "sum(case when a.status like 'cancelled%' then 1 else 0 end) as canceled, count(id) as total\n",
    "\n",
    "from Trips a \n",
    "join Users cl on a.client_id = cl.users_id and cl.banned = \"No\"\n",
    "join Users dr on a.driver_id = dr.users_id and dr.banned = \"No\"\n",
    "where  request_at between '2013-10-01' and '2013-10-03'\n",
    "group by request_at\n",
    ")a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c198505",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write your PostgreSQL query statement below\n",
    "SELECT Day, ROUND(canceled::numeric / total, 2) AS \"Cancellation Rate\"\n",
    "FROM (\n",
    "    SELECT \n",
    "        request_at AS Day, \n",
    "        SUM(CASE WHEN a.status LIKE 'cancelled%' THEN 1 ELSE 0 END) AS canceled, \n",
    "        COUNT(id) AS total\n",
    "    FROM Trips a \n",
    "    JOIN Users cl ON a.client_id = cl.users_id AND cl.banned = 'No'\n",
    "    JOIN Users dr ON a.driver_id = dr.users_id AND dr.banned = 'No'\n",
    "    WHERE request_at BETWEEN '2013-10-01' AND '2013-10-03'\n",
    "    GROUP BY request_at\n",
    ") a;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e145de0",
   "metadata": {},
   "source": [
    "1. Objective\n",
    "    The query calculates the \"Cancellation Rate\" for each day within a specified date range. The \"Cancellation Rate\" is the ratio of canceled trips to the total trips, rounded to two decimal places.\n",
    "    It filters trips to include only those where both the client and driver are not banned.\n",
    "2. Step-by-Step Solution\n",
    "Step 1: Inner Query\n",
    "\n",
    "    Purpose: Aggregate trip data for each day by calculating the total number of trips and the number of canceled trips.\n",
    "\n",
    "    Grouping: We group by request_at to get daily data.\n",
    "\n",
    "    Calculations:\n",
    "\n",
    "    SUM(CASE WHEN a.status LIKE 'cancelled%' THEN 1 ELSE 0 END) AS canceled: Counts canceled trips for each day.\n",
    "    COUNT(id) AS total: Counts total trips for each day.\n",
    "    Filtering: Only trips where both the client (cl.banned = 'No') and driver (dr.banned = 'No') are included.\n",
    "\n",
    "    Date Range: Limits results to trips within '2013-10-01' to '2013-10-03'.\n",
    "\n",
    "Step 2: Outer Query\n",
    "\n",
    "    Purpose: Calculate and format the \"Cancellation Rate\" for each day.\n",
    "    Calculation: ROUND(canceled::numeric / total, 2) AS \"Cancellation Rate\":\n",
    "    Divides canceled by total and casts to numeric to allow rounding.\n",
    "    Rounds to two decimal places for clearer presentation.\n",
    "    Final Selection: Displays the date (Day) and the calculated Cancellation Rate as final columns.\n",
    "3. Edge Cases\n",
    "    No Trips on a Day: If there are no trips on a day within the range, that date won’t appear in the output.\n",
    "    All Trips Canceled: The Cancellation Rate will show as 1.00 if all trips on a day are canceled.\n",
    "    No Canceled Trips: If no trips are canceled on a given day, Cancellation Rate will be 0.00.\n",
    "4. Complexity Analysis\n",
    "    Time Complexity: O(N), where N is the number of records in the specified date range, as each row is scanned and aggregated once.\n",
    "    Space Complexity: O(D), where D is the number of unique dates within the range (due to grouping by request_at).\n",
    "5. Follow-Up Questions\n",
    "    Q1: How would you adapt this query if you needed monthly cancellation rates instead?\n",
    "    Answer: Change GROUP BY request_at to GROUP BY DATE_TRUNC('month', request_at). Adjust the outer query to handle monthly data labels accordingly.\n",
    "    Q2: What if you wanted to exclude trips with null statuses?\n",
    "    Answer: Add a.status IS NOT NULL in the WHERE clause to exclude trips with null statuses from the aggregation.\n",
    "    Q3: How would you optimize the query for large datasets?\n",
    "    Answer: Index request_at, client_id, and driver_id columns to improve join and filter efficiency. Additionally, consider a materialized view for frequently queried date ranges."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4da3e8b",
   "metadata": {},
   "source": [
    "# Product Sales Analysis III\n",
    " \n",
    "Table: Sales\n",
    "\n",
    "    +-------------+-------+\n",
    "    | Column Name | Type  |\n",
    "    +-------------+-------+\n",
    "    | sale_id     | int   |\n",
    "    | product_id  | int   |\n",
    "    | year        | int   |\n",
    "    | quantity    | int   |\n",
    "    | price       | int   |\n",
    "    +-------------+-------+\n",
    "    (sale_id, year) is the primary key (combination of columns with unique values) of this table.\n",
    "    product_id is a foreign key (reference column) to Product table.\n",
    "    Each row of this table shows a sale on the product product_id in a certain year.\n",
    "    Note that the price is per unit.\n",
    "\n",
    "\n",
    "Table: Product\n",
    "\n",
    "    +--------------+---------+\n",
    "    | Column Name  | Type    |\n",
    "    +--------------+---------+\n",
    "    | product_id   | int     |\n",
    "    | product_name | varchar |\n",
    "    +--------------+---------+\n",
    "    product_id is the primary key (column with unique values) of this table.\n",
    "    Each row of this table indicates the product name of each product.\n",
    "\n",
    "\n",
    "    Write a solution to select the product id, year, quantity, and price for the first year of every product sold.\n",
    "\n",
    "    Return the resulting table in any order.\n",
    "\n",
    "    The result format is in the following example.\n",
    "\n",
    " \n",
    "\n",
    "Example 1:\n",
    "\n",
    "Input: \n",
    "Sales table:\n",
    "\n",
    "    +---------+------------+------+----------+-------+\n",
    "    | sale_id | product_id | year | quantity | price |\n",
    "    +---------+------------+------+----------+-------+ \n",
    "    | 1       | 100        | 2008 | 10       | 5000  |\n",
    "    | 2       | 100        | 2009 | 12       | 5000  |\n",
    "    | 7       | 200        | 2011 | 15       | 9000  |\n",
    "    +---------+------------+------+----------+-------+\n",
    "Product table:\n",
    "\n",
    "    +------------+--------------+\n",
    "    | product_id | product_name |\n",
    "    +------------+--------------+\n",
    "    | 100        | Nokia        |\n",
    "    | 200        | Apple        |\n",
    "    | 300        | Samsung      |\n",
    "    +------------+--------------+\n",
    "    \n",
    "Output: \n",
    "\n",
    "    +------------+------------+----------+-------+\n",
    "    | product_id | first_year | quantity | price |\n",
    "    +------------+------------+----------+-------+ \n",
    "    | 100        | 2008       | 10       | 5000  |\n",
    "    | 200        | 2011       | 15       | 9000  |\n",
    "    +------------+------------+----------+-------+\n",
    "    \n",
    "Solution Steps\n",
    "\n",
    "    Identify the First Sale Year: We use a subquery to find the minimum year for each product_id in the Sales table, which gives the earliest year each product was sold.\n",
    "    Join to Retrieve Required Details: Join this result with the original Sales table to retrieve the quantity and price for that year.\n",
    "    Final Selection:  Return the product_id, first_year, quantity, and price as required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a6216c",
   "metadata": {},
   "outputs": [],
   "source": [
    "SELECT \n",
    "    s.product_id,\n",
    "    s.year AS first_year,\n",
    "    s.quantity,\n",
    "    s.price\n",
    "FROM \n",
    "    Sales s\n",
    "JOIN \n",
    "    (SELECT product_id, MIN(year) AS first_year\n",
    "     FROM Sales\n",
    "     GROUP BY product_id) AS first_sale\n",
    "ON \n",
    "    s.product_id = first_sale.product_id\n",
    "    AND s.year = first_sale.first_year;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e86c7f0",
   "metadata": {},
   "source": [
    "Explanation of the Query\n",
    "\n",
    "    Inner Query: The inner query first_sale finds the first sale year for each product_id by using MIN(year) and GROUP BY product_id.\n",
    "    Join Condition: We join the Sales table (s) with the first_sale subquery on both product_id and year to filter only the records that correspond to the first sale year.\n",
    "    Selection: Finally, we select product_id, year (renamed as first_year), quantity, and price for the earliest sale year.\n",
    "    \n",
    "Edge Cases\n",
    "\n",
    "    Products without sales records: These will not appear in the result since they have no data in the Sales table.\n",
    "    Multiple Sales in the Same Year: If there are multiple entries for the same product_id and year, each row will appear, reflecting every sale for that first year.\n",
    "\n",
    " \n",
    "Solution Complexity\n",
    "\n",
    "Time Complexity:\n",
    "\n",
    "    Inner Query: O(N log N) where  N is the number of rows in the Sales table. The GROUP BY and MIN() operations require scanning all records, and the complexity may increase if sorting or hashing is used.\n",
    "    Join Operation: Assuming we join on indexed columns, the join operation is approximately O(N).\n",
    "    Overall, the query is O(N log N) due to the MIN(year) operation in the subquery.\n",
    "\n",
    "Space Complexity:\n",
    "\n",
    "    Intermediate Storage: The subquery result (one row per product_id) is stored temporarily, requiring O(P) space where P is the number of unique product_id entries.\n",
    "    Total space complexity is therefore O(P)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d53804f0",
   "metadata": {},
   "source": [
    "# Confirmation Rate\n",
    " \n",
    "Table: Signups\n",
    "\n",
    "    +----------------+----------+\n",
    "    | Column Name    | Type     |\n",
    "    +----------------+----------+\n",
    "    | user_id        | int      |\n",
    "    | time_stamp     | datetime |\n",
    "    +----------------+----------+\n",
    "    user_id is the column of unique values for this table.\n",
    "    Each row contains information about the signup time for the user with ID user_id.\n",
    "\n",
    "\n",
    "Table: Confirmations\n",
    "\n",
    "    +----------------+----------+\n",
    "    | Column Name    | Type     |\n",
    "    +----------------+----------+\n",
    "    | user_id        | int      |\n",
    "    | time_stamp     | datetime |\n",
    "    | action         | ENUM     |\n",
    "    +----------------+----------+\n",
    "    (user_id, time_stamp) is the primary key (combination of columns with unique values) for this table.\n",
    "    user_id is a foreign key (reference column) to the Signups table.\n",
    "    action is an ENUM (category) of the type ('confirmed', 'timeout')\n",
    "    Each row of this table indicates that the user with ID user_id requested a confirmation message at time_stamp and that confirmation message was either confirmed ('confirmed') or expired without confirming ('timeout').\n",
    "\n",
    "\n",
    "    The confirmation rate of a user is the number of 'confirmed' messages divided by the total number of requested confirmation messages. The confirmation rate of a user that did not request any confirmation messages is 0. Round the confirmation rate to two decimal places.\n",
    "\n",
    "    Write a solution to find the confirmation rate of each user.\n",
    "\n",
    "    Return the result table in any order.\n",
    "\n",
    "    The result format is in the following example.\n",
    "\n",
    " \n",
    "\n",
    "Example 1:\n",
    "\n",
    "Input: \n",
    "Signups table:\n",
    "\n",
    "    +---------+---------------------+\n",
    "    | user_id | time_stamp          |\n",
    "    +---------+---------------------+\n",
    "    | 3       | 2020-03-21 10:16:13 |\n",
    "    | 7       | 2020-01-04 13:57:59 |\n",
    "    | 2       | 2020-07-29 23:09:44 |\n",
    "    | 6       | 2020-12-09 10:39:37 |\n",
    "    +---------+---------------------+\n",
    "Confirmations table:\n",
    "\n",
    "    +---------+---------------------+-----------+\n",
    "    | user_id | time_stamp          | action    |\n",
    "    +---------+---------------------+-----------+\n",
    "    | 3       | 2021-01-06 03:30:46 | timeout   |\n",
    "    | 3       | 2021-07-14 14:00:00 | timeout   |\n",
    "    | 7       | 2021-06-12 11:57:29 | confirmed |\n",
    "    | 7       | 2021-06-13 12:58:28 | confirmed |\n",
    "    | 7       | 2021-06-14 13:59:27 | confirmed |\n",
    "    | 2       | 2021-01-22 00:00:00 | confirmed |\n",
    "    | 2       | 2021-02-28 23:59:59 | timeout   |\n",
    "    +---------+---------------------+-----------+\n",
    "Output: \n",
    "\n",
    "    +---------+-------------------+\n",
    "    | user_id | confirmation_rate |\n",
    "    +---------+-------------------+\n",
    "    | 6       | 0.00              |\n",
    "    | 3       | 0.00              |\n",
    "    | 7       | 1.00              |\n",
    "    | 2       | 0.50              |\n",
    "    +---------+-------------------+\n",
    "Explanation: \n",
    "\n",
    "    User 6 did not request any confirmation messages. The confirmation rate is 0.\n",
    "    User 3 made 2 requests and both timed out. The confirmation rate is 0.\n",
    "    User 7 made 3 requests and all were confirmed. The confirmation rate is 1.\n",
    "    User 2 made 2 requests where one was confirmed and the other timed out. The confirmation rate is 1 / 2 = 0.5.\n",
    "    \n",
    "    \n",
    "Problem Analysis\n",
    "\n",
    "    The task is to calculate the confirmation rate for each user in the Signups table based on actions in the Confirmations table, specifically focusing on \"confirmed\" actions. We need to avoid division by zero errors when there are no corresponding entries in Confirmations for a user.\n",
    "\n",
    "Approach\n",
    "\n",
    "    Join Tables: Perform a LEFT JOIN between Signups and Confirmations using user_id to include all users, even if they don’t have any records in Confirmations.\n",
    "    Conditional Aggregation:\n",
    "        Calculate the total number of \"confirmed\" actions per user using a SUM(CASE WHEN ...).\n",
    "        Count the total number of entries in Confirmations for each user.\n",
    "    Avoid Division by Zero: Use NULLIF on the denominator to return NULL when there’s no entry in Confirmations, allowing COALESCE to default the confirmation rate to 0.\n",
    "    Round Result: Use ROUND to format the confirmation rate to two decimal places.\n",
    "\n",
    "steps\n",
    "\n",
    "    Left Join: Start by joining Signups with Confirmations using user_id.\n",
    "    Calculate Confirmation Rate:\n",
    "        Use SUM(CASE WHEN action = 'confirmed' THEN 1 ELSE 0 END) to get confirmed actions.\n",
    "        Use NULLIF(COUNT(b.user_id), 0) to avoid division by zero.\n",
    "    Round and Handle Nulls:\n",
    "        Use COALESCE to substitute any NULL values with 0.\n",
    "        Use ROUND to ensure the result is formatted to two decimal places.\n",
    "    Grouping: Group the results by user_id.\n",
    "    \n",
    "Edge Cases\n",
    "\n",
    "    No Confirmations for a User: If a user has no entries in Confirmations, COUNT(b.user_id) will be 0, handled by NULLIF.\n",
    "    All Confirmations Ignored: If there are no \"confirmed\" actions for a user, SUM(CASE...) will be 0.\n",
    "    Null Entries in Confirmations Table: If Confirmations has null or irrelevant values, the query correctly ignores these due to the conditional aggregation.\n",
    "    \n",
    "    Time Complexity \n",
    "        O(N) for joining and grouping rows, where N is the number of entries in the Confirmations table.\n",
    "        The complexity is manageable for typical datasets, especially with indexing on user_id.\n",
    "    Space Complexity \n",
    "        O(M) space, where M is the number of unique users in Signups, required for storing intermediate results in aggregation.\n",
    "        \n",
    "Follow-up Questions\n",
    "\n",
    "    How would you improve this query’s performance on large datasets?\n",
    "\n",
    "    Answer: Adding indexes on user_id in both tables would improve join performance. Additionally, storing aggregated results in a materialized view could speed up repeated queries, especially in cases with high data frequency.\n",
    "    What if the confirmation rate calculation logic changes (e.g., includes additional statuses)?\n",
    "\n",
    "    Answer: Update the CASE statement to include other statuses as necessary, adjusting conditions to match the new requirements. This allows flexibility without significant structural changes.\n",
    "    How would you handle calculating the rate over different time frames, such as weekly or monthly rates?\n",
    "\n",
    "    Answer: Add a time filter to the WHERE clause or group by specific time intervals, like DATE_TRUNC('month', confirmation_date), to aggregate results by time frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cdd7478",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your PostgreSQL query statement below\n",
    "SELECT \n",
    "    a.user_id,\n",
    "    ROUND(\n",
    "        COALESCE(\n",
    "            SUM(CASE WHEN action = 'confirmed' THEN 1 ELSE 0 END) * 1.0 / NULLIF(COUNT(b.user_id), 0), \n",
    "            0\n",
    "        ), \n",
    "        2\n",
    "    ) AS confirmation_rate\n",
    "FROM \n",
    "    Signups a\n",
    "LEFT JOIN \n",
    "    Confirmations b \n",
    "ON \n",
    "    a.user_id = b.user_id\n",
    "GROUP BY \n",
    "    a.user_id;\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "410b6f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your MySQL query statement below\n",
    "select a.user_id,  round(ifnull(sum(case when action = \"confirmed\" then 1 else 0 end)/count(b.user_id), 0), 2) as confirmation_rate\n",
    "from Signups a\n",
    "left join Confirmations b using (user_id)\n",
    "group by a.user_id\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34fa5489",
   "metadata": {},
   "source": [
    "# Reported Posts II\n",
    " \n",
    "Table: Actions\n",
    "\n",
    "    +---------------+---------+\n",
    "    | Column Name   | Type    |\n",
    "    +---------------+---------+\n",
    "    | user_id       | int     |\n",
    "    | post_id       | int     |\n",
    "    | action_date   | date    | \n",
    "    | action        | enum    |\n",
    "    | extra         | varchar |\n",
    "    +---------------+---------+\n",
    "    This table may have duplicate rows.\n",
    "    The action column is an ENUM (category) type of ('view', 'like', 'reaction', 'comment', 'report', 'share').\n",
    "    The extra column has optional information about the action, such as a reason for the report or a type of reaction.\n",
    "\n",
    "\n",
    "Table: Removals\n",
    "\n",
    "    +---------------+---------+\n",
    "    | Column Name   | Type    |\n",
    "    +---------------+---------+\n",
    "    | post_id       | int     |\n",
    "    | remove_date   | date    | \n",
    "    +---------------+---------+\n",
    "    post_id is the primary key (column with unique values) of this table.\n",
    "    Each row in this table indicates that some post was removed due to being reported or as a result of an admin review.\n",
    "\n",
    "\n",
    "    Write a solution to find the average daily percentage of posts that got removed after being reported as spam, rounded to 2 decimal places.\n",
    "\n",
    "    The result format is in the following example.\n",
    "\n",
    "\n",
    "\n",
    "Example 1:\n",
    "\n",
    "Input: \n",
    "Actions table:\n",
    "\n",
    "    +---------+---------+-------------+--------+--------+\n",
    "    | user_id | post_id | action_date | action | extra  |\n",
    "    +---------+---------+-------------+--------+--------+\n",
    "    | 1       | 1       | 2019-07-01  | view   | null   |\n",
    "    | 1       | 1       | 2019-07-01  | like   | null   |\n",
    "    | 1       | 1       | 2019-07-01  | share  | null   |\n",
    "    | 2       | 2       | 2019-07-04  | view   | null   |\n",
    "    | 2       | 2       | 2019-07-04  | report | spam   |\n",
    "    | 3       | 4       | 2019-07-04  | view   | null   |\n",
    "    | 3       | 4       | 2019-07-04  | report | spam   |\n",
    "    | 4       | 3       | 2019-07-02  | view   | null   |\n",
    "    | 4       | 3       | 2019-07-02  | report | spam   |\n",
    "    | 5       | 2       | 2019-07-03  | view   | null   |\n",
    "    | 5       | 2       | 2019-07-03  | report | racism |\n",
    "    | 5       | 5       | 2019-07-03  | view   | null   |\n",
    "    | 5       | 5       | 2019-07-03  | report | racism |\n",
    "    +---------+---------+-------------+--------+--------+\n",
    "Removals table:\n",
    "\n",
    "    +---------+-------------+\n",
    "    | post_id | remove_date |\n",
    "    +---------+-------------+\n",
    "    | 2       | 2019-07-20  |\n",
    "    | 3       | 2019-07-18  |\n",
    "    +---------+-------------+\n",
    "Output: \n",
    "\n",
    "    +-----------------------+\n",
    "    | average_daily_percent |\n",
    "    +-----------------------+\n",
    "    | 75.00                 |\n",
    "    +-----------------------+\n",
    "Explanation:\n",
    "\n",
    "    The percentage for 2019-07-04 is 50% because only one post of two spam reported posts were removed.\n",
    "    The percentage for 2019-07-02 is 100% because one post was reported as spam and it was removed.\n",
    "    The other days had no spam reports so the average is (50 + 100) / 2 = 75%\n",
    "    Note that the output is only one number and that we do not care about the remove dates.\n",
    "    \n",
    "Problem Explanation\n",
    "\n",
    "    You need to calculate the average daily percentage of posts removed after being reported as spam. This involves analyzing two tables: Actions and Removals. You want to determine how many posts reported as spam were actually removed and then compute the average percentage of such removals per day.\n",
    "\n",
    "Steps to Solve the Problem\n",
    "Understand the Schema:\n",
    "\n",
    "    Familiarize yourself with the Actions and Removals tables, their columns, and their relationships.\n",
    "    \n",
    "Identify Relevant Actions:\n",
    "\n",
    "    Filter the Actions table for entries where extra = 'spam', as these are the actions reporting posts as spam.\n",
    "Join the Tables:\n",
    "\n",
    "    Perform a left join on the Actions and Removals tables to connect reported posts to their removal status.\n",
    "Count Distinct Posts:\n",
    "\n",
    "    For each action date, count distinct posts that were reported as spam and how many of those were removed.\n",
    "Calculate Percentages:\n",
    "\n",
    "    Calculate the percentage of reported posts that were removed for each day using the formula:\n",
    " \n",
    "    percentage=( count of reported posts/ count of removed posts)×100\n",
    "Average the Percentages:\n",
    "\n",
    "    Finally, compute the average of these daily percentages.\n",
    "    \n",
    "    \n",
    "Edge Cases to Consider\n",
    "\n",
    "    No Reports: If there are no reports of spam on certain days, ensure that the calculation handles the division correctly (should not cause division by zero).\n",
    "    No Removals: If all reported posts were not removed, ensure the percentage calculates to 0% rather than causing errors.\n",
    "    Duplicate Entries: The presence of duplicate rows in the Actions table should not skew the results. Using COUNT(DISTINCT ...) will help mitigate this.\n",
    "    Empty Tables: If either table is empty, the result should gracefully handle it without throwing errors.\n",
    "\n",
    "Time and Space Complexity\n",
    "\n",
    "    Time Complexity: The overall time complexity is O(nlogn) due to sorting while aggregating counts and the join operation, where n is the number of entries in the actions table.\n",
    "    Space Complexity: The space complexity is O(n) to store intermediate results.\n",
    "    \n",
    "Follow-up Questions\n",
    "\n",
    "    What would happen if the extra column had different values for spam?\n",
    "\n",
    "    You would need to adjust the WHERE clause to handle other values as well or normalize the input values before processing.\n",
    "    How would you optimize this query for large datasets?\n",
    "\n",
    "    Consider indexing the post_id in both tables and optimizing the join condition. Also, filtering out unnecessary data before the join can significantly improve performance.\n",
    "    Can you explain how the NULLIF function works in this context?\n",
    "\n",
    "    NULLIF returns NULL if the first argument equals the second; this prevents division by zero. In our query, it ensures that if there are no reported posts for a day, we do not attempt to divide by zero, which would lead to an error.\n",
    "    \n",
    "Sample Answers to Follow-up Questions\n",
    "\n",
    "    If the extra column had different values for spam, we could modify the query to check for those additional values as well. We might also consider normalizing the values to standardize how reports are logged.\n",
    "\n",
    "    To optimize the query for large datasets, we could index the post_id and action_date columns. Filtering early to remove irrelevant rows before joining would also help. Additionally, analyzing query execution plans to identify bottlenecks could further enhance performance.\n",
    "\n",
    "    The NULLIF function is essential in this context as it prevents division by zero errors. If the count of distinct reported posts is zero, NULLIF returns NULL, ensuring that our percentage calculation does not encounter a division by zero scenario, which would crash the query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dcf09e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your PostgreSQL query statement below\n",
    "SELECT ROUND(SUM(percent) / COUNT(DISTINCT action_date), 2) AS average_daily_percent\n",
    "FROM (\n",
    "    SELECT \n",
    "        a.action_date,\n",
    "        COUNT(DISTINCT r.post_id) * 100.0 / NULLIF(COUNT(DISTINCT a.post_id), 0) AS percent\n",
    "    FROM \n",
    "        actions a\n",
    "    LEFT JOIN \n",
    "        removals r ON a.post_id = r.post_id\n",
    "    WHERE \n",
    "        a.extra = 'spam'\n",
    "    GROUP BY \n",
    "        a.action_date\n",
    ") AS temp;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb35e376",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your MySQL query statement below\n",
    "select round(sum(percent)/count(distinct action_date),2) as average_daily_percent\n",
    "from\n",
    "    (select a.action_date,\n",
    "    count(distinct r.post_id)/count(distinct a.post_id)*100 as percent\n",
    "    from actions a left join removals r\n",
    "    on a.post_id = r.post_id\n",
    "    where a.extra='spam'\n",
    "    group by 1) temp;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1339944",
   "metadata": {},
   "source": [
    "# Customers Who Bought Products A and B but Not C\n",
    " \n",
    "Table: Customers\n",
    "\n",
    "    +---------------------+---------+\n",
    "    | Column Name         | Type    |\n",
    "    +---------------------+---------+\n",
    "    | customer_id         | int     |\n",
    "    | customer_name       | varchar |\n",
    "    +---------------------+---------+\n",
    "    customer_id is the column with unique values for this table.\n",
    "    customer_name is the name of the customer.\n",
    " \n",
    "\n",
    "Table: Orders\n",
    "\n",
    "    +---------------+---------+\n",
    "    | Column Name   | Type    |\n",
    "    +---------------+---------+\n",
    "    | order_id      | int     |\n",
    "    | customer_id   | int     |\n",
    "    | product_name  | varchar |\n",
    "    +---------------+---------+\n",
    "    order_id is the column with unique values for this table.\n",
    "    customer_id is the id of the customer who bought the product \"product_name\".\n",
    "\n",
    "\n",
    "    Write a solution to report the customer_id and customer_name of customers who bought products \"A\", \"B\" but did not buy the product \"C\" since we want to recommend them to purchase this product.\n",
    "\n",
    "    Return the result table ordered by customer_id.\n",
    "\n",
    "    The result format is in the following example.\n",
    "\n",
    "\n",
    "\n",
    "Example 1:\n",
    "\n",
    "Input: \n",
    "Customers table:\n",
    "\n",
    "    +-------------+---------------+\n",
    "    | customer_id | customer_name |\n",
    "    +-------------+---------------+\n",
    "    | 1           | Daniel        |\n",
    "    | 2           | Diana         |\n",
    "    | 3           | Elizabeth     |\n",
    "    | 4           | Jhon          |\n",
    "    +-------------+---------------+\n",
    "Orders table:\n",
    "\n",
    "    +------------+--------------+---------------+\n",
    "    | order_id   | customer_id  | product_name  |\n",
    "    +------------+--------------+---------------+\n",
    "    | 10         |     1        |     A         |\n",
    "    | 20         |     1        |     B         |\n",
    "    | 30         |     1        |     D         |\n",
    "    | 40         |     1        |     C         |\n",
    "    | 50         |     2        |     A         |\n",
    "    | 60         |     3        |     A         |\n",
    "    | 70         |     3        |     B         |\n",
    "    | 80         |     3        |     D         |\n",
    "    | 90         |     4        |     C         |\n",
    "    +------------+--------------+---------------+\n",
    "Output: \n",
    "\n",
    "    +-------------+---------------+\n",
    "    | customer_id | customer_name |\n",
    "    +-------------+---------------+\n",
    "    | 3           | Elizabeth     |\n",
    "    +-------------+---------------+\n",
    "    Explanation: Only the customer_id with id 3 bought the product A and B but not the product C.\n",
    "    \n",
    "Initial Ideas\n",
    "    We need to identify customers who have purchased both products \"A\" and \"B\" but have not purchased product \"C\". This can be achieved by using a combination of GROUP BY, HAVING, and filtering conditions.\n",
    "\n",
    "Steps\n",
    "\n",
    "    Join the Tables: Start by joining the Customers and Orders tables on customer_id to get access to customer names along with their corresponding orders.\n",
    "    Filter Orders: Use a WHERE clause to filter the products to focus on only \"A\", \"B\", and \"C\".\n",
    "    Aggregate Orders: Group the results by customer_id and count the occurrences of each product.\n",
    "    Use HAVING: Filter the grouped results with the HAVING clause to ensure the customer has:\n",
    "        Count of product \"A\" >= 1\n",
    "        Count of product \"B\" >= 1\n",
    "        Count of product \"C\" = 0 (i.e., the customer did not buy product \"C\").\n",
    "    Select Required Fields: Finally, select the customer_id and customer_name of the filtered results and order by customer_id.\n",
    "\n",
    "Edge Cases\n",
    "\n",
    "    Customers who have not made any purchases should not appear in the results.\n",
    "    A customer who bought multiple units of products \"A\" and \"B\" but no \"C\" should still be included.\n",
    "\n",
    "Complexity Analysis\n",
    "\n",
    "    Time Complexity: O(n), where n is the number of records in the Orders table, since we are scanning through the records to perform joins and aggregations.\n",
    "    Space Complexity: O(m), where m is the number of unique customers returned in the final result, as we are storing the filtered results.\n",
    "    \n",
    "Follow-Up Questions\n",
    "\n",
    "What if there were additional products to consider?\n",
    "\n",
    "    We could extend the WHERE and HAVING clauses to include other products similarly.\n",
    "How would you handle larger datasets?\n",
    "\n",
    "    Indexing customer_id on both tables would help optimize the join operation.\n",
    "What if you needed to consider the dates of purchases?\n",
    "\n",
    "    We would need to include a date field in our Orders table and adjust our WHERE clause to filter based on the desired date range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "531b62bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write your PostgreSQL query statement below\n",
    "SELECT c.customer_id, c.customer_name\n",
    "FROM Customers c\n",
    "JOIN Orders o ON c.customer_id = o.customer_id\n",
    "WHERE o.product_name IN ('A', 'B', 'C')\n",
    "GROUP BY c.customer_id, c.customer_name\n",
    "HAVING COUNT(CASE WHEN o.product_name = 'A' THEN 1 END) > 0\n",
    "   AND COUNT(CASE WHEN o.product_name = 'B' THEN 1 END) > 0\n",
    "   AND COUNT(CASE WHEN o.product_name = 'C' THEN 1 END) = 0\n",
    "ORDER BY c.customer_id;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60129d2c",
   "metadata": {},
   "source": [
    "Friend Requests I: Overall Acceptance Rate\n",
    " \n",
    "Table: FriendRequest\n",
    "\n",
    "    +----------------+---------+\n",
    "    | Column Name    | Type    |\n",
    "    +----------------+---------+\n",
    "    | sender_id      | int     |\n",
    "    | send_to_id     | int     |\n",
    "    | request_date   | date    |\n",
    "    +----------------+---------+\n",
    "    This table may contain duplicates (In other words, there is no primary key for this table in SQL).\n",
    "    This table contains the ID of the user who sent the request, the ID of the user who received the request, and the date of the request.\n",
    " \n",
    "\n",
    "Table: RequestAccepted\n",
    "\n",
    "    +----------------+---------+\n",
    "    | Column Name    | Type    |\n",
    "    +----------------+---------+\n",
    "    | requester_id   | int     |\n",
    "    | accepter_id    | int     |\n",
    "    | accept_date    | date    |\n",
    "    +----------------+---------+\n",
    "    This table may contain duplicates (In other words, there is no primary key for this table in SQL).\n",
    "    This table contains the ID of the user who sent the request, the ID of the user who received the request, and the date when the request was accepted.\n",
    "\n",
    "\n",
    "    Find the overall acceptance rate of requests, which is the number of acceptance divided by the number of requests. Return the answer rounded to 2 decimals places.\n",
    "\n",
    "    Note that:\n",
    "\n",
    "    The accepted requests are not necessarily from the table friend_request. In this case, Count the total accepted requests (no matter whether they are in the original requests), and divide it by the number of requests to get the acceptance rate.\n",
    "    It is possible that a sender sends multiple requests to the same receiver, and a request could be accepted more than once. In this case, the ‘duplicated’ requests or acceptances are only counted once.\n",
    "    If there are no requests at all, you should return 0.00 as the accept_rate.\n",
    "    The result format is in the following example.\n",
    "\n",
    " \n",
    "\n",
    "Example 1:\n",
    "\n",
    "Input: \n",
    "FriendRequest table:\n",
    "\n",
    "    +-----------+------------+--------------+\n",
    "    | sender_id | send_to_id | request_date |\n",
    "    +-----------+------------+--------------+\n",
    "    | 1         | 2          | 2016/06/01   |\n",
    "    | 1         | 3          | 2016/06/01   |\n",
    "    | 1         | 4          | 2016/06/01   |\n",
    "    | 2         | 3          | 2016/06/02   |\n",
    "    | 3         | 4          | 2016/06/09   |\n",
    "    +-----------+------------+--------------+\n",
    "RequestAccepted table:\n",
    "\n",
    "    +--------------+-------------+-------------+\n",
    "    | requester_id | accepter_id | accept_date |\n",
    "    +--------------+-------------+-------------+\n",
    "    | 1            | 2           | 2016/06/03  |\n",
    "    | 1            | 3           | 2016/06/08  |\n",
    "    | 2            | 3           | 2016/06/08  |\n",
    "    | 3            | 4           | 2016/06/09  |\n",
    "    | 3            | 4           | 2016/06/10  |\n",
    "    +--------------+-------------+-------------+\n",
    "Output: \n",
    "\n",
    "    +-------------+\n",
    "    | accept_rate |\n",
    "    +-------------+\n",
    "    | 0.8         |\n",
    "    +-------------+\n",
    "Explanation: \n",
    "\n",
    "    There are 4 unique accepted requests, and there are 5 requests in total. So the rate is 0.80.\n",
    " \n",
    " \n",
    " \n",
    "Initial Ideas\n",
    "Identify Unique Requests and Acceptances:\n",
    "\n",
    "    Each friend request may have duplicates, so we must count unique requests to avoid inflated results.\n",
    "    Similarly, accepted requests might also contain duplicates, so we should only count distinct acceptances.\n",
    "Handle Division by Zero:\n",
    "\n",
    "    If no requests were sent (count = 0), the rate should return 0.00 instead of causing a division error.\n",
    "Round the Final Result:\n",
    "\n",
    "    Ensure that the result is formatted to two decimal places.\n",
    "    \n",
    "Solution Steps\n",
    "Define requested CTE:\n",
    "\n",
    "    Extract distinct pairs of sender_id and send_to_id from FriendRequest to represent unique requests.\n",
    "Define accepted CTE:\n",
    "\n",
    "    Extract distinct pairs of requester_id and accepter_id from RequestAccepted to represent unique accepted requests.\n",
    "Calculate the Acceptance Rate:\n",
    "\n",
    "    Numerator: Count rows in accepted, representing the total accepted requests.\n",
    "    Denominator: Count rows in requested, representing the total requests sent.\n",
    "    Use NULLIF to handle cases where there are no requests by converting the denominator to NULL when it’s zero, then handle it with COALESCE(..., 0).\n",
    "Round and Format Result:\n",
    "\n",
    "    Use ROUND(..., 2) to format the result to two decimal places.\n",
    "    \n",
    "Edge Cases\n",
    "\n",
    "No Requests Sent:\n",
    "\n",
    "    If there are no records in FriendRequest, the result should be 0.00.\n",
    "No Accepted Requests:\n",
    "\n",
    "    If there are requests but no matching accepted requests, the rate should be 0.00.\n",
    "Duplicate Requests or Acceptances:\n",
    "\n",
    "    Duplicates in the tables don’t affect the result since we use DISTINCT in both CTEs.\n",
    "    \n",
    "    \n",
    "Complexity Analysis\n",
    "\n",
    "Time Complexity:\n",
    "\n",
    "    O(N + M), where N is the number of rows in FriendRequest and M is the number of rows in RequestAccepted.\n",
    "    Counting distinct pairs will take linear time with respect to the number of entries in each table.\n",
    "Space Complexity:\n",
    "\n",
    "    O(N + M) for storing requested and accepted CTEs.\n",
    "    \n",
    "Follow-up Questions and Answers\n",
    "\n",
    "Q: What if the acceptance rate needs to be calculated by month or year?\n",
    "\n",
    "    A: We can add request_date and accept_date to the CTE queries and apply GROUP BY on these date parts to calculate monthly or yearly acceptance rates.\n",
    "Q: How would you adjust the query to find the acceptance rate for specific users?\n",
    "\n",
    "    A: Add a WHERE clause to filter sender_id or requester_id in FriendRequest or RequestAccepted based on the user ID.\n",
    "Q: What if we want to consider requests sent only within the last month?\n",
    "\n",
    "    A: Filter the FriendRequest table by request_date >= DATE_SUB(CURDATE(), INTERVAL 1 MONTH) to include only recent requests in the calculation.\n",
    "Q: How would the query change if it were run in PostgreSQL instead?\n",
    "\n",
    "    A: Minor adjustments are needed, such as explicit type casting for calculations or replacing MySQL-specific functions with PostgreSQL-compatible ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f24b1354",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your MySQL query statement below\n",
    "WITH requested AS (\n",
    "    SELECT DISTINCT \n",
    "        sender_id, send_to_id\n",
    "    FROM \n",
    "        FriendRequest\n",
    "), accepted AS (\n",
    "    SELECT DISTINCT\n",
    "        requester_id, accepter_id\n",
    "    FROM \n",
    "        RequestAccepted\n",
    ")\n",
    "SELECT \n",
    "    ROUND(\n",
    "        COALESCE(\n",
    "            (SELECT COUNT(*) FROM accepted) / NULLIF((SELECT COUNT(*) FROM requested), 0),\n",
    "            0\n",
    "        ),\n",
    "        2\n",
    "    ) AS accept_rate;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ad075c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your PostgreSQL query statement below \n",
    "WITH requested AS (\n",
    "    SELECT DISTINCT \n",
    "        sender_id, send_to_id\n",
    "    FROM \n",
    "        FriendRequest\n",
    "), accepted AS (\n",
    "    SELECT DISTINCT\n",
    "        requester_id, accepter_id\n",
    "    FROM RequestAccepted\n",
    ")\n",
    "SELECT (\n",
    "    ROUND ( \n",
    "        COALESCE(\n",
    "            (SELECT COUNT (*) FROM accepted)::NUMERIC\n",
    "            /\n",
    "            NULLIF((SELECT COUNT(*) FROM requested)::NUMERIC , 0)\n",
    "        , 0)\n",
    "    , 2)\n",
    ") AS accept_rate"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
