{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43544db1",
   "metadata": {},
   "source": [
    "# 1. Project Employees III\n",
    " \n",
    "Table: Project\n",
    "\n",
    "    +-------------+---------+\n",
    "    | Column Name | Type    |\n",
    "    +-------------+---------+\n",
    "    | project_id  | int     |\n",
    "    | employee_id | int     |\n",
    "    +-------------+---------+\n",
    "(project_id, employee_id) is the primary key (combination of columns with unique values) of this table.\n",
    "employee_id is a foreign key (reference column) to Employee table.\n",
    "\n",
    "Each row of this table indicates that the employee with employee_id is working on the project with project_id.\n",
    " \n",
    "\n",
    "Table: Employee\n",
    "\n",
    "    +------------------+---------+\n",
    "    | Column Name      | Type    |\n",
    "    +------------------+---------+\n",
    "    | employee_id      | int     |\n",
    "    | name             | varchar |\n",
    "    | experience_years | int     |\n",
    "    +------------------+---------+\n",
    "employee_id is the primary key (column with unique values) of this table.\n",
    "Each row of this table contains information about one employee.\n",
    " \n",
    "\n",
    "Write a solution to report the most experienced employees in each project. In case of a tie, report all employees with the maximum number of experience years.\n",
    "\n",
    "Return the result table in any order.\n",
    "\n",
    "The result format is in the following example.\n",
    "\n",
    " \n",
    "\n",
    "Example 1:\n",
    "\n",
    "Input: \n",
    "Project table:\n",
    "\n",
    "    +-------------+-------------+\n",
    "    | project_id  | employee_id |\n",
    "    +-------------+-------------+\n",
    "    | 1           | 1           |\n",
    "    | 1           | 2           |\n",
    "    | 1           | 3           |\n",
    "    | 2           | 1           |\n",
    "    | 2           | 4           |\n",
    "    +-------------+-------------+\n",
    "    \n",
    "Employee table:\n",
    "\n",
    "    +-------------+--------+------------------+\n",
    "    | employee_id | name   | experience_years |\n",
    "    +-------------+--------+------------------+\n",
    "    | 1           | Khaled | 3                |\n",
    "    | 2           | Ali    | 2                |\n",
    "    | 3           | John   | 3                |\n",
    "    | 4           | Doe    | 2                |\n",
    "    +-------------+--------+------------------+\n",
    "Output: \n",
    "\n",
    "    +-------------+---------------+\n",
    "    | project_id  | employee_id   |\n",
    "    +-------------+---------------+\n",
    "    | 1           | 1             |\n",
    "    | 1           | 3             |\n",
    "    | 2           | 1             |\n",
    "    +-------------+---------------+\n",
    "Explanation: Both employees with id 1 and 3 have the most experience among the employees of the first project. For the second project, the employee with id 1 has the most experience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64534577",
   "metadata": {},
   "outputs": [],
   "source": [
    "SELECT p.project_id, p.employee_id\n",
    "FROM Project p\n",
    "JOIN Employee e ON p.employee_id = e.employee_id\n",
    "WHERE (p.project_id, e.experience_years) IN (\n",
    "    SELECT p2.project_id, MAX(e2.experience_years)\n",
    "    FROM Project p2\n",
    "    JOIN Employee e2 ON p2.employee_id = e2.employee_id\n",
    "    GROUP BY p2.project_id\n",
    ");\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f56a6392",
   "metadata": {},
   "source": [
    "Explanation:\n",
    "- This solution works by leveraging SQL’s ability to handle filtering with IN for multiple columns, making it concise and performant:\n",
    "\n",
    "- Complexity: The solution has a complexity mainly driven by the subquery filtering, which should work efficiently on indexed tables.\n",
    "\n",
    "- Edge Cases: We handle cases where multiple employees have the same maximum experience years in a project by including all matching rows with the WHERE (project_id, experience_years) IN condition. This approach guarantees that if there are ties, they will all be returned."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def22be6",
   "metadata": {},
   "source": [
    "# 2.Project Employees II\n",
    "Table: Project\n",
    "\n",
    "    +-------------+---------+\n",
    "    | Column Name | Type    |\n",
    "    +-------------+---------+\n",
    "    | project_id  | int     |\n",
    "    | employee_id | int     |\n",
    "    +-------------+---------+\n",
    "\n",
    "(project_id, employee_id) is the primary key (combination of columns with unique values) of this table.\n",
    "employee_id is a foreign key (reference column) to Employee table.\n",
    "Each row of this table indicates that the employee with employee_id is working on the project with project_id.\n",
    " \n",
    "\n",
    "Table: Employee\n",
    "\n",
    "    +------------------+---------+\n",
    "    | Column Name      | Type    |\n",
    "    +------------------+---------+\n",
    "    | employee_id      | int     |\n",
    "    | name             | varchar |\n",
    "    | experience_years | int     |\n",
    "    +------------------+---------+\n",
    "employee_id is the primary key (column with unique values) of this table.\n",
    "Each row of this table contains information about one employee.\n",
    " \n",
    "\n",
    "Write a solution to report all the projects that have the most employees.\n",
    "\n",
    "Return the result table in any order.\n",
    "\n",
    "The result format is in the following example.\n",
    "\n",
    " \n",
    "\n",
    "Example 1:\n",
    "\n",
    "Input: \n",
    "Project table:\n",
    "\n",
    "    +-------------+-------------+\n",
    "    | project_id  | employee_id |\n",
    "    +-------------+-------------+\n",
    "    | 1           | 1           |\n",
    "    | 1           | 2           |\n",
    "    | 1           | 3           |\n",
    "    | 2           | 1           |\n",
    "    | 2           | 4           |\n",
    "    +-------------+-------------+\n",
    "Employee table:\n",
    "\n",
    "    +-------------+--------+------------------+\n",
    "    | employee_id | name   | experience_years |\n",
    "    +-------------+--------+------------------+\n",
    "    | 1           | Khaled | 3                |\n",
    "    | 2           | Ali    | 2                |\n",
    "    | 3           | John   | 1                |\n",
    "    | 4           | Doe    | 2                |\n",
    "    +-------------+--------+------------------+\n",
    "Output: \n",
    "\n",
    "    +-------------+\n",
    "    | project_id  |\n",
    "    +-------------+\n",
    "    | 1           |\n",
    "    +-------------+\n",
    "Explanation: The first project has 3 employees while the second one has 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "518966ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "SELECT project_id\n",
    "FROM Project\n",
    "GROUP BY project_id\n",
    "HAVING COUNT(employee_id) = (\n",
    "    SELECT MAX(employee_count)\n",
    "    FROM (\n",
    "        SELECT project_id, COUNT(employee_id) AS employee_count\n",
    "        FROM Project\n",
    "        GROUP BY project_id\n",
    "    ) AS ProjectCounts\n",
    ");\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "488e54d8",
   "metadata": {},
   "source": [
    "Complexity Analysis\n",
    "\n",
    "Time Complexity:\n",
    "\n",
    "    Inner Subquery: The inner subquery has a time complexity of  O(n), where n is the number of rows in the Project table. This is because it scans all rows to group and count them.\n",
    "\n",
    "    Outer Query: The outer query also has a time complexity of O(n), as it re-groups and filters based on the maximum count.\n",
    "\n",
    "    Overall Complexity: Approximately O(n), making this efficient for typical datasets, especially with indexing on project_id.\n",
    "\n",
    "Space Complexity:\n",
    "\n",
    "    Temporary Space: The space complexity is O(m), where m is the number of unique project_ids, as it temporarily stores the ProjectCounts result.\n",
    "\n",
    "Edge Cases\n",
    "\n",
    "    - All Projects Have the Same Employee Count: If all projects have the same number of employees, the query returns all project_ids, as they all meet the maximum count condition.\n",
    "    - Single Project: If there’s only one project, the query simply returns that project’s ID, as it inherently has the maximum count.\n",
    "    - Projects with Zero Employees: If any project has zero employees, it won’t be included in the result since the count is zero, which typically won’t match the maximum.\n",
    "    - Ties for Maximum Count: If multiple projects share the maximum employee count, they’ll all be included in the result, as each meets the maximum threshold.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c6a4e29",
   "metadata": {},
   "source": [
    "# 3. Article Views I\n",
    " \n",
    "Table: Views\n",
    "\n",
    "    +---------------+---------+\n",
    "    | Column Name   | Type    |\n",
    "    +---------------+---------+\n",
    "    | article_id    | int     |\n",
    "    | author_id     | int     |\n",
    "    | viewer_id     | int     |\n",
    "    | view_date     | date    |\n",
    "    +---------------+---------+\n",
    "There is no primary key (column with unique values) for this table, the table may have duplicate rows.\n",
    "Each row of this table indicates that some viewer viewed an article (written by some author) on some date. \n",
    "Note that equal author_id and viewer_id indicate the same person.\n",
    " \n",
    "\n",
    "Write a solution to find all the authors that viewed at least one of their own articles.\n",
    "\n",
    "Return the result table sorted by id in ascending order.\n",
    "\n",
    "The result format is in the following example.\n",
    "\n",
    " \n",
    "\n",
    "Example 1:\n",
    "\n",
    "Input: \n",
    "Views table:\n",
    "    \n",
    "    +------------+-----------+-----------+------------+\n",
    "    | article_id | author_id | viewer_id | view_date  |\n",
    "    +------------+-----------+-----------+------------+\n",
    "    | 1          | 3         | 5         | 2019-08-01 |\n",
    "    | 1          | 3         | 6         | 2019-08-02 |\n",
    "    | 2          | 7         | 7         | 2019-08-01 |\n",
    "    | 2          | 7         | 6         | 2019-08-02 |\n",
    "    | 4          | 7         | 1         | 2019-07-22 |\n",
    "    | 3          | 4         | 4         | 2019-07-21 |\n",
    "    | 3          | 4         | 4         | 2019-07-21 |\n",
    "    +------------+-----------+-----------+------------+\n",
    "\n",
    "Output: \n",
    "\n",
    "    +------+\n",
    "    | id   |\n",
    "    +------+\n",
    "    | 4    |\n",
    "    | 7    |\n",
    "    +------+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4609a2bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "SELECT DISTINCT author_id AS id\n",
    "FROM Views\n",
    "WHERE author_id = viewer_id\n",
    "ORDER BY id ASC;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "827c0944",
   "metadata": {},
   "source": [
    "Explanation\n",
    "\n",
    "Problem Breakdown:\n",
    "\n",
    "    We need to identify authors who have viewed at least one of their own articles. This means we’re looking for records where the author_id is the same as the viewer_id.\n",
    "\n",
    "    The result should return only unique author_ids in ascending order.\n",
    "\n",
    "Query Explanation:\n",
    "\n",
    "    SELECT DISTINCT author_id AS id:We use SELECT DISTINCT to ensure that each author appears only once in the result, regardless of how many times they viewed their articles.\n",
    "    \n",
    "    We rename author_id as id to match the required output format.\n",
    "    \n",
    "    FROM Views: We retrieve data from the Views table, which contains all article view records, including article_id, author_id, viewer_id, and view_date.\n",
    "    \n",
    "    WHERE author_id = viewer_id: This condition filters the rows to include only those where the author_id matches the viewer_id, meaning the author viewed their own article.\n",
    "    \n",
    "    ORDER BY id ASC: Finally, we sort the result by id (the author’s ID) in ascending order to meet the problem’s output requirements.\n",
    "\n",
    "Complexity Analysis\n",
    "\n",
    "Time Complexity:\n",
    "\n",
    "    The query has a time complexity of O(n), where n is the number of rows in the Views table, as it performs a scan to filter rows where author_id = viewer_id and a distinct selection.\n",
    "\n",
    "Space Complexity:\n",
    "\n",
    "    The space complexity is O(k), where k is the number of distinct author_ids that match the condition, as we store the unique results temporarily.\n",
    "\n",
    "Edge Cases\n",
    "\n",
    "    No Matching Rows: If there are no rows where author_id = viewer_id, the result will be an empty table.\n",
    "\n",
    "    Multiple Views by the Same Author: If an author views their article multiple times, DISTINCT ensures they appear only once in the result.\n",
    "\n",
    "    Single Record Table: If the Views table has only one row and it meets the author_id = viewer_id condition, the query will return just that author’s ID."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aace34d",
   "metadata": {},
   "source": [
    "# 4. Consecutive Numbers\n",
    " \n",
    "Table: Logs\n",
    "\n",
    "    +-------------+---------+\n",
    "    | Column Name | Type    |\n",
    "    +-------------+---------+\n",
    "    | id          | int     |\n",
    "    | num         | varchar |\n",
    "    +-------------+---------+\n",
    "In SQL, id is the primary key for this table.\n",
    "id is an autoincrement column starting from 1.\n",
    " \n",
    "\n",
    "Find all numbers that appear at least three times consecutively.\n",
    "\n",
    "Return the result table in any order.\n",
    "\n",
    "The result format is in the following example.\n",
    "\n",
    " \n",
    "\n",
    "Example 1:\n",
    "\n",
    "Input: \n",
    "Logs table:\n",
    "\n",
    "    +----+-----+\n",
    "    | id | num |\n",
    "    +----+-----+\n",
    "    | 1  | 1   |\n",
    "    | 2  | 1   |\n",
    "    | 3  | 1   |\n",
    "    | 4  | 2   |\n",
    "    | 5  | 1   |\n",
    "    | 6  | 2   |\n",
    "    | 7  | 2   |\n",
    "    +----+-----+\n",
    "Output: \n",
    "\n",
    "    +-----------------+\n",
    "    | ConsecutiveNums |\n",
    "    +-----------------+\n",
    "    | 1               |\n",
    "    +-----------------+\n",
    "Explanation: 1 is the only number that appears consecutively for at least three times."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c3ce0d",
   "metadata": {},
   "source": [
    "Steps and Explanation:\n",
    "    \n",
    "    Identify Consecutive Repetitions: We need to check whether each number (num) in the Logs table appears consecutively three or more times. Consecutive means that each appearance follows immediately after the previous one in the order of id.\n",
    "\n",
    "Create Conditions for Consecutive Rows: For any given row with id = i, we’ll check:\n",
    "\n",
    "    - if num at i is the same as num at i+1\n",
    "    - and num at i+1 is the same as num at i+2.\n",
    "    - If both of these conditions are true, then we have identified a number that appears consecutively three times starting from id = i.\n",
    "\n",
    "SQL Query: We can write a query that uses a JOIN or WHERE clause to find consecutive rows.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37e1393",
   "metadata": {},
   "outputs": [],
   "source": [
    "SELECT DISTINCT l1.num AS ConsecutiveNums\n",
    "FROM Logs l1, Logs l2, Logs l3\n",
    "WHERE l1.num = l2.num \n",
    "  AND l2.num = l3.num \n",
    "  AND l1.id = l2.id - 1 \n",
    "  AND l2.id = l3.id - 1;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2962b45f",
   "metadata": {},
   "source": [
    "Explanation of the SQL Query:\n",
    "    \n",
    "    - l1, l2, and l3 are aliases for the Logs table, representing three consecutive rows.\n",
    "    \n",
    "    - The WHERE clause checks:\n",
    "        - l1.num = l2.num and l2.num = l3.num: This ensures that the same number appears in three consecutive rows.\n",
    "        - l1.id = l2.id - 1 and l2.id = l3.id - 1: This ensures the rows are consecutive based on the id field.\n",
    "    \n",
    "    - SELECT DISTINCT l1.num returns the unique numbers that meet the criteria.\n",
    "    \n",
    "Edge Cases:\n",
    "\n",
    "    Fewer than Three Rows: If the table has fewer than three rows, we can’t have any number appearing three times consecutively.\n",
    "\n",
    "    Non-Consecutive Repetitions: If a number appears multiple times but not in consecutive rows (e.g., with different numbers in between), it should not be included in the result.\n",
    "\n",
    "    Multiple Sets of Consecutive Repetitions: If the same number appears consecutively in two different sequences (e.g., three times in one part and three times in another part), it should still be included only once due to DISTINCT.\n",
    "    \n",
    "Complexity Analysis:\n",
    "\n",
    "    Time Complexity: O(n) assuming an indexed query with id being unique, as we are scanning through the table and filtering based on adjacent rows.\n",
    "\n",
    "    Space Complexity: O(m) where m is the number of unique numbers that appear consecutively three times, since we're storing these results.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8416d9cc",
   "metadata": {},
   "source": [
    "# 5. Get Highest Answer Rate Question \n",
    "\n",
    "Table: SurveyLog\n",
    "\n",
    "    +-------------+------+\n",
    "    | Column Name | Type |\n",
    "    +-------------+------+\n",
    "    | id          | int  |\n",
    "    | action      | ENUM |\n",
    "    | question_id | int  |\n",
    "    | answer_id   | int  |\n",
    "    | q_num       | int  |\n",
    "    | timestamp   | int  |\n",
    "    +-------------+------+\n",
    "- This table may contain duplicate rows.\n",
    "- action is an ENUM (category) of the type: \"show\", \"answer\", or \"skip\".\n",
    "- Each row of this table indicates the user with ID = id has taken an action with the question question_id at time timestamp.\n",
    "- If the action taken by the user is \"answer\", answer_id will contain the id of that answer, otherwise, it will be null.\n",
    "- q_num is the numeral order of the question in the current session.\n",
    " \n",
    "\n",
    "The answer rate for a question is the number of times a user answered the question by the number of times a user showed the question.\n",
    "\n",
    "Write a solution to report the question that has the highest answer rate. If multiple questions have the same maximum answer rate, report the question with the smallest question_id.\n",
    "\n",
    "The result format is in the following example.\n",
    "\n",
    " \n",
    "\n",
    "Example 1:\n",
    "\n",
    "Input: \n",
    "SurveyLog table:\n",
    "\n",
    "    +----+--------+-------------+-----------+-------+-----------+\n",
    "    | id | action | question_id | answer_id | q_num | timestamp |\n",
    "    +----+--------+-------------+-----------+-------+-----------+\n",
    "    | 5  | show   | 285         | null      | 1     | 123       |\n",
    "    | 5  | answer | 285         | 124124    | 1     | 124       |\n",
    "    | 5  | show   | 369         | null      | 2     | 125       |\n",
    "    | 5  | skip   | 369         | null      | 2     | 126       |\n",
    "    +----+--------+-------------+-----------+-------+-----------+\n",
    "Output: \n",
    "\n",
    "    +------------+\n",
    "    | survey_log |\n",
    "    +------------+\n",
    "    | 285        |\n",
    "    +------------+\n",
    "Explanation: \n",
    "\n",
    "    Question 285 was showed 1 time and answered 1 time. The answer rate of question 285 is 1.0\n",
    "    Question 369 was showed 1 time and was not answered. The answer rate of question 369 is 0.0\n",
    "    Question 285 has the highest answer rate.\n",
    "    \n",
    "    \n",
    "Steps and Explanation:\n",
    "\n",
    "Filter the show and answer Actions:\n",
    "\n",
    "    We need to count how many times each question was shown and how many times it was answered.\n",
    "    In the SurveyLog table, a show action means the question was displayed to a user, and an answer action means the user provided an answer to that question.\n",
    "    \n",
    "Aggregate Counts by Question:\n",
    "\n",
    "    We can use conditional aggregation to count show and answer actions for each question_id.\n",
    "    \n",
    "Calculate the Answer Rate:\n",
    "\n",
    "    The answer rate for each question is calculated as the count of answers divided by the count of shows.\n",
    "    To avoid division by zero, we handle cases where a question was shown but never answered.\n",
    "    \n",
    "Select the Question with the Highest Answer Rate:\n",
    "\n",
    "    We need to find the question with the maximum answer rate. If multiple questions have the same answer rate, we return the question with the smallest question_id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d84dee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your MySQL query statement below\n",
    "SELECT question_id as survey_log\n",
    "FROM (\n",
    "    SELECT \n",
    "        question_id,\n",
    "        SUM(action = 'answer') / SUM(action = 'show') AS answer_rate\n",
    "    FROM SurveyLog\n",
    "    GROUP BY question_id\n",
    ") AS AnswerRates\n",
    "ORDER BY answer_rate DESC, question_id ASC\n",
    "LIMIT 1;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a094f485",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PostgreSQL\n",
    "SELECT question_id AS survey_log\n",
    "FROM (\n",
    "    SELECT \n",
    "        question_id,\n",
    "        SUM(CASE WHEN action = 'answer' THEN 1 ELSE 0 END) * 1.0 / \n",
    "        NULLIF(SUM(CASE WHEN action = 'show' THEN 1 ELSE 0 END), 0) AS answer_rate\n",
    "    FROM SurveyLog\n",
    "    GROUP BY question_id\n",
    ") AS AnswerRates\n",
    "ORDER BY answer_rate DESC, question_id ASC\n",
    "LIMIT 1;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91dfc9e3",
   "metadata": {},
   "source": [
    "Explanation of the SQL Query:\n",
    "\n",
    "Inner Query (AnswerRates):\n",
    "\n",
    "    SUM(action = 'answer') counts how many times each question was answered. This works because MySQL treats TRUE as 1 and FALSE as 0.\n",
    "    SUM(action = 'show') counts how many times each question was shown.\n",
    "    The answer_rate is calculated by dividing the answer count by the show count for each question_id.\n",
    "    We GROUP BY question_id to calculate these values per question.\n",
    "    \n",
    "Outer Query:\n",
    "\n",
    "    ORDER BY answer_rate DESC, question_id ASC: This sorts the results by answer rate in descending order so that the highest rate is at the top. If there are ties, it uses question_id in ascending order to select the smallest question_id.\n",
    "    LIMIT 1 ensures we return only the question with the highest answer rate and, in the case of ties, the smallest question_id.\n",
    "    \n",
    "Edge Cases:\n",
    "\n",
    "    Questions Never Shown: Questions that were answered but never shown should not be included, but they won’t appear because we divide by SUM(action = 'show').\n",
    "    No Answers: If a question was shown but never answered, the answer rate will be 0. This question may be included if it has the highest rate in cases where no questions are answered.\n",
    "    Multiple Questions with the Same Answer Rate: When multiple questions have the same answer rate, this query will pick the question with the smallest question_id.\n",
    "    \n",
    "Complexity Analysis:\n",
    "\n",
    "    Time Complexity:  O(n), where n is the number of rows in the SurveyLog table. The GROUP BY operation iterates over each row, and the ORDER BY with LIMIT is efficient given it’s just selecting one row.\n",
    "    Space Complexity: O(m), where m is the number of unique question_ids, as we store these results in temporary memory for sorting and filtering."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "012ed9d1",
   "metadata": {},
   "source": [
    "# 6. Apples & Oranges\n",
    " \n",
    "Table: Sales\n",
    "\n",
    "    +---------------+---------+\n",
    "    | Column Name   | Type    |\n",
    "    +---------------+---------+\n",
    "    | sale_date     | date    |\n",
    "    | fruit         | enum    | \n",
    "    | sold_num      | int     | \n",
    "    +---------------+---------+\n",
    "(sale_date, fruit) is the primary key (combination of columns with unique values) of this table.\n",
    "This table contains the sales of \"apples\" and \"oranges\" sold each day.\n",
    " \n",
    "\n",
    "Write a solution to report the difference between the number of apples and oranges sold each day.\n",
    "\n",
    "Return the result table ordered by sale_date.\n",
    "\n",
    "The result format is in the following example.\n",
    "\n",
    " \n",
    "\n",
    "Example 1:\n",
    "\n",
    "Input: \n",
    "Sales table:\n",
    "\n",
    "    +------------+------------+-------------+\n",
    "    | sale_date  | fruit      | sold_num    |\n",
    "    +------------+------------+-------------+\n",
    "    | 2020-05-01 | apples     | 10          |\n",
    "    | 2020-05-01 | oranges    | 8           |\n",
    "    | 2020-05-02 | apples     | 15          |\n",
    "    | 2020-05-02 | oranges    | 15          |\n",
    "    | 2020-05-03 | apples     | 20          |\n",
    "    | 2020-05-03 | oranges    | 0           |\n",
    "    | 2020-05-04 | apples     | 15          |\n",
    "    | 2020-05-04 | oranges    | 16          |\n",
    "    +------------+------------+-------------+\n",
    "Output: \n",
    "\n",
    "    +------------+--------------+\n",
    "    | sale_date  | diff         |\n",
    "    +------------+--------------+\n",
    "    | 2020-05-01 | 2            |\n",
    "    | 2020-05-02 | 0            |\n",
    "    | 2020-05-03 | 20           |\n",
    "    | 2020-05-04 | -1           |\n",
    "    +------------+--------------+\n",
    "    \n",
    "Explanation: \n",
    "\n",
    "    Day 2020-05-01, 10 apples and 8 oranges were sold (Difference  10 - 8 = 2).\n",
    "    Day 2020-05-02, 15 apples and 15 oranges were sold (Difference 15 - 15 = 0).\n",
    "    Day 2020-05-03, 20 apples and 0 oranges were sold (Difference 20 - 0 = 20).\n",
    "    Day 2020-05-04, 15 apples and 16 oranges were sold (Difference 15 - 16 = -1).\n",
    "\n",
    "Steps and Explanation:\n",
    "\n",
    "    Aggregate Sales by Date: We'll need to sum the sold_num for apples and oranges separately for each sale_date.\n",
    "    Calculate the Difference: Once we have the total sold numbers for both fruits for each date, we can calculate the difference by subtracting the total number of oranges sold from the total number of apples sold.\n",
    "    Order the Results: Finally, we will order the results by sale_date to ensure the output is in the correct chronological order.\n",
    "    \n",
    "    \n",
    "Explanation of the SQL Query:\n",
    "\n",
    "SUM with CASE:\n",
    "\n",
    "    SUM(CASE WHEN fruit = 'apples' THEN sold_num ELSE 0 END): This sums up the sold_num for apples only. If the fruit is not apples, it adds 0.\n",
    "    SUM(CASE WHEN fruit = 'oranges' THEN sold_num ELSE 0 END): Similarly, this sums up the sold_num for oranges.\n",
    "    Calculating the Difference:\n",
    "\n",
    "    The difference is calculated by subtracting the total number of oranges sold from the total number of apples sold for each date.\n",
    "    \n",
    "GROUP BY:\n",
    "    \n",
    "    GROUP BY sale_date: This groups the results by each date, so we get a single result row for each date.\n",
    "ORDER BY:\n",
    "    \n",
    "    ORDER BY sale_date: This sorts the final results in chronological order by the sale date.\n",
    "    \n",
    "Edge Cases:\n",
    "\n",
    "    Dates with Only One Fruit: If a date has only apples or only oranges sold, the difference will reflect that, such as being positive or negative or even zero.\n",
    "\n",
    "    No Sales Data for a Date: If there are no sales recorded for a date in the table, that date won't appear in the output at all since it does not satisfy the GROUP BY clause.\n",
    "\n",
    "    Handling Null Values: In this query, null values for sold_num in the original table are not an issue since we're using conditional aggregation that defaults to 0.\n",
    "\n",
    "Complexity Analysis:\n",
    "\n",
    "    Time Complexity: O(n), where n is the number of rows in the Sales table. The query scans through the entire table once to aggregate data.\n",
    "    Space Complexity: O(d), where d is the number of unique sale_dates, since we are storing results for each distinct date in the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d574b405",
   "metadata": {},
   "outputs": [],
   "source": [
    "SELECT sale_date,\n",
    "       SUM(CASE WHEN fruit = 'apples' THEN sold_num ELSE 0 END) -\n",
    "       SUM(CASE WHEN fruit = 'oranges' THEN sold_num ELSE 0 END) AS diff\n",
    "FROM Sales\n",
    "GROUP BY sale_date\n",
    "ORDER BY sale_date;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e466b9b",
   "metadata": {},
   "source": [
    "# 7. Winning Candidate\n",
    " \n",
    "Table: Candidate\n",
    "\n",
    "    +-------------+----------+\n",
    "    | Column Name | Type     |\n",
    "    +-------------+----------+\n",
    "    | id          | int      |\n",
    "    | name        | varchar  |\n",
    "    +-------------+----------+\n",
    "id is the column with unique values for this table.\n",
    "\n",
    "Each row of this table contains information about the id and the name of a candidate.\n",
    " \n",
    "\n",
    "Table: Vote\n",
    "\n",
    "    +-------------+------+\n",
    "    | Column Name | Type |\n",
    "    +-------------+------+\n",
    "    | id          | int  |\n",
    "    | candidateId | int  |\n",
    "    +-------------+------+\n",
    "id is an auto-increment primary key (column with unique values).\n",
    "candidateId is a foreign key (reference column) to id from the Candidate table.\n",
    "\n",
    "Each row of this table determines the candidate who got the ith vote in the elections.\n",
    " \n",
    "\n",
    "Write a solution to report the name of the winning candidate (i.e., the candidate who got the largest number of votes).\n",
    "\n",
    "The test cases are generated so that exactly one candidate wins the elections.\n",
    "\n",
    "The result format is in the following example.\n",
    "\n",
    " \n",
    "\n",
    "Example 1:\n",
    "\n",
    "Input: \n",
    "Candidate table:\n",
    "\n",
    "    +----+------+\n",
    "    | id | name |\n",
    "    +----+------+\n",
    "    | 1  | A    |\n",
    "    | 2  | B    |\n",
    "    | 3  | C    |\n",
    "    | 4  | D    |\n",
    "    | 5  | E    |\n",
    "    +----+------+\n",
    "Vote table:\n",
    "\n",
    "    +----+-------------+\n",
    "    | id | candidateId |\n",
    "    +----+-------------+\n",
    "    | 1  | 2           |\n",
    "    | 2  | 4           |\n",
    "    | 3  | 3           |\n",
    "    | 4  | 2           |\n",
    "    | 5  | 5           |\n",
    "    +----+-------------+\n",
    "    \n",
    "Output: \n",
    "\n",
    "    +------+\n",
    "    | name |\n",
    "    +------+\n",
    "    | B    |\n",
    "    +------+\n",
    "\n",
    "Explanation: \n",
    "    Candidate B has 2 votes. Candidates C, D, and E have 1 vote each.\n",
    "    The winner is candidate B.\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be407a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "SELECT c.name\n",
    "FROM Candidate c\n",
    "JOIN (\n",
    "    SELECT candidateId, COUNT(*) AS vote_count\n",
    "    FROM Vote\n",
    "    GROUP BY candidateId\n",
    ") v ON c.id = v.candidateId\n",
    "ORDER BY v.vote_count DESC\n",
    "LIMIT 1;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "202f61c5",
   "metadata": {},
   "source": [
    "Steps:\n",
    "\n",
    "    Count the Votes: We will count the number of votes each candidate received by joining the Vote table with the Candidate table based on the candidate's ID.\n",
    "    Determine the Winner: After counting the votes, we will find the candidate with the maximum number of votes. Given that the problem states there is always one winner, we don't need to handle ties.\n",
    "    Return the Name of the Winning Candidate: Finally, we will return the name of the winning candidate.\n",
    "    \n",
    "Edge Cases:\n",
    "\n",
    "    Exactly One Candidate Wins: The problem specifies that there will always be exactly one winner, so we do not need to account for ties or situations where no votes are cast.\n",
    "    Candidates with No Votes: Candidates who have not received any votes will not appear in the results from the inner query, so they will not affect the final output.\n",
    "    No Votes Cast: Although not applicable per the problem's constraints, if there were no votes, the query would return an empty result.\n",
    "    \n",
    "Complexity Analysis:\n",
    "\n",
    "    Time Complexity: O(n+m), where n is the number of rows in the Vote table and m is the number of rows in the Candidate table. The inner query iterates through all votes, and the join operation checks against all candidates.\n",
    "    Space Complexity: O(k), where k is the number of unique candidates. The inner query results need to be stored temporarily before joining with the Candidate table."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "701e3dbb",
   "metadata": {},
   "source": [
    "# 8. Report Contiguous Dates\n",
    " \n",
    "Table: Failed\n",
    "\n",
    "    +--------------+---------+\n",
    "    | Column Name  | Type    |\n",
    "    +--------------+---------+\n",
    "    | fail_date    | date    |\n",
    "    +--------------+---------+\n",
    "    \n",
    "fail_date is the primary key (column with unique values) for this table.\n",
    "\n",
    "This table contains the days of failed tasks.\n",
    " \n",
    "\n",
    "Table: Succeeded\n",
    "\n",
    "    +--------------+---------+\n",
    "    | Column Name  | Type    |\n",
    "    +--------------+---------+\n",
    "    | success_date | date    |\n",
    "    +--------------+---------+\n",
    "success_date is the primary key (column with unique values) for this table.\n",
    "\n",
    "This table contains the days of succeeded tasks.\n",
    " \n",
    "\n",
    "A system is running one task every day. Every task is independent of the previous tasks. The tasks can fail or succeed.\n",
    "\n",
    "Write a solution to report the period_state for each continuous interval of days in the period from 2019-01-01 to 2019-12-31.\n",
    "\n",
    "period_state is 'failed' if tasks in this interval failed or 'succeeded' if tasks in this interval succeeded. \n",
    "Interval of days are retrieved as start_date and end_date.\n",
    "\n",
    "Return the result table ordered by start_date.\n",
    "\n",
    "The result format is in the following example.\n",
    "\n",
    " \n",
    "\n",
    "Example 1:\n",
    "\n",
    "Input: \n",
    "Failed table:\n",
    "\n",
    "    +-------------------+\n",
    "    | fail_date         |\n",
    "    +-------------------+\n",
    "    | 2018-12-28        |\n",
    "    | 2018-12-29        |\n",
    "    | 2019-01-04        |\n",
    "    | 2019-01-05        |\n",
    "    +-------------------+\n",
    "    \n",
    "Succeeded table:\n",
    "\n",
    "    +-------------------+\n",
    "    | success_date      |\n",
    "    +-------------------+\n",
    "    | 2018-12-30        |\n",
    "    | 2018-12-31        |\n",
    "    | 2019-01-01        |\n",
    "    | 2019-01-02        |\n",
    "    | 2019-01-03        |\n",
    "    | 2019-01-06        |\n",
    "    +-------------------+\n",
    "    \n",
    "Output: \n",
    "\n",
    "    +--------------+--------------+--------------+\n",
    "    | period_state | start_date   | end_date     |\n",
    "    +--------------+--------------+--------------+\n",
    "    | succeeded    | 2019-01-01   | 2019-01-03   |\n",
    "    | failed       | 2019-01-04   | 2019-01-05   |\n",
    "    | succeeded    | 2019-01-06   | 2019-01-06   |\n",
    "    +--------------+--------------+--------------+\n",
    "    \n",
    "Explanation: \n",
    "\n",
    "    The report ignored the system state in 2018 as we care about the system in the period 2019-01-01 to 2019-12-31.\n",
    "    From 2019-01-01 to 2019-01-03 all tasks succeeded and the system state was \"succeeded\".\n",
    "    From 2019-01-04 to 2019-01-05 all tasks failed and the system state was \"failed\".\n",
    "    From 2019-01-06 to 2019-01-06 all tasks succeeded and the system state was \"succeeded\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "972d2ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "SELECT stats AS period_state, MIN(day) AS start_date, MAX(day) AS end_date\n",
    "FROM (\n",
    "    SELECT \n",
    "        day, \n",
    "        RANK() OVER (ORDER BY day) AS overall_ranking, \n",
    "        stats, \n",
    "        rk, \n",
    "        (RANK() OVER (ORDER BY day) - rk) AS inv\n",
    "    FROM (\n",
    "        SELECT fail_date AS day, 'failed' AS stats, RANK() OVER (ORDER BY fail_date) AS rk\n",
    "        FROM Failed\n",
    "        WHERE fail_date BETWEEN '2019-01-01' AND '2019-12-31'\n",
    "        \n",
    "        UNION \n",
    "        \n",
    "        SELECT success_date AS day, 'succeeded' AS stats, RANK() OVER (ORDER BY success_date) AS rk\n",
    "        FROM Succeeded\n",
    "        WHERE success_date BETWEEN '2019-01-01' AND '2019-12-31'\n",
    "    ) t\n",
    ") c\n",
    "GROUP BY inv, stats\n",
    "ORDER BY start_date;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f00ccb7b",
   "metadata": {},
   "source": [
    "Breakdown of the SQL Query\n",
    "\n",
    "Inner Query (Union of Failures and Successes):\n",
    "\n",
    "    Combines dates from the Failed and Succeeded tables within the specified date range (2019).\n",
    "    Uses UNION to merge both tables into one result set with a common structure.\n",
    "    Assigns ranks to each date within their respective states.\n",
    "\n",
    "Ranking and Calculating Inversions:\n",
    "\n",
    "    The ranks help in identifying the sequence of days, facilitating the detection of continuous intervals.\n",
    "    The inv calculation allows the grouping of continuous days of the same state by subtracting the rk from the overall ranking.\n",
    "\n",
    "Grouping by State:\n",
    "\n",
    "    Aggregates the results to summarize the continuous periods of each state, utilizing MIN and MAX to find the range of dates for each state.\n",
    "\n",
    "Final Output:\n",
    "\n",
    "    Returns the period state, start date, and end date for each continuous period, ordered by start_date.\n",
    "    \n",
    "Edge Cases Considered\n",
    "\n",
    "    No Data for 2019: If both Failed and Succeeded tables have no entries for the year 2019, the output will be empty, as there are no dates to evaluate.\n",
    "    Continuous Successes or Failures: If all tasks are either successful or failed for the entire year, the output will consist of a single row capturing the entire range of the year (e.g., all succeeded from 2019-01-01 to 2019-12-31).\n",
    "    Interleaved Dates: If there are entries with multiple successes and failures on the same day, the ranks will correctly allow for the periods to be recognized and separated, ensuring accurate output.\n",
    "    Dates Without Both States: If a day appears in one state but not the other, the query will still generate results for those continuous periods, ensuring that no gaps are overlooked.\n",
    "\n",
    "Edge Date Handling:\n",
    "\n",
    "    The query explicitly filters dates to fall within the year 2019, thus it does not include entries from the previous or following year, avoiding incorrect aggregations.\n",
    "    \n",
    "Complexity Analysis\n",
    "\n",
    "Time Complexity: \n",
    "\n",
    "    The time complexity of this query is O(N log N), where N is the total number of entries across both the Failed and Succeeded tables. This is primarily due to the use of the RANK() function, which involves sorting the records by date.\n",
    "    The final grouping and aggregation step (using GROUP BY) also contributes to the overall complexity but is generally linear with respect to the number of groups formed.\n",
    "\n",
    "    Space Complexity: \n",
    "    The space complexity is O(N), as the query needs to store the combined results from both tables, including the calculated ranks and states.\n",
    "    The result set in memory grows with the number of unique days present in the input tables, which can affect the overall space requirement depending on the distribution of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c754e34",
   "metadata": {},
   "source": [
    "# 9. Page Recommendations II\n",
    " \n",
    "Table: Friendship\n",
    "\n",
    "    +---------------+---------+\n",
    "    | Column Name   | Type    |\n",
    "    +---------------+---------+\n",
    "    | user1_id      | int     |\n",
    "    | user2_id      | int     |\n",
    "    +---------------+---------+\n",
    "\n",
    "    (user1_id, user2_id) is the primary key (combination of columns with unique values) for this table.\n",
    "\n",
    "    Each row of this table indicates that the users user1_id and user2_id are friends.\n",
    " \n",
    "\n",
    "Table: Likes\n",
    "\n",
    "    +-------------+---------+\n",
    "    | Column Name | Type    |\n",
    "    +-------------+---------+\n",
    "    | user_id     | int     |\n",
    "    | page_id     | int     |\n",
    "    +-------------+---------+\n",
    "    (user_id, page_id) is the primary key (combination of columns with unique values) for this table.\n",
    "    Each row of this table indicates that user_id likes page_id.\n",
    " \n",
    "\n",
    "    You are implementing a page recommendation system for a social media website. Your system will recommend a page to user_id if the page is liked by at least one friend of user_id and is not liked by user_id.\n",
    "\n",
    "    Write a solution to find all the possible page recommendations for every user. Each recommendation should appear as a row in the result table with these columns:\n",
    "\n",
    "    user_id: The ID of the user that your system is making the recommendation to.\n",
    "    page_id: The ID of the page that will be recommended to user_id.\n",
    "    friends_likes: The number of the friends of user_id that like page_id.\n",
    "    Return the result table in any order.\n",
    "\n",
    "The result format is in the following example.\n",
    "\n",
    " \n",
    "\n",
    "Example 1:\n",
    "\n",
    "Input: \n",
    "Friendship table:\n",
    "\n",
    "    +----------+----------+\n",
    "    | user1_id | user2_id |\n",
    "    +----------+----------+\n",
    "    | 1        | 2        |\n",
    "    | 1        | 3        |\n",
    "    | 1        | 4        |\n",
    "    | 2        | 3        |\n",
    "    | 2        | 4        |\n",
    "    | 2        | 5        |\n",
    "    | 6        | 1        |\n",
    "    +----------+----------+\n",
    "    \n",
    "Likes table:\n",
    "\n",
    "    +---------+---------+\n",
    "    | user_id | page_id |\n",
    "    +---------+---------+\n",
    "    | 1       | 88      |\n",
    "    | 2       | 23      |\n",
    "    | 3       | 24      |\n",
    "    | 4       | 56      |\n",
    "    | 5       | 11      |\n",
    "    | 6       | 33      |\n",
    "    | 2       | 77      |\n",
    "    | 3       | 77      |\n",
    "    | 6       | 88      |\n",
    "    +---------+---------+\n",
    "Output: \n",
    "\n",
    "    +---------+---------+---------------+\n",
    "    | user_id | page_id | friends_likes |\n",
    "    +---------+---------+---------------+\n",
    "    | 1       | 77      | 2             |\n",
    "    | 1       | 23      | 1             |\n",
    "    | 1       | 24      | 1             |\n",
    "    | 1       | 56      | 1             |\n",
    "    | 1       | 33      | 1             |\n",
    "    | 2       | 24      | 1             |\n",
    "    | 2       | 56      | 1             |\n",
    "    | 2       | 11      | 1             |\n",
    "    | 2       | 88      | 1             |\n",
    "    | 3       | 88      | 1             |\n",
    "    | 3       | 23      | 1             |\n",
    "    | 4       | 88      | 1             |\n",
    "    | 4       | 77      | 1             |\n",
    "    | 4       | 23      | 1             |\n",
    "    | 5       | 77      | 1             |\n",
    "    | 5       | 23      | 1             |\n",
    "    +---------+---------+---------------+\n",
    "    \n",
    "Explanation: \n",
    "\n",
    "Take user 1 as an example:\n",
    "  - User 1 is friends with users 2, 3, 4, and 6.\n",
    "  - Recommended pages are 23 (user 2 liked it), 24 (user 3 liked it), 56 (user 3 liked it), 33 (user 6 liked it), and 77 (user 2 and user 3 liked it).\n",
    "  - Note that page 88 is not recommended because user 1 already liked it.\n",
    "\n",
    "Another example is user 6:\n",
    "  - User 6 is friends with user 1.\n",
    "  - User 1 only liked page 88, but user 6 already liked it. Hence, user 6 has no recommendations.\n",
    "\n",
    "You can recommend pages for users 2, 3, 4, and 5 using a similar process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2115a566",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your MySQL query statement below\n",
    "SELECT user1_id as user_id,page_id,COUNT(user_id) as friends_likes\n",
    "FROM\n",
    "(\n",
    "    SELECT a.user1_id,b.user_id,b.page_id # user, all user friends, page_id\n",
    "    FROM Friendship as a\n",
    "    JOIN Likes as b\n",
    "    ON a.user2_id=b.user_id\n",
    "    \n",
    "    UNION \n",
    "    \n",
    "    SELECT a.user2_id,b.user_id,b.page_id\n",
    "    FROM Friendship as a\n",
    "    JOIN Likes as b\n",
    "    ON a.user1_id=b.user_id\n",
    ") a\n",
    "WHERE CONCAT(user1_id,\",\",page_id) NOT IN\n",
    "(SELECT CONCAT(user_id,\",\",page_id) FROM Likes)\n",
    "GROUP BY user1_id,page_id;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6564f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write your PostgreSQL query statement below\n",
    "SELECT user1_id AS user_id, page_id, COUNT(user_id) AS friends_likes\n",
    "FROM (\n",
    "    #page that user1's friends like\n",
    "    SELECT a.user1_id, b.user_id, b.page_id   \n",
    "    FROM Friendship AS a\n",
    "    JOIN Likes AS b ON a.user2_id = b.user_id\n",
    "    \n",
    "    UNION\n",
    "    \n",
    "    # page that user2' user1 like\n",
    "    SELECT a.user2_id, b.user_id, b.page_id\n",
    "    FROM Friendship AS a\n",
    "    JOIN Likes AS b ON a.user1_id = b.user_id\n",
    ") AS a\n",
    "WHERE user1_id || ',' || page_id NOT IN (\n",
    "    SELECT user_id || ',' || page_id FROM Likes\n",
    ")\n",
    "GROUP BY user1_id, page_id;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56fa2b1c",
   "metadata": {},
   "source": [
    "Breakdown of the SQL Query\n",
    "\n",
    "Selecting the Required Columns:\n",
    "\n",
    "    The query selects user1_id (aliased as user_id), page_id, and counts the number of friends who liked each page using COUNT(user_id) (aliased as friends_likes). This provides the necessary output structure for the recommendations.\n",
    "    \n",
    "Inner Query (Union of Friendships and Likes):\n",
    "\n",
    "    The inner query performs two JOIN operations between the Friendship table (aliased as a) and the Likes table (aliased as b):\n",
    "        The first SELECT statement joins where user2_id from the Friendship table matches the user_id from the Likes table, capturing pages liked by friends of user1_id.\n",
    "        The second SELECT statement does the opposite, joining on user1_id to include the cases where user2_id is the friend of the user.\n",
    "    The use of UNION ensures that all unique combinations of users, their friends, and the pages liked are captured.\n",
    "    \n",
    "example for inner query with user1 = 1: \n",
    "\n",
    "| step | user1_id | user_id | page_id |\n",
    "| ---- | -------- | ------- | ------- |\n",
    "| \"1\"  | 1        | 4       | 56      |\n",
    "| \"1\"  | 1        | 2       | 77      |\n",
    "| \"1\"  | 1        | 2       | 23      |\n",
    "| \"1\"  | 1        | 3       | 24      |\n",
    "| \"1\"  | 1        | 3       | 77      |\n",
    "| \"2\"  | 3        | 1       | 88      |\n",
    "| \"2\"  | 2        | 1       | 88      |\n",
    "| \"2\"  | 4        | 1       | 88      |\n",
    "\n",
    "\n",
    "    \n",
    "Filtering Out Liked Pages:\n",
    "\n",
    "    The WHERE clause filters the results to exclude any page that the user (represented by user1_id) has already liked. It does this by checking if the combination of user1_id and page_id is present in the Likes table using a NOT IN subquery.\n",
    "    The CONCAT function is used to create a unique identifier for each user-page combination, simplifying the comparison.\n",
    "    \n",
    "Grouping and Counting:\n",
    "\n",
    "    The GROUP BY user1_id, page_id clause aggregates the results by user and page, allowing the COUNT(user_id) to calculate the number of friends who liked each recommended page.\n",
    "    This step summarizes how many friends of each user liked each page, forming the basis of the recommendations.\n",
    "\n",
    "Example Explanation\n",
    "Using the provided data:\n",
    "\n",
    "For User 1:\n",
    "\n",
    "    Friends: User 2, 3, 4, 6\n",
    "    Recommended pages:\n",
    "    Page 23 (liked by User 2)\n",
    "    Page 24 (liked by User 3)\n",
    "    Page 56 (liked by User 4)\n",
    "    Page 33 (liked by User 6)\n",
    "    Page 77 (liked by User 2 and User 3)\n",
    "    Not recommended: Page 88 (liked by User 1)\n",
    "For User 6:\n",
    "\n",
    "    Friends: User 1\n",
    "    No recommendations, as User 1's only liked page (88) is already liked by User 6.\n",
    "\n",
    "Edge Cases Considered\n",
    "\n",
    "    No Friendships: If there are no entries in the Friendship table, the output will be empty, as no recommendations can be made.\n",
    "    No Likes: If the Likes table has no entries for a user, they will not receive any recommendations, resulting in an empty output for that user.\n",
    "    Mutual Likes: If a user and their friend have mutual likes on certain pages, those pages won't appear in the recommendations, ensuring that the system suggests only unliked pages.\n",
    "    Multiple Likes for a Page: If multiple friends like the same page, the count will correctly reflect the total number of friends who liked that page.\n",
    "    \n",
    "Complexity Analysis\n",
    "\n",
    "    Time Complexity: The time complexity of this query is approximately O(N + M), where N is the number of friendships and M is the number of likes. The UNION operation processes both tables, and the GROUP BY operation aggregates the results.\n",
    "    Space Complexity: The space complexity is O(P), where P is the number of unique pages being recommended. The intermediate results will occupy memory based on the size of the result set, which is determined by the number of user-page combinations generated from the friends' likes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b33da400",
   "metadata": {},
   "source": [
    "# 10. Finding the Topic of Each Post\n",
    " \n",
    "Table: Keywords\n",
    "\n",
    "    +-------------+---------+\n",
    "    | Column Name | Type    |\n",
    "    +-------------+---------+\n",
    "    | topic_id    | int     |\n",
    "    | word        | varchar |\n",
    "    +-------------+---------+\n",
    "    (topic_id, word) is the primary key (combination of columns with unique values) for this table.\n",
    "    Each row of this table contains the id of a topic and a word that is used to express this topic.\n",
    "    There may be more than one word to express the same topic and one word may be used to express multiple topics.\n",
    "\n",
    "\n",
    "Table: Posts\n",
    "\n",
    "    +-------------+---------+\n",
    "    | Column Name | Type    |\n",
    "    +-------------+---------+\n",
    "    | post_id     | int     |\n",
    "    | content     | varchar |\n",
    "    +-------------+---------+\n",
    "    post_id is the primary key (column with unique values) for this table.\n",
    "    Each row of this table contains the ID of a post and its content.\n",
    "    Content will consist only of English letters and spaces.\n",
    " \n",
    "\n",
    "    Leetcode has collected some posts from its social media website and is interested in finding the topics of each post. Each topic can be expressed by one or more keywords. If a keyword of a certain topic exists in the content of a post (case insensitive) then the post has this topic.\n",
    "\n",
    "    Write a solution to find the topics of each post according to the following rules:\n",
    "\n",
    "    If the post does not have keywords from any topic, its topic should be \"Ambiguous!\".\n",
    "    If the post has at least one keyword of any topic, its topic should be a string of the IDs of its topics sorted in ascending order and separated by commas ','. The string should not contain duplicate IDs.\n",
    "    Return the result table in any order.\n",
    "\n",
    "The result format is in the following example.\n",
    "\n",
    " \n",
    "\n",
    "Example 1:\n",
    "\n",
    "Input: \n",
    "Keywords table:\n",
    "\n",
    "    +----------+----------+\n",
    "    | topic_id | word     |\n",
    "    +----------+----------+\n",
    "    | 1        | handball |\n",
    "    | 1        | football |\n",
    "    | 3        | WAR      |\n",
    "    | 2        | Vaccine  |\n",
    "    +----------+----------+\n",
    "    \n",
    "Posts table:\n",
    "\n",
    "    +---------+------------------------------------------------------------------------+\n",
    "    | post_id | content                                                                |\n",
    "    +---------+------------------------------------------------------------------------+\n",
    "    | 1       | We call it soccer They call it football hahaha                         |\n",
    "    | 2       | Americans prefer basketball while Europeans love handball and football |\n",
    "    | 3       | stop the war and play handball                                         |\n",
    "    | 4       | warning I planted some flowers this morning and then got vaccinated    |\n",
    "    +---------+------------------------------------------------------------------------+\n",
    "Output: \n",
    "\n",
    "    +---------+------------+\n",
    "    | post_id | topic      |\n",
    "    +---------+------------+\n",
    "    | 1       | 1          |\n",
    "    | 2       | 1          |\n",
    "    | 3       | 1,3        |\n",
    "    | 4       | Ambiguous! |\n",
    "    +---------+------------+\n",
    "    \n",
    "Explanation: \n",
    "\n",
    "    1: \"We call it soccer They call it football hahaha\"\n",
    "    \"football\" expresses topic 1. There is no other word that expresses any other topic.\n",
    "\n",
    "    2: \"Americans prefer basketball while Europeans love handball and football\"\n",
    "    \"handball\" expresses topic 1. \"football\" expresses topic 1. \n",
    "    There is no other word that expresses any other topic.\n",
    "\n",
    "    3: \"stop the war and play handball\"\n",
    "    \"war\" expresses topic 3. \"handball\" expresses topic 1.\n",
    "    There is no other word that expresses any other topic.\n",
    "\n",
    "    4: \"warning I planted some flowers this morning and then got vaccinated\"\n",
    "    There is no word in this sentence that expresses any topic. Note that \"warning\" is different from \"war\" although they have a common prefix. \n",
    "    This post is ambiguous.\n",
    "\n",
    "    Note that it is okay to have one word that expresses more than one topic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f7d3705",
   "metadata": {},
   "outputs": [],
   "source": [
    "SELECT \n",
    "    P.post_id, \n",
    "    IFNULL(GROUP_CONCAT(DISTINCT K.topic_id ORDER BY K.topic_id), 'Ambiguous!') AS topic\n",
    "FROM Posts AS P\n",
    "LEFT JOIN Keywords AS K\n",
    "ON CONCAT(' ', LOWER(P.content), ' ') LIKE CONCAT('% ', LOWER(K.word), ' %')\n",
    "GROUP BY P.post_id;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebc41816",
   "metadata": {},
   "source": [
    "Breakdown of the MySQL Query\n",
    "\n",
    "Selecting Required Columns:\n",
    "\n",
    "    The query selects P.post_id from the Posts table.\n",
    "    The topic column is derived from the GROUP_CONCAT function, which concatenates distinct topic_ids associated with each post.\n",
    "    \n",
    "Handling Topics with IFNULL:\n",
    "\n",
    "    The IFNULL function is used to return 'Ambiguous!' if there are no topic_ids found for a post. This ensures that posts without any matching keywords clearly indicate ambiguity.\n",
    "\n",
    "Joining Keywords with Posts:\n",
    "\n",
    "    A LEFT JOIN connects the Posts table (P) with the Keywords table (K).\n",
    "    The join condition uses a LIKE statement to match keywords in a case-insensitive manner. The CONCAT function adds spaces around both the post content and the keyword, ensuring that only whole words are matched (e.g., it prevents partial matches like 'hand' in 'handball').\n",
    "    \n",
    "Grouping and Concatenating Results:\n",
    "\n",
    "    The results are grouped by P.post_id, ensuring that each post appears only once in the output.\n",
    "    GROUP_CONCAT(DISTINCT K.topic_id ORDER BY K.topic_id) is used to combine multiple topic IDs into a single string, ordered by topic_id.\n",
    "    \n",
    "Explanation of Edge Cases and Complexity Analysis\n",
    "\n",
    "Edge Cases Considered:\n",
    "\n",
    "    No Keywords Match: If a post contains no keywords from the Keywords table, the IFNULL function ensures that the output will be 'Ambiguous!'.\n",
    "    Multiple Topics: If a post contains keywords that map to different topics, all distinct topic IDs will be concatenated and returned.\n",
    "    Non-distinct Keywords: If a post includes multiple instances of the same keyword, they will only be counted once due to the use of DISTINCT in GROUP_CONCAT.\n",
    "\n",
    "Complexity Analysis:\n",
    "\n",
    "    Time Complexity: The time complexity is approximately O(M * N), where M is the number of posts and N is the number of keywords. This complexity arises from the need to check each keyword against the content of each post.\n",
    "    Space Complexity: The space complexity is O(P + K), where P is the number of posts and K is the number of unique topic IDs that might need to be stored in memory for concatenation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f99c6b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your PostgreSQL query statement below\n",
    "\n",
    "with words as (\n",
    "    Select\n",
    "    post_id,\n",
    "    unnest(string_to_array(lower(content),' ')) as content\n",
    "    from\n",
    "    Posts\n",
    "),\n",
    "valid as (\n",
    "    Select distinct\n",
    "    post_id, \n",
    "    topic_id\n",
    "    from\n",
    "    words w \n",
    "    left join keywords kw on w.content = lower(kw.word)\n",
    "    order by post_id, topic_id\n",
    "),\n",
    "combine as \n",
    "(\n",
    "    Select \n",
    "    post_id,\n",
    "    string_agg(topic_id::text,',') as topic\n",
    "    from \n",
    "    valid\n",
    "    group by post_id\n",
    ")\n",
    "select\n",
    "post_id,\n",
    "case when topic is null then 'Ambiguous!'\n",
    "else topic end as topic\n",
    "from\n",
    "combine\n",
    "order by post_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d81412c7",
   "metadata": {},
   "source": [
    "Explanation of the Query\n",
    "\n",
    "This query determines relevant topics for each post based on keyword matches within the post content. It’s structured in multiple Common Table Expressions (CTEs) to break down each transformation and aggregation step.\n",
    "\n",
    "words CTE:\n",
    "\n",
    "    Purpose: Split each post's content into individual words (lowercased) so that they can be matched with keywords.\n",
    "    Operation: unnest(string_to_array(...)) splits the content into an array of words, then unnests them into separate rows for each post_id.\n",
    "    Complexity: Assuming there are n posts and each post has an average of m words, this step has O(n * m) complexity due to unnesting each word in each post.\n",
    "\n",
    "valid CTE:\n",
    "\n",
    "    Purpose: Identify valid topic matches by joining the words from each post with keywords.\n",
    "    Operation: A LEFT JOIN between words and keywords is performed to find matches between the lowercased word and the keywords.\n",
    "    Complexity: For k keywords and n * m rows from words, the join has approximately O((n * m) * k) complexity, assuming no indexing optimizations.\n",
    "    \n",
    "Output: Produces distinct combinations of post_id and topic_id, ensuring that each relevant topic for a post appears only once.\n",
    "\n",
    "combine CTE:\n",
    "\n",
    "    Purpose: Aggregate topic IDs for each post_id into a single comma-separated string.\n",
    "    Operation: Uses STRING_AGG to concatenate the distinct topic_ids for each post_id.\n",
    "    Complexity: Since combine processes O(n) post IDs and aggregates topics per post, the complexity here is roughly O(n).\n",
    "Final SELECT Statement:\n",
    "\n",
    "    Purpose: Produce the final output where each post_id has either a list of associated topics or the label \"Ambiguous!\" if no topics were found.\n",
    "    Operation: Uses a CASE statement to replace NULL topic lists with \"Ambiguous!\".\n",
    "    Complexity: This step is O(n) as it scans each post ID to check for NULL values.\n",
    "    Complexity Summary\n",
    "    The overall time complexity of the query is dominated by the valid CTE join, giving an approximate total complexity of O(n * m * k).\n",
    "\n",
    "Edge Cases\n",
    "\n",
    "No Keywords Match a Post:\n",
    "\n",
    "    If a post contains no words that match any keywords, it will have no topic_id in the valid CTE, and the final output will show \"Ambiguous!\" for that post_id.\n",
    "Case Sensitivity:\n",
    "\n",
    "    All comparisons are case-insensitive due to the use of LOWER() on both content and keywords. This prevents case mismatches from affecting the output.\n",
    "Empty Content:\n",
    "\n",
    "    Posts with empty content fields will have no rows generated in words and will ultimately appear as \"Ambiguous!\" in the final output.\n",
    "Multiple Matches per Post:\n",
    "\n",
    "    Posts containing multiple Tinstances of the same keyword still show only one instance per topic due to the use of DISTINCT in the valid CTE. his avoids duplicate topic_ids in the final list.\n",
    "No Topics in Keywords Table:\n",
    "\n",
    "    If the keywords table is empty, all posts will be marked as \"Ambiguous!\" since no matches can occur.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2feed4ce",
   "metadata": {},
   "source": [
    "# Number of Comments per Post\n",
    " \n",
    "Table: Submissions\n",
    "\n",
    "    +---------------+----------+\n",
    "    | Column Name   | Type     |\n",
    "    +---------------+----------+\n",
    "    | sub_id        | int      |\n",
    "    | parent_id     | int      |\n",
    "    +---------------+----------+\n",
    "This table may have duplicate rows.\n",
    "Each row can be a post or comment on the post.\n",
    "parent_id is null for posts.\n",
    "parent_id for comments is sub_id for another post in the table.\n",
    " \n",
    "\n",
    "Write a solution to find the number of comments per post. The result table should contain post_id and its corresponding number_of_comments.\n",
    "\n",
    "The Submissions table may contain duplicate comments. You should count the number of unique comments per post.\n",
    "\n",
    "The Submissions table may contain duplicate posts. You should treat them as one post.\n",
    "\n",
    "The result table should be ordered by post_id in ascending order.\n",
    "\n",
    "The result format is in the following example.\n",
    "\n",
    " \n",
    "\n",
    "Example 1:\n",
    "\n",
    "Input: \n",
    "Submissions table:\n",
    "\n",
    "    +---------+------------+\n",
    "    | sub_id  | parent_id  |\n",
    "    +---------+------------+\n",
    "    | 1       | Null       |\n",
    "    | 2       | Null       |\n",
    "    | 1       | Null       |\n",
    "    | 12      | Null       |\n",
    "    | 3       | 1          |\n",
    "    | 5       | 2          |\n",
    "    | 3       | 1          |\n",
    "    | 4       | 1          |\n",
    "    | 9       | 1          |\n",
    "    | 10      | 2          |\n",
    "    | 6       | 7          |\n",
    "    +---------+------------+\n",
    "Output: \n",
    "\n",
    "    +---------+--------------------+\n",
    "    | post_id | number_of_comments |\n",
    "    +---------+--------------------+\n",
    "    | 1       | 3                  |\n",
    "    | 2       | 2                  |\n",
    "    | 12      | 0                  |\n",
    "    +---------+--------------------+\n",
    "Explanation: \n",
    "The post with id 1 has three comments in the table with id 3, 4, and 9. The comment with id 3 is repeated in the table, we counted it only once.\n",
    "The post with id 2 has two comments in the table with id 5 and 10.\n",
    "The post with id 12 has no comments in the table.\n",
    "The comment with id 6 is a comment on a deleted post with id 7 so we ignored it.\n",
    "\n",
    "Explanation\n",
    "\n",
    "Identify Unique Posts:\n",
    "\n",
    "    The unique_posts CTE extracts unique parent_ids to find posts that have comments. We filter out any NULL values, ensuring that we only consider valid posts.\n",
    "    \n",
    "Count Unique Comments:\n",
    "\n",
    "    The comment_counts CTE counts the unique comments associated with each post (via parent_id). We ensure to count distinct comments using COUNT(DISTINCT sub_id), grouping the results by parent_id.\n",
    "    \n",
    "Post Identification:\n",
    "\n",
    "    The primary selection now directly generates unique post IDs by selecting distinct sub_ids from the Submissions table where parent_id is NULL. This ensures we are considering only those IDs that represent posts, which corresponds to the expected output structure.\n",
    "    \n",
    "Combine Results:\n",
    "\n",
    "    A LEFT JOIN is performed between the unique post IDs and the comment counts. The COALESCE function is used to return 0 for posts with no comments.\n",
    "    \n",
    "Order Results:\n",
    "\n",
    "    Finally, results are ordered by post_id in ascending order.\n",
    "    \n",
    "Edge Cases\n",
    "\n",
    "    Posts with No Comments: Posts without any comments (e.g., post_id 12) should appear with a count of 0.\n",
    "    Handling Duplicate Comments: The counting should ensure that if multiple identical comments are associated with a post, they are counted only once.\n",
    "    Null Parent IDs: The query must correctly filter out NULL values from the parent_id column to focus solely on valid posts.\n",
    "    \n",
    "Complexity Analysis\n",
    "\n",
    "    Time Complexity: The revised solution maintains a time complexity of O(n + m), where n is the number of rows in the Submissions table and m is the number of unique posts. The key operations include:\n",
    "        Extracting unique parent_ids and counting distinct sub_ids.\n",
    "        Joining the results to aggregate comments.\n",
    "        Space Complexity: The space complexity is O(m + k), where m is the number of unique posts and k is the number of unique comments stored in the temporary structures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e957d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "-- Write your PostgreSQL query statement below\n",
    "WITH unique_posts AS (\n",
    "    SELECT DISTINCT parent_id AS post_id\n",
    "    FROM Submissions\n",
    "    WHERE parent_id IS NOT NULL\n",
    "),\n",
    "comment_counts AS (\n",
    "    SELECT parent_id AS post_id, COUNT(DISTINCT sub_id) AS number_of_comments\n",
    "    FROM Submissions\n",
    "    WHERE parent_id IS NOT NULL\n",
    "    GROUP BY parent_id\n",
    ")\n",
    "SELECT \n",
    "    p.post_id,\n",
    "    COALESCE(c.number_of_comments, 0) AS number_of_comments\n",
    "FROM \n",
    "    (SELECT DISTINCT sub_id AS post_id FROM Submissions WHERE parent_id IS NULL) p\n",
    "LEFT JOIN \n",
    "    comment_counts c ON p.post_id = c.post_id\n",
    "ORDER BY \n",
    "    p.post_id;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae9758d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your MySQL query statement below\n",
    "WITH unique_posts AS (\n",
    "    SELECT DISTINCT parent_id AS post_id\n",
    "    FROM Submissions\n",
    "    WHERE parent_id IS NOT NULL\n",
    "),\n",
    "comment_counts AS (\n",
    "    SELECT parent_id AS post_id, COUNT(DISTINCT sub_id) AS number_of_comments\n",
    "    FROM Submissions\n",
    "    WHERE parent_id IS NOT NULL\n",
    "    GROUP BY parent_id\n",
    ")\n",
    "SELECT \n",
    "    p.post_id,\n",
    "    COALESCE(c.number_of_comments, 0) AS number_of_comments\n",
    "FROM \n",
    "    (SELECT DISTINCT sub_id AS post_id FROM Submissions WHERE parent_id IS NULL) p\n",
    "LEFT JOIN \n",
    "    comment_counts c ON p.post_id = c.post_id\n",
    "ORDER BY \n",
    "    p.post_id;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d5657a",
   "metadata": {},
   "source": [
    "# Strong Friendship\n",
    " \n",
    "Table: Friendship\n",
    "\n",
    "    +-------------+------+\n",
    "    | Column Name | Type |\n",
    "    +-------------+------+\n",
    "    | user1_id    | int  |\n",
    "    | user2_id    | int  |\n",
    "    +-------------+------+\n",
    "    (user1_id, user2_id) is the primary key (combination of columns with unique values) for this table.\n",
    "    Each row of this table indicates that the users user1_id and user2_id are friends.\n",
    "    Note that user1_id < user2_id.\n",
    " \n",
    "\n",
    "    A friendship between a pair of friends x and y is strong if x and y have at least three common friends.\n",
    "\n",
    "    Write a solution to find all the strong friendships.\n",
    "\n",
    "    Note that the result table should not contain duplicates with user1_id < user2_id.\n",
    "\n",
    "    Return the result table in any order.\n",
    "\n",
    "    The result format is in the following example.\n",
    "\n",
    " \n",
    "\n",
    "Example 1:\n",
    "\n",
    "Input: \n",
    "Friendship table:\n",
    "\n",
    "    +----------+----------+\n",
    "    | user1_id | user2_id |\n",
    "    +----------+----------+\n",
    "    | 1        | 2        |\n",
    "    | 1        | 3        |\n",
    "    | 2        | 3        |\n",
    "    | 1        | 4        |\n",
    "    | 2        | 4        |\n",
    "    | 1        | 5        |\n",
    "    | 2        | 5        |\n",
    "    | 1        | 7        |\n",
    "    | 3        | 7        |\n",
    "    | 1        | 6        |\n",
    "    | 3        | 6        |\n",
    "    | 2        | 6        |\n",
    "    +----------+----------+\n",
    "Output: \n",
    "\n",
    "    +----------+----------+---------------+\n",
    "    | user1_id | user2_id | common_friend |\n",
    "    +----------+----------+---------------+\n",
    "    | 1        | 2        | 4             |\n",
    "    | 1        | 3        | 3             |\n",
    "    +----------+----------+---------------+\n",
    "\n",
    "Explanation: \n",
    "\n",
    "    Users 1 and 2 have 4 common friends (3, 4, 5, and 6).\n",
    "    Users 1 and 3 have 3 common friends (2, 6, and 7).\n",
    "    We did not include the friendship of users 2 and 3 because they only have two common friends (1 and 6).\n",
    "    \n",
    "\n",
    "This SQL code is designed to find pairs of users who are friends and share at least three common friends. Below is an explanation of the code, including ideas, steps, edge cases, and complexity analysis.\n",
    "\n",
    "Explanation of the Code\n",
    "\n",
    "Common Table Expression (CTE) f:\n",
    " \n",
    "    The CTE f generates a list of friendships by selecting user pairs from the Friendship table.\n",
    "    The first query retrieves user1_id and user2_id directly, while the second query reverses the order, ensuring that friendships are bidirectional (i.e., friendship between user1 and user2 is represented both as (user1, user2) and (user2, user1)).\n",
    "    \n",
    "Main Query:\n",
    " \n",
    "    This part selects user pairs from the original Friendship table (a).\n",
    "    It joins the CTE f to find pairs of friends and their corresponding common friends.\n",
    "    The join conditions:\n",
    "        The first join (f b) finds friends of user1_id.\n",
    "        The second join (f c) matches user2_id with the second user's friends.\n",
    "    The count(c.user2_id) counts the common friends between user1 and user2.\n",
    "    Finally, it groups results by user pairs and filters for those pairs having at least three common friends using the HAVING clause.\n",
    "    \n",
    "Ideas\n",
    "\n",
    "    The purpose of this query is to identify friendships with a significant connection through mutual friends, which can be useful for social network analysis, recommendations, or understanding user connectivity in social platforms.\n",
    "    The approach leverages SQL's ability to handle sets and joins to efficiently determine relationships between data points.\n",
    "    \n",
    "Steps to Execute the Query\n",
    "\n",
    "    Define the common friends using a CTE to normalize the friendship data.\n",
    "    Join the friendship data back to the CTE to find pairs of friends and their common friends.\n",
    "    Count the number of common friends for each pair.\n",
    "    Filter the results to only include pairs with three or more common friends.\n",
    "    \n",
    "Edge Cases\n",
    "\n",
    "    No Common Friends: If no pairs have at least three common friends, the result will be an empty set.\n",
    "    Self-Friendships: If a user is listed as their own friend, this could affect counts if not handled correctly (typically, self-references should be excluded).\n",
    "    Duplicate Entries: If the Friendship table contains duplicate entries for the same friendship, this could inflate the count of common friends unless distinct pairs are ensured.\n",
    "    Zero Friendship Records: If there are no entries in the Friendship table, the query will return an empty result set.\n",
    "Complexity Analysis\n",
    "\n",
    "Time Complexity: The complexity mainly arises from the joins and the counting of common friends. Assuming n is the number of rows in the Friendship table:\n",
    "\n",
    "    The CTE f will create approximately 2n rows.\n",
    "    The joins could lead to n^2 complexity in the worst case (if every user is friends with every other user).\n",
    "    The final grouping and counting will also contribute to complexity, leading to an overall time complexity of O(n^ 2) in the worst-case scenario.\n",
    "\n",
    "Space Complexity: The CTE f uses space proportional to the number of friendships (up to 2n rows), plus additional space for the join results. Thus, space complexity can also reach  O(n)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ca3ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your MySQL/postgresSQL query statement below\n",
    "with f as (\n",
    "    select user1_id, user2_id \n",
    "    from Friendship\n",
    "    \n",
    "    union \n",
    "    \n",
    "    select user2_id user1_id, user1_id user2_id\n",
    "    from Friendship\n",
    ")\n",
    "\n",
    "select a.user1_id, a.user2_id, count(c.user2_id) common_friend\n",
    "from Friendship a \n",
    "join f b \n",
    "on a.user1_id = b.user1_id  \n",
    "join f c \n",
    "on a.user2_id = c.user1_id  \n",
    "and b.user2_id = c.user2_id  \n",
    "group by a.user1_id, a.user2_id\n",
    "having count(c.user2_id) >= 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "264b93d1",
   "metadata": {},
   "source": [
    "# Fix Names in a Table\n",
    " \n",
    "Table: Users\n",
    "\n",
    "    +----------------+---------+\n",
    "    | Column Name    | Type    |\n",
    "    +----------------+---------+\n",
    "    | user_id        | int     |\n",
    "    | name           | varchar |\n",
    "    +----------------+---------+\n",
    "user_id is the primary key (column with unique values) for this table.\n",
    "This table contains the ID and the name of the user. The name consists of only lowercase and uppercase characters.\n",
    " \n",
    "\n",
    "Write a solution to fix the names so that only the first character is uppercase and the rest are lowercase.\n",
    "\n",
    "Return the result table ordered by user_id.\n",
    "\n",
    "The result format is in the following example.\n",
    "\n",
    " \n",
    "\n",
    "Example 1:\n",
    "\n",
    "Input: \n",
    "Users table:\n",
    "    \n",
    "    +---------+-------+\n",
    "    | user_id | name  |\n",
    "    +---------+-------+\n",
    "    | 1       | aLice |\n",
    "    | 2       | bOB   |\n",
    "    +---------+-------+\n",
    "Output: \n",
    "\n",
    "    +---------+-------+\n",
    "    | user_id | name  |\n",
    "    +---------+-------+\n",
    "    | 1       | Alice |\n",
    "    | 2       | Bob   |\n",
    "    +---------+-------+\n",
    "    \n",
    "Explanation\n",
    "\n",
    "    UPPER(SUBSTRING(name, 1, 1)): This part of the query takes the first character of the name and converts it to uppercase.\n",
    "\n",
    "    SUBSTRING(name, 1, 1) extracts the first character of the name.\n",
    "    LOWER(SUBSTRING(name, 2)): This converts the rest of the name to lowercase.\n",
    "\n",
    "    SUBSTRING(name, 2) extracts the substring starting from the second character to the end.\n",
    "    CONCAT(...): This function combines the uppercase first character with the lowercase substring to form the corrected name.\n",
    "\n",
    "    ORDER BY user_id: Finally, the results are ordered by the user_id to meet the specified output format.\n",
    "    \n",
    "Edge Cases\n",
    "\n",
    "    Empty Strings: If the name field is an empty string (''), the query should handle it gracefully. The output should remain an empty string.\n",
    "    Null Values: If there are NULL values in the name column, the query should ensure that these are handled properly. The result could return NULL for those entries.\n",
    "    Single Character Names: Names consisting of a single character (e.g., 'a', 'b') should be transformed correctly to 'A', 'B'.\n",
    "    Names Already Correctly Formatted: If names are already in the correct format (e.g., 'Alice', 'Bob'), the query should leave them unchanged.\n",
    "    Leading/Trailing Spaces: Names with leading or trailing whitespace (e.g., ' Alice ' or 'Bob ') should ideally be trimmed. You may want to include a TRIM() function to handle this.\n",
    "    Case Variations: Names with unusual casing (e.g., 'aLiCe', 'bOB', or even mixed case like 'AlIce') should all be transformed to the proper format.\n",
    "    \n",
    "Complexity Analysis\n",
    "\n",
    "Time Complexity:\n",
    "\n",
    "    The time complexity for this query is generally O(n), where n is the number of rows in the Users table. This is because the query processes each row to apply the string functions.\n",
    "    Each string manipulation (like SUBSTRING, UPPER, and LOWER) generally operates in constant time with respect to the length of the string. Therefore, the overall complexity remains linear with respect to the number of rows.\n",
    "Space Complexity:\n",
    "\n",
    "    The space complexity is O(n) for the output, where n is again the number of rows in the Users table. This is due to the need to store the transformed names for each user in the result set.\n",
    "    If the database engine uses temporary storage for intermediate results, that might also contribute to additional space usage, but it is typically bounded by the size of the output."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a63376",
   "metadata": {},
   "source": [
    "Average Time of Process per Machine\n",
    " \n",
    "Table: Activity\n",
    "\n",
    "    +----------------+---------+\n",
    "    | Column Name    | Type    |\n",
    "    +----------------+---------+\n",
    "    | machine_id     | int     |\n",
    "    | process_id     | int     |\n",
    "    | activity_type  | enum    |\n",
    "    | timestamp      | float   |\n",
    "    +----------------+---------+\n",
    "    The table shows the user activities for a factory website.\n",
    "    (machine_id, process_id, activity_type) is the primary key (combination of columns with unique values) of this table.\n",
    "    machine_id is the ID of a machine.\n",
    "    process_id is the ID of a process running on the machine with ID machine_id.\n",
    "    activity_type is an ENUM (category) of type ('start', 'end').\n",
    "    timestamp is a float representing the current time in seconds.\n",
    "    'start' means the machine starts the process at the given timestamp and 'end' means the machine ends the process at the given timestamp.\n",
    "    The 'start' timestamp will always be before the 'end' timestamp for every (machine_id, process_id) pair.\n",
    "    It is guaranteed that each (machine_id, process_id) pair has a 'start' and 'end' timestamp.\n",
    " \n",
    "\n",
    "    There is a factory website that has several machines each running the same number of processes. Write a solution to find the average time each machine takes to complete a process.\n",
    "\n",
    "    The time to complete a process is the 'end' timestamp minus the 'start' timestamp. The average time is calculated by the total time to complete every process on the machine divided by the number of processes that were run.\n",
    "\n",
    "    The resulting table should have the machine_id along with the average time as processing_time, which should be rounded to 3 decimal places.\n",
    "\n",
    "    Return the result table in any order.\n",
    "\n",
    "    The result format is in the following example.\n",
    "\n",
    " \n",
    "\n",
    "Example 1:\n",
    "\n",
    "Input: \n",
    "Activity table:\n",
    "\n",
    "    +------------+------------+---------------+-----------+\n",
    "    | machine_id | process_id | activity_type | timestamp |\n",
    "    +------------+------------+---------------+-----------+\n",
    "    | 0          | 0          | start         | 0.712     |\n",
    "    | 0          | 0          | end           | 1.520     |\n",
    "    | 0          | 1          | start         | 3.140     |\n",
    "    | 0          | 1          | end           | 4.120     |\n",
    "    | 1          | 0          | start         | 0.550     |\n",
    "    | 1          | 0          | end           | 1.550     |\n",
    "    | 1          | 1          | start         | 0.430     |\n",
    "    | 1          | 1          | end           | 1.420     |\n",
    "    | 2          | 0          | start         | 4.100     |\n",
    "    | 2          | 0          | end           | 4.512     |\n",
    "    | 2          | 1          | start         | 2.500     |\n",
    "    | 2          | 1          | end           | 5.000     |\n",
    "    +------------+------------+---------------+-----------+\n",
    "Output: \n",
    "\n",
    "    +------------+-----------------+\n",
    "    | machine_id | processing_time |\n",
    "    +------------+-----------------+\n",
    "    | 0          | 0.894           |\n",
    "    | 1          | 0.995           |\n",
    "    | 2          | 1.456           |\n",
    "    +------------+-----------------+\n",
    "Explanation: \n",
    "\n",
    "    There are 3 machines running 2 processes each.\n",
    "    Machine 0's average time is ((1.520 - 0.712) + (4.120 - 3.140)) / 2 = 0.894\n",
    "    Machine 1's average time is ((1.550 - 0.550) + (1.420 - 0.430)) / 2 = 0.995\n",
    "    Machine 2's average time is ((4.512 - 4.100) + (5.000 - 2.500)) / 2 = 1.456.\n",
    "    \n",
    "Explanation of the Query\n",
    "\n",
    "Inner Subquery:\n",
    "\n",
    "    The inner subquery calculates the start and end timestamps for each process for each machine.\n",
    "    It selects the machine_id and process_id.\n",
    "    The MAX function retrieves the end timestamp for each process (when activity_type is 'end').\n",
    "    The MIN function retrieves the start timestamp for each process (when activity_type is 'start').\n",
    "    The results are grouped by machine_id and process_id to get a unique start and end time for each process.\n",
    "Outer Query:\n",
    "\n",
    "    The outer query computes the average processing time by subtracting the start_time from the end_time.\n",
    "    It rounds the average processing time to three decimal places using the ROUND function.\n",
    "    Finally, it groups the results by machine_id to return the average processing time for each machine.\n",
    "    \n",
    "Edge Cases to Consider\n",
    "\n",
    "    Incomplete Data: If there are processes without corresponding start or end entries, they will not contribute to the average calculation.\n",
    "    Duplicate Entries: Ensure that there are no duplicate entries for the same process that could distort the calculations.\n",
    "    No Processes: If a machine has no recorded processes, it will not appear in the result.\n",
    "    Invalid Timestamps: Define how to handle invalid timestamps, such as negative values or cases where the end timestamp is earlier than the start timestamp.\n",
    "\n",
    "Complexity Analysis\n",
    "\n",
    "Time Complexity:\n",
    "\n",
    "    The time complexity is still O(n), where n is the number of rows in the Activity table. We process each row to calculate the necessary timestamps and averages.\n",
    "\n",
    "Space Complexity:\n",
    "\n",
    "    The space complexity remains O(m), where m is the number of unique processes (or machines) being tracked. This is due to the temporary storage for processing times in the inner subquery before calculating the final averages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "566c7c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your MySQL query statement below\n",
    "SELECT \n",
    "    machine_id,\n",
    "    ROUND(AVG(end_time - start_time), 3) AS processing_time\n",
    "FROM (\n",
    "    SELECT \n",
    "        machine_id,\n",
    "        process_id,\n",
    "        MAX(CASE WHEN activity_type = 'end' THEN timestamp END) AS end_time,\n",
    "        MIN(CASE WHEN activity_type = 'start' THEN timestamp END) AS start_time\n",
    "    FROM \n",
    "        Activity\n",
    "    GROUP BY \n",
    "        machine_id, process_id\n",
    ") AS ProcessTimes\n",
    "GROUP BY \n",
    "    machine_id;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0482322f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your PostgreSQL query statement below\n",
    "SELECT \n",
    "    machine_id,\n",
    "    ROUND(AVG(end_time - start_time)::decimal, 3) AS processing_time\n",
    "FROM (\n",
    "    SELECT \n",
    "        machine_id,\n",
    "        process_id,\n",
    "        MAX(CASE WHEN activity_type = 'end' THEN timestamp END) AS end_time,\n",
    "        MIN(CASE WHEN activity_type = 'start' THEN timestamp END) AS start_time\n",
    "    FROM \n",
    "        Activity\n",
    "    GROUP BY \n",
    "        machine_id, process_id\n",
    ") AS ProcessTimes\n",
    "GROUP BY \n",
    "    machine_id;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b1cdea",
   "metadata": {},
   "source": [
    "# ads Performance\n",
    " \n",
    "Table: Ads\n",
    "\n",
    "    +---------------+---------+\n",
    "    | Column Name   | Type    |\n",
    "    +---------------+---------+\n",
    "    | ad_id         | int     |\n",
    "    | user_id       | int     |\n",
    "    | action        | enum    |\n",
    "    +---------------+---------+\n",
    "    (ad_id, user_id) is the primary key (combination of columns with unique values) for this table.\n",
    "    Each row of this table contains the ID of an Ad, the ID of a user, and the action taken by this user regarding this Ad.\n",
    "    The action column is an ENUM (category) type of ('Clicked', 'Viewed', 'Ignored').\n",
    "\n",
    "\n",
    "    A company is running Ads and wants to calculate the performance of each Ad.\n",
    "\n",
    "    Performance of the Ad is measured using Click-Through Rate (CTR) where:\n",
    "\n",
    "    CTR = (Number of Clicks + Number of Views/ Number of Clicks) ×100\n",
    "\n",
    " \n",
    "    Write a solution to find the ctr of each Ad. Round ctr to two decimal points.\n",
    "\n",
    "    Return the result table ordered by ctr in descending order and by ad_id in ascending order in case of a tie.\n",
    "\n",
    "    The result format is in the following example.\n",
    "\n",
    " \n",
    "\n",
    "Example 1:\n",
    "\n",
    "Input: \n",
    "Ads table:\n",
    "\n",
    "    +-------+---------+---------+\n",
    "    | ad_id | user_id | action  |\n",
    "    +-------+---------+---------+\n",
    "    | 1     | 1       | Clicked |\n",
    "    | 2     | 2       | Clicked |\n",
    "    | 3     | 3       | Viewed  |\n",
    "    | 5     | 5       | Ignored |\n",
    "    | 1     | 7       | Ignored |\n",
    "    | 2     | 7       | Viewed  |\n",
    "    | 3     | 5       | Clicked |\n",
    "    | 1     | 4       | Viewed  |\n",
    "    | 2     | 11      | Viewed  |\n",
    "    | 1     | 2       | Clicked |\n",
    "    +-------+---------+---------+\n",
    "Output: \n",
    "\n",
    "    +-------+-------+\n",
    "    | ad_id | ctr   |\n",
    "    +-------+-------+\n",
    "    | 1     | 66.67 |\n",
    "    | 3     | 50.00 |\n",
    "    | 2     | 33.33 |\n",
    "    | 5     | 0.00  |\n",
    "    +-------+-------+\n",
    "Explanation: \n",
    "\n",
    "    for ad_id = 1, ctr = (2/(2+1)) * 100 = 66.67\n",
    "    for ad_id = 2, ctr = (1/(1+2)) * 100 = 33.33\n",
    "    for ad_id = 3, ctr = (1/(1+1)) * 100 = 50.00\n",
    "    for ad_id = 5, ctr = 0.00, Note that ad_id = 5 has no clicks or views.\n",
    "    Note that we do not care about Ignored Ads.\n",
    "    \n",
    "1. Problem Understanding and Key Idea\n",
    "    We need to calculate the click-through rate (CTR) for each ad.\n",
    "    CTR formula: \n",
    "    CTR = (Number of Clicks + Number of Views/ Number of Clicks) ×100\n",
    "    Goal: Output each ad's CTR, ordered by CTR in descending order and by ad_id ascending when CTRs are tied.\n",
    "    \n",
    "2. Steps to Approach the Problem\n",
    "    Step 1: Filter only relevant actions (Clicked and Viewed) because Ignored doesn’t affect CTR.\n",
    "    Step 2: For each ad_id, count the number of Clicked and Viewed actions:\n",
    "        Use CASE statements to count the number of clicks (action = 'Clicked') and views (action = 'Viewed').\n",
    "    Step 3: Calculate CTR by dividing the number of clicks by the sum of clicks and views.\n",
    "    Step 4: Round CTR to two decimal points, and handle division by zero by defaulting CTR to 0 for ads with no views or clicks.\n",
    "    Step 5: Order results by ctr in descending order, then by ad_id in ascending order.\n",
    "    \n",
    "3. SQL Solution\n",
    "    Here’s the SQL query that follows these steps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d91eca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "SELECT \n",
    "    ad_id,\n",
    "    ROUND(COALESCE(SUM(CASE WHEN action = 'Clicked' THEN 1 ELSE 0 END) * 100.0 /\n",
    "           NULLIF(SUM(CASE WHEN action IN ('Clicked', 'Viewed') THEN 1 ELSE 0 END), 0), 0), 2) AS ctr\n",
    "FROM Ads\n",
    "GROUP BY ad_id\n",
    "ORDER BY ctr DESC, ad_id ASC;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd9637ea",
   "metadata": {},
   "source": [
    "4. Edge Cases\n",
    "    No Clicked or Viewed Actions: If an ad has no relevant actions, CTR should be 0. This is handled by NULLIF, which avoids division by zero.\n",
    "    Ads with Only Viewed Actions: If an ad has only views but no clicks, CTR should also be 0.\n",
    "    Ads with Only Clicked Actions: If an ad has only clicks, CTR will be 100% (since there are no views to lower it).\n",
    "    Ties in CTR: Multiple ads with the same CTR should be sorted by ad_id in ascending order.\n",
    "    \n",
    "5. Complexity Analysis\n",
    "    Time Complexity: O(N) where N is the number of rows in the Ads table, as we are grouping and aggregating by ad_id.\n",
    "    Space Complexity: O(M) where M is the number of unique ad_ids, as we need space to store counts for each ad.\n",
    "\n",
    "6. Follow-Up Questions\n",
    "\n",
    "    Q1: What if we wanted to track additional metrics for each ad, such as the total number of users who ignored it?\n",
    "    Answer: We could modify the query to include an additional CASE statement to count Ignored actions and return that as a separate column. This would allow us to track all actions (Clicked, Viewed, Ignored) in a single query.\n",
    "\n",
    "    Q2: How would you modify the query if the Ads table were extremely large?\n",
    "    Answer: We could create an index on ad_id and action to improve the performance of grouping and filtering actions. Alternatively, if this calculation needs to be done frequently, storing CTR values in a separate summary table that gets updated periodically (e.g., nightly) would reduce query time.\n",
    "\n",
    "    Q3: How would you handle rounding to more or fewer decimal places?\n",
    "    Answer: We can change the rounding precision by modifying the ROUND function. For example, ROUND(..., 1) for one decimal place or ROUND(..., 3) for three.\n",
    "\n",
    "    Q4: What would happen if there were duplicate rows with the same ad_id, user_id, and action?\n",
    "    Answer: Duplicates could inflate the counts, leading to inaccurate CTR calculations. To prevent this, we could add a DISTINCT clause within the SUM function or ensure data integrity by removing duplicates before aggregation.\n",
    "\n",
    "    Q5: What if the business wants a rolling CTR for each ad (e.g., over the last 7 days)?\n",
    "    Answer: We could add a date column to the Ads table and use it to filter records by date (e.g., WHERE date >= DATE_SUB(CURRENT_DATE, INTERVAL 7 DAY)). This would calculate CTR based on a recent timeframe."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "404f8a68",
   "metadata": {},
   "source": [
    "# Page Recommendations\n",
    " \n",
    "Table: Friendship\n",
    "\n",
    "    +---------------+---------+\n",
    "    | Column Name   | Type    |\n",
    "    +---------------+---------+\n",
    "    | user1_id      | int     |\n",
    "    | user2_id      | int     |\n",
    "    +---------------+---------+\n",
    "    (user1_id, user2_id) is the primary key (combination of columns with unique values) for this table.\n",
    "    Each row of this table indicates that there is a friendship relation between user1_id and user2_id.\n",
    " \n",
    "\n",
    "Table: Likes\n",
    "\n",
    "    +-------------+---------+\n",
    "    | Column Name | Type    |\n",
    "    +-------------+---------+\n",
    "    | user_id     | int     |\n",
    "    | page_id     | int     |\n",
    "    +-------------+---------+\n",
    "    (user_id, page_id) is the primary key (combination of columns with unique values) for this table.\n",
    "    Each row of this table indicates that user_id likes page_id.\n",
    "\n",
    "\n",
    "    Write a solution to recommend pages to the user with user_id = 1 using the pages that your friends liked. It should not recommend pages you already liked.\n",
    "\n",
    "    Return result table in any order without duplicates.\n",
    "\n",
    "    The result format is in the following example.\n",
    "\n",
    " \n",
    "\n",
    "Example 1:\n",
    "\n",
    "Input: \n",
    "Friendship table:\n",
    "\n",
    "    +----------+----------+\n",
    "    | user1_id | user2_id |\n",
    "    +----------+----------+\n",
    "    | 1        | 2        |\n",
    "    | 1        | 3        |\n",
    "    | 1        | 4        |\n",
    "    | 2        | 3        |\n",
    "    | 2        | 4        |\n",
    "    | 2        | 5        |\n",
    "    | 6        | 1        |\n",
    "    +----------+----------+\n",
    "Likes table:\n",
    "\n",
    "    +---------+---------+\n",
    "    | user_id | page_id |\n",
    "    +---------+---------+\n",
    "    | 1       | 88      |\n",
    "    | 2       | 23      |\n",
    "    | 3       | 24      |\n",
    "    | 4       | 56      |\n",
    "    | 5       | 11      |\n",
    "    | 6       | 33      |\n",
    "    | 2       | 77      |\n",
    "    | 3       | 77      |\n",
    "    | 6       | 88      |\n",
    "    +---------+---------+\n",
    "Output: \n",
    "\n",
    "    +------------------+\n",
    "    | recommended_page |\n",
    "    +------------------+\n",
    "    | 23               |\n",
    "    | 24               |\n",
    "    | 56               |\n",
    "    | 33               |\n",
    "    | 77               |\n",
    "    +------------------+\n",
    "Explanation: \n",
    "\n",
    "    User one is friend with users 2, 3, 4 and 6.\n",
    "    Suggested pages are 23 from user 2, 24 from user 3, 56 from user 3 and 33 from user 6.\n",
    "    Page 77 is suggested from both user 2 and user 3.\n",
    "    Page 88 is not suggested because user 1 already likes it.\n",
    "    \n",
    "    \n",
    "1. Understanding the Relationships\n",
    "    Friendship Table: Indicates who is friends with whom.\n",
    "    Likes Table: Indicates which pages each user likes.\n",
    "    Goal: Find all unique pages liked by friends of user_id = 1, excluding pages that user_id = 1 already likes.\n",
    "2. Steps to Approach the Solution\n",
    "    Step 1: Identify friends of user_id = 1. We need both directions (user1_id and user2_id) in the Friendship table since friendships are bi-directional.\n",
    "    Step 2: Find pages liked by these friends (from the Likes table).\n",
    "    Step 3: Exclude pages that user_id = 1 already likes.\n",
    "3. SQL Solution\n",
    "    The solution joins tables to find recommended pages, then filters out pages already liked by user_id = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c54e238d",
   "metadata": {},
   "outputs": [],
   "source": [
    "WITH Friends AS (\n",
    "    SELECT \n",
    "        CASE \n",
    "            WHEN user1_id = 1 THEN user2_id \n",
    "            ELSE user1_id \n",
    "        END AS friend_id\n",
    "    FROM Friendship\n",
    "    WHERE 1 IN (user1_id, user2_id)\n",
    "),\n",
    "FriendLikes AS (\n",
    "    SELECT DISTINCT \n",
    "        L.page_id\n",
    "    FROM Likes L\n",
    "    JOIN Friends F ON L.user_id = F.friend_id\n",
    "),\n",
    "UserLikes AS (\n",
    "    SELECT \n",
    "        page_id\n",
    "    FROM Likes\n",
    "    WHERE user_id = 1\n",
    ")\n",
    "SELECT \n",
    "    page_id AS recommended_page\n",
    "FROM FriendLikes\n",
    "WHERE page_id NOT IN (SELECT page_id FROM UserLikes);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71d7f9ed",
   "metadata": {},
   "source": [
    "Explanation\n",
    "\n",
    "    Friends CTE: Identifies all friends of user_id = 1 by selecting user2_id if user1_id is 1, or user1_id if user2_id is 1.\n",
    "    FriendLikes CTE: Joins Friends with the Likes table to find all pages liked by friends.\n",
    "    UserLikes CTE: Selects pages that user_id = 1 already likes from the Likes table.\n",
    "    Final Query: Selects pages liked by friends (FriendLikes) that are not in UserLikes (i.e., pages that user_id = 1 hasn’t liked).\n",
    "    \n",
    "4. Edge Cases\n",
    "    No Friends: If user_id = 1 has no friends, there will be no recommendations.\n",
    "    Friends with No Likes: If friends haven’t liked any pages, the output will be empty.\n",
    "    All Pages Already Liked: If user_id = 1 has already liked all pages that friends like, there will be no recommendations.\n",
    "    \n",
    "5. Complexity Analysis\n",
    "    Time Complexity: O(F+L), where  F is the number of friendships and L is the number of likes. Each CTE involves scanning or joining tables, but proper indexing on user_id and page_id can optimize performance.\n",
    "    Space Complexity: O(F+L), as we store intermediate CTE results.\n",
    "6. Follow-Up Questions\n",
    "\n",
    "    Q1: What if the user wants recommendations based on only a subset of friends, such as close friends?\n",
    "    Answer: We could add an additional column (e.g., friendship_level) in the Friendship table and filter Friends based on this level.\n",
    "    Q2: How would you handle large datasets for this query?\n",
    "    Answer: Adding indexes on user_id and page_id in both Friendship and Likes tables would improve join performance. For very large datasets, a materialized view or periodic pre-calculated recommendation table could be created.\n",
    "    Q3: What if we need to rank the recommended pages by popularity among friends?\n",
    "    Answer: In FriendLikes, count likes for each page_id and order by the count in descending order."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72e1f4ee",
   "metadata": {},
   "source": [
    "# Trips and Users\n",
    " \n",
    "Table: Trips\n",
    "\n",
    "    +-------------+----------+\n",
    "    | Column Name | Type     |\n",
    "    +-------------+----------+\n",
    "    | id          | int      |\n",
    "    | client_id   | int      |\n",
    "    | driver_id   | int      |\n",
    "    | city_id     | int      |\n",
    "    | status      | enum     |\n",
    "    | request_at  | varchar  |     \n",
    "    +-------------+----------+\n",
    "    id is the primary key (column with unique values) for this table.\n",
    "    The table holds all taxi trips. Each trip has a unique id, while client_id and driver_id are foreign keys to the users_id at the Users table.\n",
    "    Status is an ENUM (category) type of ('completed', 'cancelled_by_driver', 'cancelled_by_client').\n",
    "\n",
    "\n",
    "Table: Users\n",
    "\n",
    "    +-------------+----------+\n",
    "    | Column Name | Type     |\n",
    "    +-------------+----------+\n",
    "    | users_id    | int      |\n",
    "    | banned      | enum     |\n",
    "    | role        | enum     |\n",
    "    +-------------+----------+\n",
    "    users_id is the primary key (column with unique values) for this table.\n",
    "    The table holds all users. Each user has a unique users_id, and role is an ENUM type of ('client', 'driver', 'partner').\n",
    "    banned is an ENUM (category) type of ('Yes', 'No').\n",
    "\n",
    "\n",
    "    The cancellation rate is computed by dividing the number of canceled (by client or driver) requests with unbanned users by the total number of requests with unbanned users on that day.\n",
    "\n",
    "    Write a solution to find the cancellation rate of requests with unbanned users (both client and driver must not be banned) each day between \"2013-10-01\" and \"2013-10-03\". Round Cancellation Rate to two decimal points.\n",
    "\n",
    "    Return the result table in any order.\n",
    "\n",
    "    The result format is in the following example.\n",
    "\n",
    " \n",
    "\n",
    "Example 1:\n",
    "\n",
    "Input: \n",
    "Trips table:\n",
    "\n",
    "    +----+-----------+-----------+---------+---------------------+------------+\n",
    "    | id | client_id | driver_id | city_id | status              | request_at |\n",
    "    +----+-----------+-----------+---------+---------------------+------------+\n",
    "    | 1  | 1         | 10        | 1       | completed           | 2013-10-01 |\n",
    "    | 2  | 2         | 11        | 1       | cancelled_by_driver | 2013-10-01 |\n",
    "    | 3  | 3         | 12        | 6       | completed           | 2013-10-01 |\n",
    "    | 4  | 4         | 13        | 6       | cancelled_by_client | 2013-10-01 |\n",
    "    | 5  | 1         | 10        | 1       | completed           | 2013-10-02 |\n",
    "    | 6  | 2         | 11        | 6       | completed           | 2013-10-02 |\n",
    "    | 7  | 3         | 12        | 6       | completed           | 2013-10-02 |\n",
    "    | 8  | 2         | 12        | 12      | completed           | 2013-10-03 |\n",
    "    | 9  | 3         | 10        | 12      | completed           | 2013-10-03 |\n",
    "    | 10 | 4         | 13        | 12      | cancelled_by_driver | 2013-10-03 |\n",
    "    +----+-----------+-----------+---------+---------------------+------------+\n",
    "Users table:\n",
    "\n",
    "    +----------+--------+--------+\n",
    "    | users_id | banned | role   |\n",
    "    +----------+--------+--------+\n",
    "    | 1        | No     | client |\n",
    "    | 2        | Yes    | client |\n",
    "    | 3        | No     | client |\n",
    "    | 4        | No     | client |\n",
    "    | 10       | No     | driver |\n",
    "    | 11       | No     | driver |\n",
    "    | 12       | No     | driver |\n",
    "    | 13       | No     | driver |\n",
    "    +----------+--------+--------+\n",
    "Output: \n",
    "\n",
    "    +------------+-------------------+\n",
    "    | Day        | Cancellation Rate |\n",
    "    +------------+-------------------+\n",
    "    | 2013-10-01 | 0.33              |\n",
    "    | 2013-10-02 | 0.00              |\n",
    "    | 2013-10-03 | 0.50              |\n",
    "    +------------+-------------------+\n",
    "Explanation: \n",
    "\n",
    "On 2013-10-01:\n",
    "  - There were 4 requests in total, 2 of which were canceled.\n",
    "  - However, the request with Id=2 was made by a banned client (User_Id=2), so it is ignored in the calculation.\n",
    "  - Hence there are 3 unbanned requests in total, 1 of which was canceled.\n",
    "  - The Cancellation Rate is (1 / 3) = 0.33\n",
    "On 2013-10-02:\n",
    "  - There were 3 requests in total, 0 of which were canceled.\n",
    "  - The request with Id=6 was made by a banned client, so it is ignored.\n",
    "  - Hence there are 2 unbanned requests in total, 0 of which were canceled.\n",
    "  - The Cancellation Rate is (0 / 2) = 0.00\n",
    "On 2013-10-03:\n",
    "  - There were 3 requests in total, 1 of which was canceled.\n",
    "  - The request with Id=8 was made by a banned client, so it is ignored.\n",
    "  - Hence there are 2 unbanned request in total, 1 of which were canceled.\n",
    "  - The Cancellation Rate is (1 / 2) = 0.50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b8f09b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your MySQL query statement below\n",
    "select Day, round(canceled/total, 2) as `Cancellation Rate`  from(\n",
    "select request_at as Day, \n",
    "\n",
    "sum(case when a.status like 'cancelled%' then 1 else 0 end) as canceled, count(id) as total\n",
    "\n",
    "from Trips a \n",
    "join Users cl on a.client_id = cl.users_id and cl.banned = \"No\"\n",
    "join Users dr on a.driver_id = dr.users_id and dr.banned = \"No\"\n",
    "where  request_at between '2013-10-01' and '2013-10-03'\n",
    "group by request_at\n",
    ")a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a972dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write your PostgreSQL query statement below\n",
    "SELECT Day, ROUND(canceled::numeric / total, 2) AS \"Cancellation Rate\"\n",
    "FROM (\n",
    "    SELECT \n",
    "        request_at AS Day, \n",
    "        SUM(CASE WHEN a.status LIKE 'cancelled%' THEN 1 ELSE 0 END) AS canceled, \n",
    "        COUNT(id) AS total\n",
    "    FROM Trips a \n",
    "    JOIN Users cl ON a.client_id = cl.users_id AND cl.banned = 'No'\n",
    "    JOIN Users dr ON a.driver_id = dr.users_id AND dr.banned = 'No'\n",
    "    WHERE request_at BETWEEN '2013-10-01' AND '2013-10-03'\n",
    "    GROUP BY request_at\n",
    ") a;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4814ae5",
   "metadata": {},
   "source": [
    "1. Objective\n",
    "    The query calculates the \"Cancellation Rate\" for each day within a specified date range. The \"Cancellation Rate\" is the ratio of canceled trips to the total trips, rounded to two decimal places.\n",
    "    It filters trips to include only those where both the client and driver are not banned.\n",
    "2. Step-by-Step Solution\n",
    "Step 1: Inner Query\n",
    "\n",
    "    Purpose: Aggregate trip data for each day by calculating the total number of trips and the number of canceled trips.\n",
    "\n",
    "    Grouping: We group by request_at to get daily data.\n",
    "\n",
    "    Calculations:\n",
    "\n",
    "    SUM(CASE WHEN a.status LIKE 'cancelled%' THEN 1 ELSE 0 END) AS canceled: Counts canceled trips for each day.\n",
    "    COUNT(id) AS total: Counts total trips for each day.\n",
    "    Filtering: Only trips where both the client (cl.banned = 'No') and driver (dr.banned = 'No') are included.\n",
    "\n",
    "    Date Range: Limits results to trips within '2013-10-01' to '2013-10-03'.\n",
    "\n",
    "Step 2: Outer Query\n",
    "\n",
    "    Purpose: Calculate and format the \"Cancellation Rate\" for each day.\n",
    "    Calculation: ROUND(canceled::numeric / total, 2) AS \"Cancellation Rate\":\n",
    "    Divides canceled by total and casts to numeric to allow rounding.\n",
    "    Rounds to two decimal places for clearer presentation.\n",
    "    Final Selection: Displays the date (Day) and the calculated Cancellation Rate as final columns.\n",
    "3. Edge Cases\n",
    "    No Trips on a Day: If there are no trips on a day within the range, that date won’t appear in the output.\n",
    "    All Trips Canceled: The Cancellation Rate will show as 1.00 if all trips on a day are canceled.\n",
    "    No Canceled Trips: If no trips are canceled on a given day, Cancellation Rate will be 0.00.\n",
    "4. Complexity Analysis\n",
    "    Time Complexity: O(N), where N is the number of records in the specified date range, as each row is scanned and aggregated once.\n",
    "    Space Complexity: O(D), where D is the number of unique dates within the range (due to grouping by request_at).\n",
    "5. Follow-Up Questions\n",
    "    Q1: How would you adapt this query if you needed monthly cancellation rates instead?\n",
    "    Answer: Change GROUP BY request_at to GROUP BY DATE_TRUNC('month', request_at). Adjust the outer query to handle monthly data labels accordingly.\n",
    "    Q2: What if you wanted to exclude trips with null statuses?\n",
    "    Answer: Add a.status IS NOT NULL in the WHERE clause to exclude trips with null statuses from the aggregation.\n",
    "    Q3: How would you optimize the query for large datasets?\n",
    "    Answer: Index request_at, client_id, and driver_id columns to improve join and filter efficiency. Additionally, consider a materialized view for frequently queried date ranges."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac6de9d",
   "metadata": {},
   "source": [
    "# Product Sales Analysis III\n",
    " \n",
    "Table: Sales\n",
    "\n",
    "    +-------------+-------+\n",
    "    | Column Name | Type  |\n",
    "    +-------------+-------+\n",
    "    | sale_id     | int   |\n",
    "    | product_id  | int   |\n",
    "    | year        | int   |\n",
    "    | quantity    | int   |\n",
    "    | price       | int   |\n",
    "    +-------------+-------+\n",
    "    (sale_id, year) is the primary key (combination of columns with unique values) of this table.\n",
    "    product_id is a foreign key (reference column) to Product table.\n",
    "    Each row of this table shows a sale on the product product_id in a certain year.\n",
    "    Note that the price is per unit.\n",
    "\n",
    "\n",
    "Table: Product\n",
    "\n",
    "    +--------------+---------+\n",
    "    | Column Name  | Type    |\n",
    "    +--------------+---------+\n",
    "    | product_id   | int     |\n",
    "    | product_name | varchar |\n",
    "    +--------------+---------+\n",
    "    product_id is the primary key (column with unique values) of this table.\n",
    "    Each row of this table indicates the product name of each product.\n",
    "\n",
    "\n",
    "    Write a solution to select the product id, year, quantity, and price for the first year of every product sold.\n",
    "\n",
    "    Return the resulting table in any order.\n",
    "\n",
    "    The result format is in the following example.\n",
    "\n",
    " \n",
    "\n",
    "Example 1:\n",
    "\n",
    "Input: \n",
    "Sales table:\n",
    "\n",
    "    +---------+------------+------+----------+-------+\n",
    "    | sale_id | product_id | year | quantity | price |\n",
    "    +---------+------------+------+----------+-------+ \n",
    "    | 1       | 100        | 2008 | 10       | 5000  |\n",
    "    | 2       | 100        | 2009 | 12       | 5000  |\n",
    "    | 7       | 200        | 2011 | 15       | 9000  |\n",
    "    +---------+------------+------+----------+-------+\n",
    "Product table:\n",
    "\n",
    "    +------------+--------------+\n",
    "    | product_id | product_name |\n",
    "    +------------+--------------+\n",
    "    | 100        | Nokia        |\n",
    "    | 200        | Apple        |\n",
    "    | 300        | Samsung      |\n",
    "    +------------+--------------+\n",
    "    \n",
    "Output: \n",
    "\n",
    "    +------------+------------+----------+-------+\n",
    "    | product_id | first_year | quantity | price |\n",
    "    +------------+------------+----------+-------+ \n",
    "    | 100        | 2008       | 10       | 5000  |\n",
    "    | 200        | 2011       | 15       | 9000  |\n",
    "    +------------+------------+----------+-------+\n",
    "    \n",
    "Solution Steps\n",
    "\n",
    "    Identify the First Sale Year: We use a subquery to find the minimum year for each product_id in the Sales table, which gives the earliest year each product was sold.\n",
    "    Join to Retrieve Required Details: Join this result with the original Sales table to retrieve the quantity and price for that year.\n",
    "    Final Selection:  Return the product_id, first_year, quantity, and price as required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d9c477",
   "metadata": {},
   "outputs": [],
   "source": [
    "SELECT \n",
    "    s.product_id,\n",
    "    s.year AS first_year,\n",
    "    s.quantity,\n",
    "    s.price\n",
    "FROM \n",
    "    Sales s\n",
    "JOIN \n",
    "    (SELECT product_id, MIN(year) AS first_year\n",
    "     FROM Sales\n",
    "     GROUP BY product_id) AS first_sale\n",
    "ON \n",
    "    s.product_id = first_sale.product_id\n",
    "    AND s.year = first_sale.first_year;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c07481a0",
   "metadata": {},
   "source": [
    "Explanation of the Query\n",
    "\n",
    "    Inner Query: The inner query first_sale finds the first sale year for each product_id by using MIN(year) and GROUP BY product_id.\n",
    "    Join Condition: We join the Sales table (s) with the first_sale subquery on both product_id and year to filter only the records that correspond to the first sale year.\n",
    "    Selection: Finally, we select product_id, year (renamed as first_year), quantity, and price for the earliest sale year.\n",
    "    \n",
    "Edge Cases\n",
    "\n",
    "    Products without sales records: These will not appear in the result since they have no data in the Sales table.\n",
    "    Multiple Sales in the Same Year: If there are multiple entries for the same product_id and year, each row will appear, reflecting every sale for that first year.\n",
    "\n",
    " \n",
    "Solution Complexity\n",
    "\n",
    "Time Complexity:\n",
    "\n",
    "    Inner Query: O(N log N) where  N is the number of rows in the Sales table. The GROUP BY and MIN() operations require scanning all records, and the complexity may increase if sorting or hashing is used.\n",
    "    Join Operation: Assuming we join on indexed columns, the join operation is approximately O(N).\n",
    "    Overall, the query is O(N log N) due to the MIN(year) operation in the subquery.\n",
    "\n",
    "Space Complexity:\n",
    "\n",
    "    Intermediate Storage: The subquery result (one row per product_id) is stored temporarily, requiring O(P) space where P is the number of unique product_id entries.\n",
    "    Total space complexity is therefore O(P)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d115ec64",
   "metadata": {},
   "source": [
    "# Confirmation Rate\n",
    " \n",
    "Table: Signups\n",
    "\n",
    "    +----------------+----------+\n",
    "    | Column Name    | Type     |\n",
    "    +----------------+----------+\n",
    "    | user_id        | int      |\n",
    "    | time_stamp     | datetime |\n",
    "    +----------------+----------+\n",
    "    user_id is the column of unique values for this table.\n",
    "    Each row contains information about the signup time for the user with ID user_id.\n",
    "\n",
    "\n",
    "Table: Confirmations\n",
    "\n",
    "    +----------------+----------+\n",
    "    | Column Name    | Type     |\n",
    "    +----------------+----------+\n",
    "    | user_id        | int      |\n",
    "    | time_stamp     | datetime |\n",
    "    | action         | ENUM     |\n",
    "    +----------------+----------+\n",
    "    (user_id, time_stamp) is the primary key (combination of columns with unique values) for this table.\n",
    "    user_id is a foreign key (reference column) to the Signups table.\n",
    "    action is an ENUM (category) of the type ('confirmed', 'timeout')\n",
    "    Each row of this table indicates that the user with ID user_id requested a confirmation message at time_stamp and that confirmation message was either confirmed ('confirmed') or expired without confirming ('timeout').\n",
    "\n",
    "\n",
    "    The confirmation rate of a user is the number of 'confirmed' messages divided by the total number of requested confirmation messages. The confirmation rate of a user that did not request any confirmation messages is 0. Round the confirmation rate to two decimal places.\n",
    "\n",
    "    Write a solution to find the confirmation rate of each user.\n",
    "\n",
    "    Return the result table in any order.\n",
    "\n",
    "    The result format is in the following example.\n",
    "\n",
    " \n",
    "\n",
    "Example 1:\n",
    "\n",
    "Input: \n",
    "Signups table:\n",
    "\n",
    "    +---------+---------------------+\n",
    "    | user_id | time_stamp          |\n",
    "    +---------+---------------------+\n",
    "    | 3       | 2020-03-21 10:16:13 |\n",
    "    | 7       | 2020-01-04 13:57:59 |\n",
    "    | 2       | 2020-07-29 23:09:44 |\n",
    "    | 6       | 2020-12-09 10:39:37 |\n",
    "    +---------+---------------------+\n",
    "Confirmations table:\n",
    "\n",
    "    +---------+---------------------+-----------+\n",
    "    | user_id | time_stamp          | action    |\n",
    "    +---------+---------------------+-----------+\n",
    "    | 3       | 2021-01-06 03:30:46 | timeout   |\n",
    "    | 3       | 2021-07-14 14:00:00 | timeout   |\n",
    "    | 7       | 2021-06-12 11:57:29 | confirmed |\n",
    "    | 7       | 2021-06-13 12:58:28 | confirmed |\n",
    "    | 7       | 2021-06-14 13:59:27 | confirmed |\n",
    "    | 2       | 2021-01-22 00:00:00 | confirmed |\n",
    "    | 2       | 2021-02-28 23:59:59 | timeout   |\n",
    "    +---------+---------------------+-----------+\n",
    "Output: \n",
    "\n",
    "    +---------+-------------------+\n",
    "    | user_id | confirmation_rate |\n",
    "    +---------+-------------------+\n",
    "    | 6       | 0.00              |\n",
    "    | 3       | 0.00              |\n",
    "    | 7       | 1.00              |\n",
    "    | 2       | 0.50              |\n",
    "    +---------+-------------------+\n",
    "Explanation: \n",
    "\n",
    "    User 6 did not request any confirmation messages. The confirmation rate is 0.\n",
    "    User 3 made 2 requests and both timed out. The confirmation rate is 0.\n",
    "    User 7 made 3 requests and all were confirmed. The confirmation rate is 1.\n",
    "    User 2 made 2 requests where one was confirmed and the other timed out. The confirmation rate is 1 / 2 = 0.5.\n",
    "    \n",
    "    \n",
    "Problem Analysis\n",
    "\n",
    "    The task is to calculate the confirmation rate for each user in the Signups table based on actions in the Confirmations table, specifically focusing on \"confirmed\" actions. We need to avoid division by zero errors when there are no corresponding entries in Confirmations for a user.\n",
    "\n",
    "Approach\n",
    "\n",
    "    Join Tables: Perform a LEFT JOIN between Signups and Confirmations using user_id to include all users, even if they don’t have any records in Confirmations.\n",
    "    Conditional Aggregation:\n",
    "        Calculate the total number of \"confirmed\" actions per user using a SUM(CASE WHEN ...).\n",
    "        Count the total number of entries in Confirmations for each user.\n",
    "    Avoid Division by Zero: Use NULLIF on the denominator to return NULL when there’s no entry in Confirmations, allowing COALESCE to default the confirmation rate to 0.\n",
    "    Round Result: Use ROUND to format the confirmation rate to two decimal places.\n",
    "\n",
    "steps\n",
    "\n",
    "    Left Join: Start by joining Signups with Confirmations using user_id.\n",
    "    Calculate Confirmation Rate:\n",
    "        Use SUM(CASE WHEN action = 'confirmed' THEN 1 ELSE 0 END) to get confirmed actions.\n",
    "        Use NULLIF(COUNT(b.user_id), 0) to avoid division by zero.\n",
    "    Round and Handle Nulls:\n",
    "        Use COALESCE to substitute any NULL values with 0.\n",
    "        Use ROUND to ensure the result is formatted to two decimal places.\n",
    "    Grouping: Group the results by user_id.\n",
    "    \n",
    "Edge Cases\n",
    "\n",
    "    No Confirmations for a User: If a user has no entries in Confirmations, COUNT(b.user_id) will be 0, handled by NULLIF.\n",
    "    All Confirmations Ignored: If there are no \"confirmed\" actions for a user, SUM(CASE...) will be 0.\n",
    "    Null Entries in Confirmations Table: If Confirmations has null or irrelevant values, the query correctly ignores these due to the conditional aggregation.\n",
    "    \n",
    "    Time Complexity \n",
    "        O(N) for joining and grouping rows, where N is the number of entries in the Confirmations table.\n",
    "        The complexity is manageable for typical datasets, especially with indexing on user_id.\n",
    "    Space Complexity \n",
    "        O(M) space, where M is the number of unique users in Signups, required for storing intermediate results in aggregation.\n",
    "        \n",
    "Follow-up Questions\n",
    "\n",
    "    How would you improve this query’s performance on large datasets?\n",
    "\n",
    "    Answer: Adding indexes on user_id in both tables would improve join performance. Additionally, storing aggregated results in a materialized view could speed up repeated queries, especially in cases with high data frequency.\n",
    "    What if the confirmation rate calculation logic changes (e.g., includes additional statuses)?\n",
    "\n",
    "    Answer: Update the CASE statement to include other statuses as necessary, adjusting conditions to match the new requirements. This allows flexibility without significant structural changes.\n",
    "    How would you handle calculating the rate over different time frames, such as weekly or monthly rates?\n",
    "\n",
    "    Answer: Add a time filter to the WHERE clause or group by specific time intervals, like DATE_TRUNC('month', confirmation_date), to aggregate results by time frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "670162f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your PostgreSQL query statement below\n",
    "SELECT \n",
    "    a.user_id,\n",
    "    ROUND(\n",
    "        COALESCE(\n",
    "            SUM(CASE WHEN action = 'confirmed' THEN 1 ELSE 0 END) * 1.0 / NULLIF(COUNT(b.user_id), 0), \n",
    "            0\n",
    "        ), \n",
    "        2\n",
    "    ) AS confirmation_rate\n",
    "FROM \n",
    "    Signups a\n",
    "LEFT JOIN \n",
    "    Confirmations b \n",
    "ON \n",
    "    a.user_id = b.user_id\n",
    "GROUP BY \n",
    "    a.user_id;\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb95b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your MySQL query statement below\n",
    "select a.user_id,  round(ifnull(sum(case when action = \"confirmed\" then 1 else 0 end)/count(b.user_id), 0), 2) as confirmation_rate\n",
    "from Signups a\n",
    "left join Confirmations b using (user_id)\n",
    "group by a.user_id\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c939353c",
   "metadata": {},
   "source": [
    "# Reported Posts II\n",
    " \n",
    "Table: Actions\n",
    "\n",
    "    +---------------+---------+\n",
    "    | Column Name   | Type    |\n",
    "    +---------------+---------+\n",
    "    | user_id       | int     |\n",
    "    | post_id       | int     |\n",
    "    | action_date   | date    | \n",
    "    | action        | enum    |\n",
    "    | extra         | varchar |\n",
    "    +---------------+---------+\n",
    "    This table may have duplicate rows.\n",
    "    The action column is an ENUM (category) type of ('view', 'like', 'reaction', 'comment', 'report', 'share').\n",
    "    The extra column has optional information about the action, such as a reason for the report or a type of reaction.\n",
    "\n",
    "\n",
    "Table: Removals\n",
    "\n",
    "    +---------------+---------+\n",
    "    | Column Name   | Type    |\n",
    "    +---------------+---------+\n",
    "    | post_id       | int     |\n",
    "    | remove_date   | date    | \n",
    "    +---------------+---------+\n",
    "    post_id is the primary key (column with unique values) of this table.\n",
    "    Each row in this table indicates that some post was removed due to being reported or as a result of an admin review.\n",
    "\n",
    "\n",
    "    Write a solution to find the average daily percentage of posts that got removed after being reported as spam, rounded to 2 decimal places.\n",
    "\n",
    "    The result format is in the following example.\n",
    "\n",
    "\n",
    "\n",
    "Example 1:\n",
    "\n",
    "Input: \n",
    "Actions table:\n",
    "\n",
    "    +---------+---------+-------------+--------+--------+\n",
    "    | user_id | post_id | action_date | action | extra  |\n",
    "    +---------+---------+-------------+--------+--------+\n",
    "    | 1       | 1       | 2019-07-01  | view   | null   |\n",
    "    | 1       | 1       | 2019-07-01  | like   | null   |\n",
    "    | 1       | 1       | 2019-07-01  | share  | null   |\n",
    "    | 2       | 2       | 2019-07-04  | view   | null   |\n",
    "    | 2       | 2       | 2019-07-04  | report | spam   |\n",
    "    | 3       | 4       | 2019-07-04  | view   | null   |\n",
    "    | 3       | 4       | 2019-07-04  | report | spam   |\n",
    "    | 4       | 3       | 2019-07-02  | view   | null   |\n",
    "    | 4       | 3       | 2019-07-02  | report | spam   |\n",
    "    | 5       | 2       | 2019-07-03  | view   | null   |\n",
    "    | 5       | 2       | 2019-07-03  | report | racism |\n",
    "    | 5       | 5       | 2019-07-03  | view   | null   |\n",
    "    | 5       | 5       | 2019-07-03  | report | racism |\n",
    "    +---------+---------+-------------+--------+--------+\n",
    "Removals table:\n",
    "\n",
    "    +---------+-------------+\n",
    "    | post_id | remove_date |\n",
    "    +---------+-------------+\n",
    "    | 2       | 2019-07-20  |\n",
    "    | 3       | 2019-07-18  |\n",
    "    +---------+-------------+\n",
    "Output: \n",
    "\n",
    "    +-----------------------+\n",
    "    | average_daily_percent |\n",
    "    +-----------------------+\n",
    "    | 75.00                 |\n",
    "    +-----------------------+\n",
    "Explanation:\n",
    "\n",
    "    The percentage for 2019-07-04 is 50% because only one post of two spam reported posts were removed.\n",
    "    The percentage for 2019-07-02 is 100% because one post was reported as spam and it was removed.\n",
    "    The other days had no spam reports so the average is (50 + 100) / 2 = 75%\n",
    "    Note that the output is only one number and that we do not care about the remove dates.\n",
    "    \n",
    "Problem Explanation\n",
    "\n",
    "    You need to calculate the average daily percentage of posts removed after being reported as spam. This involves analyzing two tables: Actions and Removals. You want to determine how many posts reported as spam were actually removed and then compute the average percentage of such removals per day.\n",
    "\n",
    "Steps to Solve the Problem\n",
    "Understand the Schema:\n",
    "\n",
    "    Familiarize yourself with the Actions and Removals tables, their columns, and their relationships.\n",
    "    \n",
    "Identify Relevant Actions:\n",
    "\n",
    "    Filter the Actions table for entries where extra = 'spam', as these are the actions reporting posts as spam.\n",
    "Join the Tables:\n",
    "\n",
    "    Perform a left join on the Actions and Removals tables to connect reported posts to their removal status.\n",
    "Count Distinct Posts:\n",
    "\n",
    "    For each action date, count distinct posts that were reported as spam and how many of those were removed.\n",
    "Calculate Percentages:\n",
    "\n",
    "    Calculate the percentage of reported posts that were removed for each day using the formula:\n",
    " \n",
    "    percentage=( count of reported posts/ count of removed posts)×100\n",
    "Average the Percentages:\n",
    "\n",
    "    Finally, compute the average of these daily percentages.\n",
    "    \n",
    "    \n",
    "Edge Cases to Consider\n",
    "\n",
    "    No Reports: If there are no reports of spam on certain days, ensure that the calculation handles the division correctly (should not cause division by zero).\n",
    "    No Removals: If all reported posts were not removed, ensure the percentage calculates to 0% rather than causing errors.\n",
    "    Duplicate Entries: The presence of duplicate rows in the Actions table should not skew the results. Using COUNT(DISTINCT ...) will help mitigate this.\n",
    "    Empty Tables: If either table is empty, the result should gracefully handle it without throwing errors.\n",
    "\n",
    "Time and Space Complexity\n",
    "\n",
    "    Time Complexity: The overall time complexity is O(nlogn) due to sorting while aggregating counts and the join operation, where n is the number of entries in the actions table.\n",
    "    Space Complexity: The space complexity is O(n) to store intermediate results.\n",
    "    \n",
    "Follow-up Questions\n",
    "\n",
    "    What would happen if the extra column had different values for spam?\n",
    "\n",
    "    You would need to adjust the WHERE clause to handle other values as well or normalize the input values before processing.\n",
    "    How would you optimize this query for large datasets?\n",
    "\n",
    "    Consider indexing the post_id in both tables and optimizing the join condition. Also, filtering out unnecessary data before the join can significantly improve performance.\n",
    "    Can you explain how the NULLIF function works in this context?\n",
    "\n",
    "    NULLIF returns NULL if the first argument equals the second; this prevents division by zero. In our query, it ensures that if there are no reported posts for a day, we do not attempt to divide by zero, which would lead to an error.\n",
    "    \n",
    "Sample Answers to Follow-up Questions\n",
    "\n",
    "    If the extra column had different values for spam, we could modify the query to check for those additional values as well. We might also consider normalizing the values to standardize how reports are logged.\n",
    "\n",
    "    To optimize the query for large datasets, we could index the post_id and action_date columns. Filtering early to remove irrelevant rows before joining would also help. Additionally, analyzing query execution plans to identify bottlenecks could further enhance performance.\n",
    "\n",
    "    The NULLIF function is essential in this context as it prevents division by zero errors. If the count of distinct reported posts is zero, NULLIF returns NULL, ensuring that our percentage calculation does not encounter a division by zero scenario, which would crash the query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "940e13a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your PostgreSQL query statement below\n",
    "SELECT ROUND(SUM(percent) / COUNT(DISTINCT action_date), 2) AS average_daily_percent\n",
    "FROM (\n",
    "    SELECT \n",
    "        a.action_date,\n",
    "        COUNT(DISTINCT r.post_id) * 100.0 / NULLIF(COUNT(DISTINCT a.post_id), 0) AS percent\n",
    "    FROM \n",
    "        actions a\n",
    "    LEFT JOIN \n",
    "        removals r ON a.post_id = r.post_id\n",
    "    WHERE \n",
    "        a.extra = 'spam'\n",
    "    GROUP BY \n",
    "        a.action_date\n",
    ") AS temp;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e114224",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your MySQL query statement below\n",
    "select round(sum(percent)/count(distinct action_date),2) as average_daily_percent\n",
    "from\n",
    "    (select a.action_date,\n",
    "    count(distinct r.post_id)/count(distinct a.post_id)*100 as percent\n",
    "    from actions a left join removals r\n",
    "    on a.post_id = r.post_id\n",
    "    where a.extra='spam'\n",
    "    group by 1) temp;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf82b06",
   "metadata": {},
   "source": [
    "# Customers Who Bought Products A and B but Not C\n",
    " \n",
    "Table: Customers\n",
    "\n",
    "    +---------------------+---------+\n",
    "    | Column Name         | Type    |\n",
    "    +---------------------+---------+\n",
    "    | customer_id         | int     |\n",
    "    | customer_name       | varchar |\n",
    "    +---------------------+---------+\n",
    "    customer_id is the column with unique values for this table.\n",
    "    customer_name is the name of the customer.\n",
    " \n",
    "\n",
    "Table: Orders\n",
    "\n",
    "    +---------------+---------+\n",
    "    | Column Name   | Type    |\n",
    "    +---------------+---------+\n",
    "    | order_id      | int     |\n",
    "    | customer_id   | int     |\n",
    "    | product_name  | varchar |\n",
    "    +---------------+---------+\n",
    "    order_id is the column with unique values for this table.\n",
    "    customer_id is the id of the customer who bought the product \"product_name\".\n",
    "\n",
    "\n",
    "    Write a solution to report the customer_id and customer_name of customers who bought products \"A\", \"B\" but did not buy the product \"C\" since we want to recommend them to purchase this product.\n",
    "\n",
    "    Return the result table ordered by customer_id.\n",
    "\n",
    "    The result format is in the following example.\n",
    "\n",
    "\n",
    "\n",
    "Example 1:\n",
    "\n",
    "Input: \n",
    "Customers table:\n",
    "\n",
    "    +-------------+---------------+\n",
    "    | customer_id | customer_name |\n",
    "    +-------------+---------------+\n",
    "    | 1           | Daniel        |\n",
    "    | 2           | Diana         |\n",
    "    | 3           | Elizabeth     |\n",
    "    | 4           | Jhon          |\n",
    "    +-------------+---------------+\n",
    "Orders table:\n",
    "\n",
    "    +------------+--------------+---------------+\n",
    "    | order_id   | customer_id  | product_name  |\n",
    "    +------------+--------------+---------------+\n",
    "    | 10         |     1        |     A         |\n",
    "    | 20         |     1        |     B         |\n",
    "    | 30         |     1        |     D         |\n",
    "    | 40         |     1        |     C         |\n",
    "    | 50         |     2        |     A         |\n",
    "    | 60         |     3        |     A         |\n",
    "    | 70         |     3        |     B         |\n",
    "    | 80         |     3        |     D         |\n",
    "    | 90         |     4        |     C         |\n",
    "    +------------+--------------+---------------+\n",
    "Output: \n",
    "\n",
    "    +-------------+---------------+\n",
    "    | customer_id | customer_name |\n",
    "    +-------------+---------------+\n",
    "    | 3           | Elizabeth     |\n",
    "    +-------------+---------------+\n",
    "    Explanation: Only the customer_id with id 3 bought the product A and B but not the product C.\n",
    "    \n",
    "Initial Ideas\n",
    "    We need to identify customers who have purchased both products \"A\" and \"B\" but have not purchased product \"C\". This can be achieved by using a combination of GROUP BY, HAVING, and filtering conditions.\n",
    "\n",
    "Steps\n",
    "\n",
    "    Join the Tables: Start by joining the Customers and Orders tables on customer_id to get access to customer names along with their corresponding orders.\n",
    "    Filter Orders: Use a WHERE clause to filter the products to focus on only \"A\", \"B\", and \"C\".\n",
    "    Aggregate Orders: Group the results by customer_id and count the occurrences of each product.\n",
    "    Use HAVING: Filter the grouped results with the HAVING clause to ensure the customer has:\n",
    "        Count of product \"A\" >= 1\n",
    "        Count of product \"B\" >= 1\n",
    "        Count of product \"C\" = 0 (i.e., the customer did not buy product \"C\").\n",
    "    Select Required Fields: Finally, select the customer_id and customer_name of the filtered results and order by customer_id.\n",
    "\n",
    "Edge Cases\n",
    "\n",
    "    Customers who have not made any purchases should not appear in the results.\n",
    "    A customer who bought multiple units of products \"A\" and \"B\" but no \"C\" should still be included.\n",
    "\n",
    "Complexity Analysis\n",
    "\n",
    "    Time Complexity: O(n), where n is the number of records in the Orders table, since we are scanning through the records to perform joins and aggregations.\n",
    "    Space Complexity: O(m), where m is the number of unique customers returned in the final result, as we are storing the filtered results.\n",
    "    \n",
    "Follow-Up Questions\n",
    "\n",
    "What if there were additional products to consider?\n",
    "\n",
    "    We could extend the WHERE and HAVING clauses to include other products similarly.\n",
    "How would you handle larger datasets?\n",
    "\n",
    "    Indexing customer_id on both tables would help optimize the join operation.\n",
    "What if you needed to consider the dates of purchases?\n",
    "\n",
    "    We would need to include a date field in our Orders table and adjust our WHERE clause to filter based on the desired date range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ee2de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write your PostgreSQL query statement below\n",
    "SELECT c.customer_id, c.customer_name\n",
    "FROM Customers c\n",
    "JOIN Orders o ON c.customer_id = o.customer_id\n",
    "WHERE o.product_name IN ('A', 'B', 'C')\n",
    "GROUP BY c.customer_id, c.customer_name\n",
    "HAVING COUNT(CASE WHEN o.product_name = 'A' THEN 1 END) > 0\n",
    "   AND COUNT(CASE WHEN o.product_name = 'B' THEN 1 END) > 0\n",
    "   AND COUNT(CASE WHEN o.product_name = 'C' THEN 1 END) = 0\n",
    "ORDER BY c.customer_id;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9088657f",
   "metadata": {},
   "source": [
    "Friend Requests I: Overall Acceptance Rate\n",
    " \n",
    "Table: FriendRequest\n",
    "\n",
    "    +----------------+---------+\n",
    "    | Column Name    | Type    |\n",
    "    +----------------+---------+\n",
    "    | sender_id      | int     |\n",
    "    | send_to_id     | int     |\n",
    "    | request_date   | date    |\n",
    "    +----------------+---------+\n",
    "    This table may contain duplicates (In other words, there is no primary key for this table in SQL).\n",
    "    This table contains the ID of the user who sent the request, the ID of the user who received the request, and the date of the request.\n",
    " \n",
    "\n",
    "Table: RequestAccepted\n",
    "\n",
    "    +----------------+---------+\n",
    "    | Column Name    | Type    |\n",
    "    +----------------+---------+\n",
    "    | requester_id   | int     |\n",
    "    | accepter_id    | int     |\n",
    "    | accept_date    | date    |\n",
    "    +----------------+---------+\n",
    "    This table may contain duplicates (In other words, there is no primary key for this table in SQL).\n",
    "    This table contains the ID of the user who sent the request, the ID of the user who received the request, and the date when the request was accepted.\n",
    "\n",
    "\n",
    "    Find the overall acceptance rate of requests, which is the number of acceptance divided by the number of requests. Return the answer rounded to 2 decimals places.\n",
    "\n",
    "    Note that:\n",
    "\n",
    "    The accepted requests are not necessarily from the table friend_request. In this case, Count the total accepted requests (no matter whether they are in the original requests), and divide it by the number of requests to get the acceptance rate.\n",
    "    It is possible that a sender sends multiple requests to the same receiver, and a request could be accepted more than once. In this case, the ‘duplicated’ requests or acceptances are only counted once.\n",
    "    If there are no requests at all, you should return 0.00 as the accept_rate.\n",
    "    The result format is in the following example.\n",
    "\n",
    " \n",
    "\n",
    "Example 1:\n",
    "\n",
    "Input: \n",
    "FriendRequest table:\n",
    "\n",
    "    +-----------+------------+--------------+\n",
    "    | sender_id | send_to_id | request_date |\n",
    "    +-----------+------------+--------------+\n",
    "    | 1         | 2          | 2016/06/01   |\n",
    "    | 1         | 3          | 2016/06/01   |\n",
    "    | 1         | 4          | 2016/06/01   |\n",
    "    | 2         | 3          | 2016/06/02   |\n",
    "    | 3         | 4          | 2016/06/09   |\n",
    "    +-----------+------------+--------------+\n",
    "RequestAccepted table:\n",
    "\n",
    "    +--------------+-------------+-------------+\n",
    "    | requester_id | accepter_id | accept_date |\n",
    "    +--------------+-------------+-------------+\n",
    "    | 1            | 2           | 2016/06/03  |\n",
    "    | 1            | 3           | 2016/06/08  |\n",
    "    | 2            | 3           | 2016/06/08  |\n",
    "    | 3            | 4           | 2016/06/09  |\n",
    "    | 3            | 4           | 2016/06/10  |\n",
    "    +--------------+-------------+-------------+\n",
    "Output: \n",
    "\n",
    "    +-------------+\n",
    "    | accept_rate |\n",
    "    +-------------+\n",
    "    | 0.8         |\n",
    "    +-------------+\n",
    "Explanation: \n",
    "\n",
    "    There are 4 unique accepted requests, and there are 5 requests in total. So the rate is 0.80.\n",
    " \n",
    " \n",
    " \n",
    "Initial Ideas\n",
    "Identify Unique Requests and Acceptances:\n",
    "\n",
    "    Each friend request may have duplicates, so we must count unique requests to avoid inflated results.\n",
    "    Similarly, accepted requests might also contain duplicates, so we should only count distinct acceptances.\n",
    "Handle Division by Zero:\n",
    "\n",
    "    If no requests were sent (count = 0), the rate should return 0.00 instead of causing a division error.\n",
    "Round the Final Result:\n",
    "\n",
    "    Ensure that the result is formatted to two decimal places.\n",
    "    \n",
    "Solution Steps\n",
    "Define requested CTE:\n",
    "\n",
    "    Extract distinct pairs of sender_id and send_to_id from FriendRequest to represent unique requests.\n",
    "Define accepted CTE:\n",
    "\n",
    "    Extract distinct pairs of requester_id and accepter_id from RequestAccepted to represent unique accepted requests.\n",
    "Calculate the Acceptance Rate:\n",
    "\n",
    "    Numerator: Count rows in accepted, representing the total accepted requests.\n",
    "    Denominator: Count rows in requested, representing the total requests sent.\n",
    "    Use NULLIF to handle cases where there are no requests by converting the denominator to NULL when it’s zero, then handle it with COALESCE(..., 0).\n",
    "Round and Format Result:\n",
    "\n",
    "    Use ROUND(..., 2) to format the result to two decimal places.\n",
    "    \n",
    "Edge Cases\n",
    "\n",
    "No Requests Sent:\n",
    "\n",
    "    If there are no records in FriendRequest, the result should be 0.00.\n",
    "No Accepted Requests:\n",
    "\n",
    "    If there are requests but no matching accepted requests, the rate should be 0.00.\n",
    "Duplicate Requests or Acceptances:\n",
    "\n",
    "    Duplicates in the tables don’t affect the result since we use DISTINCT in both CTEs.\n",
    "    \n",
    "    \n",
    "Complexity Analysis\n",
    "\n",
    "Time Complexity:\n",
    "\n",
    "    O(N + M), where N is the number of rows in FriendRequest and M is the number of rows in RequestAccepted.\n",
    "    Counting distinct pairs will take linear time with respect to the number of entries in each table.\n",
    "Space Complexity:\n",
    "\n",
    "    O(N + M) for storing requested and accepted CTEs.\n",
    "    \n",
    "Follow-up Questions and Answers\n",
    "\n",
    "Q: What if the acceptance rate needs to be calculated by month or year?\n",
    "\n",
    "    A: We can add request_date and accept_date to the CTE queries and apply GROUP BY on these date parts to calculate monthly or yearly acceptance rates.\n",
    "Q: How would you adjust the query to find the acceptance rate for specific users?\n",
    "\n",
    "    A: Add a WHERE clause to filter sender_id or requester_id in FriendRequest or RequestAccepted based on the user ID.\n",
    "Q: What if we want to consider requests sent only within the last month?\n",
    "\n",
    "    A: Filter the FriendRequest table by request_date >= DATE_SUB(CURDATE(), INTERVAL 1 MONTH) to include only recent requests in the calculation.\n",
    "Q: How would the query change if it were run in PostgreSQL instead?\n",
    "\n",
    "    A: Minor adjustments are needed, such as explicit type casting for calculations or replacing MySQL-specific functions with PostgreSQL-compatible ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6adb127",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your MySQL query statement below\n",
    "WITH requested AS (\n",
    "    SELECT DISTINCT \n",
    "        sender_id, send_to_id\n",
    "    FROM \n",
    "        FriendRequest\n",
    "), accepted AS (\n",
    "    SELECT DISTINCT\n",
    "        requester_id, accepter_id\n",
    "    FROM \n",
    "        RequestAccepted\n",
    ")\n",
    "SELECT \n",
    "    ROUND(\n",
    "        COALESCE(\n",
    "            (SELECT COUNT(*) FROM accepted) / NULLIF((SELECT COUNT(*) FROM requested), 0),\n",
    "            0\n",
    "        ),\n",
    "        2\n",
    "    ) AS accept_rate;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e77a752",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your PostgreSQL query statement below \n",
    "WITH requested AS (\n",
    "    SELECT DISTINCT \n",
    "        sender_id, send_to_id\n",
    "    FROM \n",
    "        FriendRequest\n",
    "), accepted AS (\n",
    "    SELECT DISTINCT\n",
    "        requester_id, accepter_id\n",
    "    FROM RequestAccepted\n",
    ")\n",
    "SELECT (\n",
    "    ROUND ( \n",
    "        COALESCE(\n",
    "            (SELECT COUNT (*) FROM accepted)::NUMERIC\n",
    "            /\n",
    "            NULLIF((SELECT COUNT(*) FROM requested)::NUMERIC , 0)\n",
    "        , 0)\n",
    "    , 2)\n",
    ") AS accept_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fa5afb6",
   "metadata": {},
   "source": [
    "# Nth Highest Salary\n",
    " \n",
    "Table: Employee\n",
    "\n",
    "    +-------------+------+\n",
    "    | Column Name | Type |\n",
    "    +-------------+------+\n",
    "    | id          | int  |\n",
    "    | salary      | int  |\n",
    "    +-------------+------+\n",
    "    id is the primary key (column with unique values) for this table.\n",
    "    Each row of this table contains information about the salary of an employee.\n",
    "\n",
    "\n",
    "    Write a solution to find the nth highest salary from the Employee table. If there is no nth highest salary, return null.\n",
    "\n",
    "    The result format is in the following example.\n",
    "\n",
    "\n",
    "\n",
    "Example 1:\n",
    "\n",
    "Input: \n",
    "Employee table:\n",
    "\n",
    "    +----+--------+\n",
    "    | id | salary |\n",
    "    +----+--------+\n",
    "    | 1  | 100    |\n",
    "    | 2  | 200    |\n",
    "    | 3  | 300    |\n",
    "    +----+--------+\n",
    "    n = 2\n",
    "    \n",
    "Output: \n",
    "\n",
    "    +------------------------+\n",
    "    | getNthHighestSalary(2) |\n",
    "    +------------------------+\n",
    "    | 200                    |\n",
    "    +------------------------+\n",
    "Example 2:\n",
    "\n",
    "Input: \n",
    "\n",
    "Employee table:\n",
    "\n",
    "    +----+--------+\n",
    "    | id | salary |\n",
    "    +----+--------+\n",
    "    | 1  | 100    |\n",
    "    +----+--------+\n",
    "    n = 2\n",
    "Output: \n",
    "\n",
    "    +------------------------+\n",
    "    | getNthHighestSalary(2) |\n",
    "    +------------------------+\n",
    "    | null                   |\n",
    "    +------------------------+\n",
    "    \n",
    "Initial Ideas\n",
    "\n",
    "    Problem Definition: The goal is to retrieve the N-th highest salary from the Employee table.\n",
    "    Use of DENSE_RANK: DENSE_RANK is utilized to rank salaries while handling ties (e.g., two employees with the same salary will receive the same rank).\n",
    "    Function Behavior: The function should return the salary for a specific rank or NULL if that rank does not exist.\n",
    "\n",
    "Steps\n",
    "\n",
    "    Declare Variables: Start by declaring a variable result to hold the final salary.\n",
    "    Rank Salaries:\n",
    "        Use a subquery to select salaries from the Employee table.\n",
    "        Apply DENSE_RANK() to order the salaries in descending order and assign ranks.\n",
    "    Select N-th Salary:\n",
    "        In the outer query, filter to select the salary that matches the provided rank N.\n",
    "        Use LIMIT 1 to ensure only one salary is returned.\n",
    "    Return Result: The final salary is returned from the function.\n",
    "\n",
    "Edge Cases\n",
    "\n",
    "    N is Greater than the Number of Distinct Salaries: The function should handle cases where N exceeds the number of unique salaries, returning NULL.\n",
    "    N is Less than 1: If N is less than 1, the function might return NULL or throw an error depending on the SQL environment.\n",
    "    Empty Employee Table: If there are no records in the Employee table, the function should also return NULL.\n",
    "\n",
    "Complexity\n",
    "\n",
    "    Time Complexity: The function mainly depends on the sorting operation for the DENSE_RANK(), which is O(M log M) where M is the number of distinct salaries.\n",
    "    Space Complexity: Space complexity is O(M) for storing the ranked salaries.\n",
    "    \n",
    "Follow-Up Questions\n",
    "\n",
    "What happens if multiple employees have the same salary?\n",
    "\n",
    "    The function will assign them the same rank, and if N corresponds to that rank, it will return the salary. For example, if two employees earn $100,000 and are ranked 1, they will both be assigned the same rank, so querying for the 1st highest salary will return $100,000.\n",
    "    \n",
    "How would you modify this function to return the second highest salary?\n",
    "\n",
    "    You can call the function with N = 2 to get the second highest salary directly.\n",
    "What would you do if you wanted to include a salary of zero?\n",
    "\n",
    "    You would need to adjust the ranking logic, possibly by using RANK() instead of DENSE_RANK() if you want to consider all entries, including duplicates and zero salaries.\n",
    "How would you handle NULL salaries in your dataset?\n",
    "\n",
    "    You could filter out NULL values in the subquery by adding a WHERE e.salary IS NOT NULL clause.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f720f58b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MySQL\n",
    "CREATE FUNCTION getNthHighestSalary(N INT) \n",
    "RETURNS INT\n",
    "DETERMINISTIC\n",
    "BEGIN\n",
    "  DECLARE result INT;\n",
    "\n",
    "  SELECT a.salary INTO result\n",
    "  FROM (\n",
    "    SELECT e.salary, DENSE_RANK() OVER (ORDER BY e.salary DESC) AS salary_rank  -- Renamed to salary_rank\n",
    "    FROM Employee e\n",
    "  ) AS a\n",
    "  WHERE a.salary_rank = N  -- Use the new alias here\n",
    "  LIMIT 1;\n",
    "\n",
    "  RETURN result;\n",
    "END;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51fbb32b",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Write your PostgreSQL query statement below.\n",
    "CREATE OR REPLACE FUNCTION NthHighestSalary(N INT) RETURNS TABLE (Salary INT) AS $$\n",
    "BEGIN\n",
    "  RETURN QUERY (\n",
    "   \n",
    "    select a.salary as SecondHighestSalary from (select e.salary, dense_rank() over \n",
    "    (order by e.salary desc) as rank from Employee e)a\n",
    "    where a.rank=N limit 1\n",
    " \n",
    "  );\n",
    "END;\n",
    "$$ LANGUAGE plpgsql;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccbf0262",
   "metadata": {},
   "source": [
    "# Department Top Three Salaries\n",
    " \n",
    "Table: Employee\n",
    "\n",
    "    +--------------+---------+\n",
    "    | Column Name  | Type    |\n",
    "    +--------------+---------+\n",
    "    | id           | int     |\n",
    "    | name         | varchar |\n",
    "    | salary       | int     |\n",
    "    | departmentId | int     |\n",
    "    +--------------+---------+\n",
    "    id is the primary key (column with unique values) for this table.\n",
    "    departmentId is a foreign key (reference column) of the ID from the Department table.\n",
    "    Each row of this table indicates the ID, name, and salary of an employee. It also contains the ID of their department.\n",
    "\n",
    "\n",
    "Table: Department\n",
    "\n",
    "    +-------------+---------+\n",
    "    | Column Name | Type    |\n",
    "    +-------------+---------+\n",
    "    | id          | int     |\n",
    "    | name        | varchar |\n",
    "    +-------------+---------+\n",
    "    id is the primary key (column with unique values) for this table.\n",
    "    Each row of this table indicates the ID of a department and its name.\n",
    "\n",
    "\n",
    "    A company's executives are interested in seeing who earns the most money in each of the company's departments. A high earner in a department is an employee who has a salary in the top three unique salaries for that department.\n",
    "\n",
    "    Write a solution to find the employees who are high earners in each of the departments.\n",
    "\n",
    "    Return the result table in any order.\n",
    "\n",
    "    The result format is in the following example.\n",
    "\n",
    " \n",
    "\n",
    "Example 1:\n",
    "\n",
    "Input: \n",
    "Employee table:\n",
    "\n",
    "    +----+-------+--------+--------------+\n",
    "    | id | name  | salary | departmentId |\n",
    "    +----+-------+--------+--------------+\n",
    "    | 1  | Joe   | 85000  | 1            |\n",
    "    | 2  | Henry | 80000  | 2            |\n",
    "    | 3  | Sam   | 60000  | 2            |\n",
    "    | 4  | Max   | 90000  | 1            |\n",
    "    | 5  | Janet | 69000  | 1            |\n",
    "    | 6  | Randy | 85000  | 1            |\n",
    "    | 7  | Will  | 70000  | 1            |\n",
    "    +----+-------+--------+--------------+\n",
    "Department table:\n",
    "\n",
    "    +----+-------+\n",
    "    | id | name  |\n",
    "    +----+-------+\n",
    "    | 1  | IT    |\n",
    "    | 2  | Sales |\n",
    "    +----+-------+\n",
    "Output: \n",
    "\n",
    "    +------------+----------+--------+\n",
    "    | Department | Employee | Salary |\n",
    "    +------------+----------+--------+\n",
    "    | IT         | Max      | 90000  |\n",
    "    | IT         | Joe      | 85000  |\n",
    "    | IT         | Randy    | 85000  |\n",
    "    | IT         | Will     | 70000  |\n",
    "    | Sales      | Henry    | 80000  |\n",
    "    | Sales      | Sam      | 60000  |\n",
    "    +------------+----------+--------+\n",
    "Explanation: \n",
    "\n",
    "    In the IT department:\n",
    "    - Max earns the highest unique salary\n",
    "    - Both Randy and Joe earn the second-highest unique salary\n",
    "    - Will earns the third-highest unique salary\n",
    "\n",
    "    In the Sales department:\n",
    "    - Henry earns the highest salary\n",
    "    - Sam earns the second-highest salary\n",
    "    - There is no third-highest salary as there are only two employees\n",
    "    \n",
    "Initial Ideas\n",
    "\n",
    "    Problem Understanding: We need to identify employees who are high earners in their respective departments based on their salary. High earners are defined as those with salaries that fall within the top three unique salary values in each department.\n",
    "    Use of Ranking: The solution leverages SQL's window function DENSE_RANK() to rank salaries within each department. This allows for proper handling of ties in salary values.\n",
    "\n",
    "Steps\n",
    "\n",
    "    Join Tables: Start by joining the Employee table with the Department table on the departmentId to access department names alongside employee details.\n",
    "    Rank Salaries:\n",
    "        Use DENSE_RANK() to assign a rank to each employee’s salary, partitioned by departmentId and ordered by salary in descending order.\n",
    "    Filter Results: In the outer query, filter to include only those employees whose rank is less than or equal to 3, capturing the top three salaries.\n",
    "    Select Output: Return the required columns: department name, employee name, and salary.\n",
    "\n",
    "Edge Cases\n",
    "\n",
    "    Fewer than Three Employees: If a department has fewer than three employees, the query should still return those employees.\n",
    "    Identical Salaries: If multiple employees have the same salary, they will all receive the same rank, which should still be counted within the top three.\n",
    "    No Employees in Department: If a department has no employees, it will not appear in the result.\n",
    "\n",
    "Complexity\n",
    "\n",
    "    Time Complexity: The overall complexity is O(N log N) due to the sorting step involved in ranking, where N is the number of employees.\n",
    "    Space Complexity: The space complexity is O(N) for storing the ranks and salary data during processing.\n",
    "\n",
    "Follow-Up Questions\n",
    "How does DENSE_RANK() handle ties?\n",
    "\n",
    "    DENSE_RANK() assigns the same rank to tied salaries and does not skip any ranks, which allows multiple employees with the same salary to be included in the top three.\n",
    "What would you do if you also needed the fourth-highest salary?\n",
    "    \n",
    "    You would modify the filtering condition in the outer query to WHERE r_ <= 4 to include the fourth-highest salaries.\n",
    "How would you adjust this query for performance with a larger dataset?\n",
    "\n",
    "    You could consider indexing the salary and departmentId columns for faster access and sorting. Additionally, you might filter out employees with low salaries earlier in the process to reduce the number of rows processed.\n",
    "What happens if the employee salary is NULL?\n",
    "\n",
    "    If any salaries are NULL, they will be excluded from ranking since NULL values are generally not included in the ranking functions. If required, you could handle these separately by replacing NULL with a default value (e.g., 0) in the ranking process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23aba53c",
   "metadata": {},
   "outputs": [],
   "source": [
    "select Department, Employee, salary from (\n",
    "select e.name as Employee, salary, d.name as Department, dense_rank() over(partition by departmentId order by salary desc) as r_\n",
    "from Employee e \n",
    "join Department d on e.departmentId = d.id) as a\n",
    "where r_ <=3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1486eac",
   "metadata": {},
   "source": [
    "# Active Users\n",
    " \n",
    "Table: Accounts\n",
    "\n",
    "    +---------------+---------+\n",
    "    | Column Name   | Type    |\n",
    "    +---------------+---------+\n",
    "    | id            | int     |\n",
    "    | name          | varchar |\n",
    "    +---------------+---------+\n",
    "    id is the primary key (column with unique values) for this table.\n",
    "    This table contains the account id and the user name of each account.\n",
    " \n",
    "\n",
    "Table: Logins\n",
    "\n",
    "    +---------------+---------+\n",
    "    | Column Name   | Type    |\n",
    "    +---------------+---------+\n",
    "    | id            | int     |\n",
    "    | login_date    | date    |\n",
    "    +---------------+---------+\n",
    "    This table may contain duplicate rows.\n",
    "    This table contains the account id of the user who logged in and the login date. A user may log in multiple times in the day.\n",
    "\n",
    "\n",
    "    Active users are those who logged in to their accounts for five or more consecutive days.\n",
    "\n",
    "    Write a solution to find the id and the name of active users.\n",
    "\n",
    "    Return the result table ordered by id.\n",
    "\n",
    "    The result format is in the following example.\n",
    "\n",
    " \n",
    "\n",
    "Example 1:\n",
    "\n",
    "Input: \n",
    "Accounts table:\n",
    "\n",
    "    +----+----------+\n",
    "    | id | name     |\n",
    "    +----+----------+\n",
    "    | 1  | Winston  |\n",
    "    | 7  | Jonathan |\n",
    "    +----+----------+\n",
    "Logins table:\n",
    "\n",
    "    +----+------------+\n",
    "    | id | login_date |\n",
    "    +----+------------+\n",
    "    | 7  | 2020-05-30 |\n",
    "    | 1  | 2020-05-30 |\n",
    "    | 7  | 2020-05-31 |\n",
    "    | 7  | 2020-06-01 |\n",
    "    | 7  | 2020-06-02 |\n",
    "    | 7  | 2020-06-02 |\n",
    "    | 7  | 2020-06-03 |\n",
    "    | 1  | 2020-06-07 |\n",
    "    | 7  | 2020-06-10 |\n",
    "    +----+------------+\n",
    "Output: \n",
    "\n",
    "    +----+----------+\n",
    "    | id | name     |\n",
    "    +----+----------+\n",
    "    | 7  | Jonathan |\n",
    "    +----+----------+\n",
    "\n",
    "Explanation: \n",
    "\n",
    "    User Winston with id = 1 logged in 2 times only in 2 different days, so, Winston is not an active user.\n",
    "    User Jonathan with id = 7 logged in 7 times in 6 different days, five of them were consecutive days, so, Jonathan is an active user.\n",
    "\n",
    "\n",
    "Initial Idea\n",
    "\n",
    "    The goal is to find users who have logged in for a specified number of consecutive days (in this case, four days) within the dataset. To achieve this, we:\n",
    "        Look at each user's login records, specifically comparing each login date with other logins within a four-day range.\n",
    "        Count unique login days for each id within this range.\n",
    "        Select users who have exactly four consecutive unique login days.\n",
    "        \n",
    "Steps to Solve\n",
    "\n",
    "    Self-Join: We perform a self-join on the Logins table. Each login date (l1.login_date) is joined with other login dates (l2.login_date) that are within one to four days after it.\n",
    "        This comparison enables us to check whether each user has logged in across four unique days within a four-day window.\n",
    "    Date Range Filtering: Using l2.login_date BETWEEN l1.login_date + INTERVAL '1 day' AND l1.login_date + INTERVAL '4 days', we get logins for the next four days after each specific login date.\n",
    "    Grouping and Counting: We group by each user's id and initial login date (l1.login_date) and count distinct login dates (l2.login_date). If this count equals 4, it means the user logged in on four unique consecutive days.\n",
    "    Selecting Names: For each qualifying id, we retrieve the corresponding name from the Accounts table.\n",
    "    \n",
    "Edge Cases\n",
    "\n",
    "    Insufficient Login Days: Users with fewer than four total logins cannot meet the criteria and should be excluded.\n",
    "    Duplicate Login Days: If a user logged in multiple times on the same day, it should only count as one unique day.\n",
    "    Non-Consecutive Four Days: Users with four logins that aren’t on consecutive days won’t be counted as active.\n",
    "\n",
    "Complexity Analysis\n",
    "\n",
    "    Time Complexity: O(n^2) due to the self-join operation, where each row in Logins is compared with other rows. For large datasets, this could be inefficient.\n",
    "    Space Complexity: O(n), mainly for storing the intermediate results of the self-join.\n",
    "    \n",
    "Follow-Up Questions\n",
    "\n",
    "How would you generalize this for any n consecutive days?\n",
    "\n",
    "    Change 4 in l1.login_date + INTERVAL '4 days' and HAVING COUNT(DISTINCT l2.login_date) = 4 to n days.\n",
    "How can we optimize this for performance, especially with large datasets?\n",
    "\n",
    "    Use indexes on id and login_date to improve join performance.\n",
    "    Use a window function to compute consecutive login streaks without a self-join.\n",
    "What if login data contains gaps within the days that aren’t consecutive but still has multiple consecutive streaks?\n",
    "\n",
    "    We would need to break down the login events into \"streaks\" using row numbering and window functions, but it may complicate the solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d2bbd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write your PostgreSQL query statement below\n",
    "SELECT DISTINCT l1.id,\n",
    "       (SELECT name FROM Accounts WHERE id = l1.id) AS name\n",
    "FROM Logins l1\n",
    "JOIN Logins l2 ON l1.id = l2.id AND l2.login_date BETWEEN l1.login_date + INTERVAL '1 day' AND l1.login_date + INTERVAL '4 days'\n",
    "GROUP BY l1.id, l1.login_date\n",
    "HAVING COUNT(DISTINCT l2.login_date) = 4;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cca08bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your MySQL query statement below\n",
    "SELECT DISTINCT l1.id,\n",
    "(SELECT name FROM Accounts WHERE id = l1.id) AS name\n",
    "FROM Logins l1\n",
    "JOIN Logins l2 ON l1.id = l2.id AND DATEDIFF(l2.login_date, l1.login_date) BETWEEN 1 AND 4\n",
    "GROUP BY l1.id, l1.login_date\n",
    "HAVING COUNT(DISTINCT l2.login_date) = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db7a51d",
   "metadata": {},
   "source": [
    "# Dynamic Pivoting of a Table\n",
    " \n",
    "Table: Products\n",
    "\n",
    "    +-------------+---------+\n",
    "    | Column Name | Type    |\n",
    "    +-------------+---------+\n",
    "    | product_id  | int     |\n",
    "    | store       | varchar |\n",
    "    | price       | int     |\n",
    "    +-------------+---------+\n",
    "    (product_id, store) is the primary key (combination of columns with unique values) for this table.\n",
    "    Each row of this table indicates the price of product_id in store.\n",
    "    There will be at most 30 different stores in the table.\n",
    "    price is the price of the product at this store.\n",
    "\n",
    "\n",
    "    Important note: This problem targets those who have a good experience with SQL. If you are a beginner, we recommend that you skip it for now.\n",
    "\n",
    "    Implement the procedure PivotProducts to reorganize the Products table so that each row has the id of one product and its price in each store. The price should be null if the product is not sold in a store. The columns of the table should contain each store and they should be sorted in lexicographical order.\n",
    "\n",
    "    The procedure should return the table after reorganizing it.\n",
    "\n",
    "    Return the result table in any order.\n",
    "\n",
    "    The result format is in the following example.\n",
    "\n",
    " \n",
    "\n",
    "Example 1:\n",
    "\n",
    "Input: \n",
    "Products table:\n",
    "\n",
    "    +------------+----------+-------+\n",
    "    | product_id | store    | price |\n",
    "    +------------+----------+-------+\n",
    "    | 1          | Shop     | 110   |\n",
    "    | 1          | LC_Store | 100   |\n",
    "    | 2          | Nozama   | 200   |\n",
    "    | 2          | Souq     | 190   |\n",
    "    | 3          | Shop     | 1000  |\n",
    "    | 3          | Souq     | 1900  |\n",
    "    +------------+----------+-------+\n",
    "Output: \n",
    "\n",
    "    +------------+----------+--------+------+------+\n",
    "    | product_id | LC_Store | Nozama | Shop | Souq |\n",
    "    +------------+----------+--------+------+------+\n",
    "    | 1          | 100      | null   | 110  | null |\n",
    "    | 2          | null     | 200    | null | 190  |\n",
    "    | 3          | null     | null   | 1000 | 1900 |\n",
    "    +------------+----------+--------+------+------+\n",
    "Initial Ideas\n",
    "\n",
    "    The goal is to reorganize the Products table such that each row corresponds to a unique product_id, and each store becomes a separate column displaying the price of that product. If a product is not available at a particular store, the price should be represented as NULL. This requires dynamic SQL to handle varying store names efficiently.\n",
    "\n",
    "Steps Involved\n",
    "\n",
    "Session Variable Adjustment:\n",
    "\n",
    "    We begin by overriding the default limit of the GROUP_CONCAT function using SET SESSION group_concat_max_len = 1000000;. This ensures we can handle a larger number of concatenated store names without truncation.\n",
    "Dynamic Case Statement Creation:\n",
    "\n",
    "    The SELECT statement constructs a dynamic SQL statement by generating a SUM(CASE WHEN ...) structure for each distinct store. The result is concatenated into the variable @case_stmt, which will represent the pivoted columns for prices.\n",
    "Here’s the breakdown:\n",
    "    SUM(CASE WHEN store = \"<store_name>\" THEN price END) effectively filters prices by store, summing the values for each product.\n",
    "Final Query Construction:\n",
    "\n",
    "    We build the final SQL query using the dynamically created @case_stmt and store it in @sql_query. The query structure is SELECT product_id, <case_stmt> FROM products GROUP BY product_id.\n",
    "Execution of the Dynamic Query:\n",
    "\n",
    "    The prepared statement is executed with PREPARE, EXECUTE, and then deallocated to free up resources.\n",
    "    \n",
    "Edge Cases\n",
    "\n",
    "    Empty Products Table: If the Products table has no rows, the output will simply return an empty result set, which is an expected behavior.\n",
    "    Single Product with No Stores: If a product exists but has no corresponding entries for any stores, it should return NULL for all store columns.\n",
    "    Special Characters in Store Names: If store names contain special characters or quotes, it could break the SQL syntax. Proper escaping or handling of identifiers is necessary to avoid SQL injection vulnerabilities.\n",
    "    \n",
    "Complexity Analysis\n",
    "\n",
    "Time Complexity:\n",
    "\n",
    "    The complexity for generating the GROUP_CONCAT is O(N), where N is the number of rows in the Products table.\n",
    "    The execution of the final query is also O(N) since it groups the data by product_id and aggregates the prices.\n",
    "\n",
    "Space Complexity:\n",
    "\n",
    "    The space used is primarily for storing the SQL strings (@case_stmt, @sql_query), which would depend on the number of distinct stores and the length of their names.\n",
    "    \n",
    "Follow-up Questions and Answers\n",
    "\n",
    "Q: How would you handle a scenario where the number of stores exceeds a certain limit?\n",
    "\n",
    "    A: If the number of stores is too high, it may be necessary to limit the number of stores considered in the pivoting. This could be done by applying filters, such as only including the top N stores by sales volume or price, to keep the result manageable.\n",
    "Q: Can you think of ways to optimize this query for larger datasets?\n",
    "\n",
    "    A: One approach to optimize the query could be to create appropriate indexes on the store and product_id columns to speed up the grouping and filtering processes. Additionally, materialized views could be used to cache results if the underlying data doesn't change frequently.\n",
    "Q: What if the price values contain decimals or are negative? How would you address that?\n",
    "\n",
    "    A: If prices can be negative, we should ensure that our business logic accommodates that, perhaps by applying additional conditions or validations. If we are only interested in positive prices, we could add a filter in the case statement like WHEN store = \"<store_name>\" AND price >= 0.\n",
    "Q: How would you modify this procedure to handle multiple products sold at the same store?\n",
    "\n",
    "    A: The current setup using SUM in the CASE statements works for aggregating prices, but if multiple prices exist for the same product-store combination, we might want to decide on the aggregation method (e.g., MAX, MIN, or AVG). Adjusting the aggregate function in the CASE statement would achieve this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e623b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "CREATE PROCEDURE PivotProducts()\n",
    "BEGIN\n",
    "\n",
    "#Override GROUP_CONCAT length which has a default limit of 1024\n",
    "SET SESSION group_concat_max_len = 1000000;\n",
    "\n",
    "#Store case statement for dynamically generated columns in a variable ie case_stmt\n",
    "SET @case_stmt = NULL;\n",
    "SELECT GROUP_CONCAT(DISTINCT CONCAT('SUM(CASE WHEN store = \"', store, '\" THEN price END) AS ', store))\n",
    "INTO @case_stmt\n",
    "FROM products;\n",
    " \n",
    "#Insert above statement (@case_stmt) in the following main query to frame final query \n",
    "SET @sql_query = CONCAT('SELECT product_id, ', @case_stmt, ' FROM products GROUP BY product_id');\n",
    "\n",
    "#Execute final query\n",
    "PREPARE final_sql_query FROM @sql_query;\n",
    "EXECUTE final_sql_query;\n",
    "DEALLOCATE PREPARE final_sql_query;\n",
    "\n",
    "END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6593c380",
   "metadata": {},
   "outputs": [],
   "source": [
    "SELECT \n",
    "    product_id,\n",
    "    SUM(CASE WHEN store = 'LC_Store' THEN price END) AS LC_Store,\n",
    "    SUM(CASE WHEN store = 'Nozama' THEN price END) AS Nozama,\n",
    "    SUM(CASE WHEN store = 'Shop' THEN price END) AS Shop,\n",
    "    SUM(CASE WHEN store = 'Souq' THEN price END) AS Souq\n",
    "FROM \n",
    "    Products\n",
    "GROUP BY \n",
    "    product_id\n",
    "ORDER BY \n",
    "    product_id;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "669c38d2",
   "metadata": {},
   "source": [
    "# Find Interview Candidates\n",
    " \n",
    "Table: Contests\n",
    "\n",
    "    +--------------+------+\n",
    "    | Column Name  | Type |\n",
    "    +--------------+------+\n",
    "    | contest_id   | int  |\n",
    "    | gold_medal   | int  |\n",
    "    | silver_medal | int  |\n",
    "    | bronze_medal | int  |\n",
    "    +--------------+------+\n",
    "    contest_id is the column with unique values for this table.\n",
    "    This table contains the LeetCode contest ID and the user IDs of the gold, silver, and bronze medalists.\n",
    "    It is guaranteed that any consecutive contests have consecutive IDs and that no ID is skipped.\n",
    "\n",
    "\n",
    "Table: Users\n",
    "\n",
    "    +-------------+---------+\n",
    "    | Column Name | Type    |\n",
    "    +-------------+---------+\n",
    "    | user_id     | int     |\n",
    "    | mail        | varchar |\n",
    "    | name        | varchar |\n",
    "    +-------------+---------+\n",
    "    user_id is the column with unique values for this table.\n",
    "    This table contains information about the users.\n",
    "\n",
    "\n",
    "    Write a solution to report the name and the mail of all interview candidates. A user is an interview candidate if at least one of these two conditions is true:\n",
    "\n",
    "    The user won any medal in three or more consecutive contests.\n",
    "    The user won the gold medal in three or more different contests (not necessarily consecutive).\n",
    "    Return the result table in any order.\n",
    "\n",
    "    The result format is in the following example.\n",
    "\n",
    "\n",
    "Example 1:\n",
    "\n",
    "Input: \n",
    "Contests table:\n",
    "\n",
    "    +------------+------------+--------------+--------------+\n",
    "    | contest_id | gold_medal | silver_medal | bronze_medal |\n",
    "    +------------+------------+--------------+--------------+\n",
    "    | 190        | 1          | 5            | 2            |\n",
    "    | 191        | 2          | 3            | 5            |\n",
    "    | 192        | 5          | 2            | 3            |\n",
    "    | 193        | 1          | 3            | 5            |\n",
    "    | 194        | 4          | 5            | 2            |\n",
    "    | 195        | 4          | 2            | 1            |\n",
    "    | 196        | 1          | 5            | 2            |\n",
    "    +------------+------------+--------------+--------------+\n",
    "Users table:\n",
    "\n",
    "    +---------+--------------------+-------+\n",
    "    | user_id | mail               | name  |\n",
    "    +---------+--------------------+-------+\n",
    "    | 1       | sarah@leetcode.com | Sarah |\n",
    "    | 2       | bob@leetcode.com   | Bob   |\n",
    "    | 3       | alice@leetcode.com | Alice |\n",
    "    | 4       | hercy@leetcode.com | Hercy |\n",
    "    | 5       | quarz@leetcode.com | Quarz |\n",
    "    +---------+--------------------+-------+\n",
    "Output: \n",
    "\n",
    "    +-------+--------------------+\n",
    "    | name  | mail               |\n",
    "    +-------+--------------------+\n",
    "    | Sarah | sarah@leetcode.com |\n",
    "    | Bob   | bob@leetcode.com   |\n",
    "    | Alice | alice@leetcode.com |\n",
    "    | Quarz | quarz@leetcode.com |\n",
    "    +-------+--------------------+\n",
    "    \n",
    "Explanation: \n",
    "\n",
    "    Sarah won 3 gold medals (190, 193, and 196), so we include her in the result table.\n",
    "    Bob won a medal in 3 consecutive contests (190, 191, and 192), so we include him in the result table.\n",
    "        - Note that he also won a medal in 3 other consecutive contests (194, 195, and 196).\n",
    "    Alice won a medal in 3 consecutive contests (191, 192, and 193), so we include her in the result table.\n",
    "    Quarz won a medal in 5 consecutive contests (190, 191, 192, 193, and 194), so we include them in the result table.\n",
    " \n",
    "Initial Ideas:\n",
    "\n",
    "    The goal of the query is to identify users who meet specific criteria to be considered interview candidates based on their performance in contests. Users are candidates if they:\n",
    "        Have won any medal (gold, silver, or bronze) in three or more consecutive contests.\n",
    "        Have won the gold medal in three or more different contests.\n",
    "        \n",
    "Steps to Solve the Problem:\n",
    "\n",
    "Data Collection (t0):\n",
    "\n",
    "    Gather data from the contests table, extracting gold_medal, silver_medal, and bronze_medal along with their corresponding contest_id.\n",
    "    Use UNION ALL to combine results into a single table (t0) where each row represents a user and the contest they participated in.\n",
    "Row Number Assignment (t1):\n",
    "\n",
    "    For each user, assign a row number ordered by contest_id using the ROW_NUMBER() function. This helps to differentiate consecutive contests for each user.\n",
    "    Create a new table (t1) containing the user_id, contest_id, and the assigned row number.\n",
    "Identify Candidates (t2):\n",
    "\n",
    "    In the first part, group by user_id and a calculated difference (contest_id - rn) to identify consecutive medal wins. If a user has three or more such occurrences, they are included.\n",
    "    In the second part, retrieve users who have won the gold medal in three or more distinct contests. Use COUNT(DISTINCT contest_id) to ensure the count is based on unique contests.\n",
    "Final Selection:\n",
    "\n",
    "    Perform a final selection by joining the results from t2 with the users table to get the names and email addresses of the candidates.\n",
    "    \n",
    "Time and Space Complexity:\n",
    "\n",
    "Time Complexity:\n",
    "\n",
    "    The query runs in linear time relative to the size of the input data, primarily driven by the table scans and aggregations. The most expensive operation is the grouping and counting, which is generally O(n).\n",
    "Space Complexity:\n",
    "\n",
    "    The space complexity is O(n) as well, due to the intermediate CTEs (t0, t1, and t2) storing potentially large datasets.\n",
    "    \n",
    "Follow-Up Questions and Answers:\n",
    "\n",
    "Q: What happens if there are users with NULL medals?\n",
    "\n",
    "    A: Users with NULL medals are filtered out in the WHERE ... IS NOT NULL clauses, ensuring they do not contribute to the candidate selection.\n",
    "Q: How can the query be modified to find candidates based on different criteria?\n",
    "\n",
    "    A: The criteria can be adjusted by changing the conditions in the HAVING clauses or modifying the aggregation logic. For instance, to find candidates with two consecutive wins, you would change the HAVING COUNT(*) >= 3 to HAVING COUNT(*) >= 2.\n",
    "Q: How do we ensure that a user is only counted once in the final results?\n",
    "\n",
    "    A: The final SELECT DISTINCT clause ensures that each candidate appears only once in the results based on their unique identifiers.\n",
    "Q: What are potential optimizations for this query?\n",
    "\n",
    "    A: If the contests table is large, consider creating indexes on the medal columns and the contest_id to speed up the querying process. Also, ensuring that users table has appropriate indexing on user_id can enhance join performance.\n",
    "Q: Can the query handle a very large dataset efficiently?\n",
    "\n",
    "    A: While the query is designed to be efficient, the actual performance depends on the database's indexing, the execution environment, and hardware specifications. Optimizations mentioned earlier can help improve performance for large datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bffbe95a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# posgresSQL\n",
    "WITH t0 AS (\n",
    "    SELECT gold_medal AS user_id, contest_id \n",
    "    FROM contests \n",
    "    WHERE gold_medal IS NOT NULL\n",
    "    \n",
    "    UNION ALL \n",
    "    \n",
    "    SELECT silver_medal AS user_id, contest_id \n",
    "    FROM contests \n",
    "    WHERE silver_medal IS NOT NULL\n",
    "    \n",
    "    UNION ALL \n",
    "    \n",
    "    SELECT bronze_medal AS user_id, contest_id \n",
    "    FROM contests \n",
    "    WHERE bronze_medal IS NOT NULL \n",
    "),\n",
    "t1 AS (\n",
    "    SELECT user_id, contest_id, \n",
    "           ROW_NUMBER() OVER (PARTITION BY user_id ORDER BY contest_id) AS rn \n",
    "    FROM t0 \n",
    "),\n",
    "t2 AS (\n",
    "    SELECT user_id \n",
    "    FROM t1 \n",
    "    GROUP BY user_id, contest_id - rn \n",
    "    HAVING COUNT(*) >= 3 -- consecutive medal winners\n",
    "    UNION ALL\n",
    "    SELECT gold_medal AS user_id \n",
    "    FROM contests \n",
    "    WHERE gold_medal IS NOT NULL\n",
    "    GROUP BY gold_medal \n",
    "    HAVING COUNT(DISTINCT contest_id) >= 3 -- gold medal winners\n",
    ")\n",
    "SELECT DISTINCT u.name, u.mail \n",
    "FROM t2 \n",
    "INNER JOIN users u ON t2.user_id = u.user_id;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a0fd32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your MySQL query statement below\n",
    "with t0 as (\n",
    "    select gold_medal as user, contest_id \n",
    "    from contests \n",
    "    union all \n",
    "    select silver_medal as user, contest_id \n",
    "    from contests \n",
    "    union all \n",
    "    select bronze_medal as user, contest_id \n",
    "    from contests \n",
    ")\n",
    ", t1 as (\n",
    "    select user, contest_id, row_number() over(partition by user order by contest_id) as rn \n",
    "    from t0 \n",
    ")\n",
    ", t2 as (\n",
    "    select user as user_id -- consecutive medal winners\n",
    "    from t1 \n",
    "    group by user, contest_id - rn \n",
    "    having count(*) >= 3 -- replace 3 with any number to solve the N problem\n",
    "    union all\n",
    "    select gold_medal as user_id  -- gold medal winners\n",
    "    from contests \n",
    "    group by gold_medal \n",
    "    having count(*) >= 3\n",
    ")\n",
    "select distinct u.name, u.mail \n",
    "from t2 \n",
    "inner join users u\n",
    "on t2.user_id = u.user_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81965a1b",
   "metadata": {},
   "source": [
    "# Exchange Seats\n",
    " \n",
    "Table: Seat\n",
    "\n",
    "    +-------------+---------+\n",
    "    | Column Name | Type    |\n",
    "    +-------------+---------+\n",
    "    | id          | int     |\n",
    "    | student     | varchar |\n",
    "    +-------------+---------+\n",
    "    id is the primary key (unique value) column for this table.\n",
    "    Each row of this table indicates the name and the ID of a student.\n",
    "    The ID sequence always starts from 1 and increments continuously.\n",
    "\n",
    "\n",
    "    Write a solution to swap the seat id of every two consecutive students. If the number of students is odd, the id of the last student is not swapped.\n",
    "\n",
    "    Return the result table ordered by id in ascending order.\n",
    "\n",
    "    The result format is in the following example.\n",
    "\n",
    " \n",
    "\n",
    "Example 1:\n",
    "\n",
    "Input: \n",
    "Seat table:\n",
    "\n",
    "    +----+---------+\n",
    "    | id | student |\n",
    "    +----+---------+\n",
    "    | 1  | Abbot   |\n",
    "    | 2  | Doris   |\n",
    "    | 3  | Emerson |\n",
    "    | 4  | Green   |\n",
    "    | 5  | Jeames  |\n",
    "    +----+---------+\n",
    "Output: \n",
    "\n",
    "    +----+---------+\n",
    "    | id | student |\n",
    "    +----+---------+\n",
    "    | 1  | Doris   |\n",
    "    | 2  | Abbot   |\n",
    "    | 3  | Green   |\n",
    "    | 4  | Emerson |\n",
    "    | 5  | Jeames  |\n",
    "    +----+---------+\n",
    "Explanation: \n",
    "\n",
    "    Note that if the number of students is odd, there is no need to change the last one's seat.\n",
    "    \n",
    "Problem: Exchange Seats\n",
    "\n",
    "    You are given a table named Seat that represents the seating arrangement in a classroom. Each row has two columns: id (the student's ID) and student (the name of the student).\n",
    "\n",
    "    Your task is to write a SQL query to exchange the seats of students who are sitting in even-numbered rows with those in odd-numbered rows. The new seating assignment should be such that a student in an odd-numbered row exchanges seats with the student directly below them in the even-numbered row. If the number of students is odd, the last student remains in their original seat.\n",
    "\n",
    "Initial Ideas\n",
    "\n",
    "    Identify Pairs for Exchange: Select pairs of students where one is in an odd-numbered seat and the other is in the next even-numbered seat.\n",
    "    Update Logic: Swap the students' names for the identified pairs while keeping the last student unchanged if the total count is odd.\n",
    "    Query Construction: The SQL query should manage the selection and updating of these pairs efficiently.\n",
    "\n",
    "Steps\n",
    "\n",
    "    Select Student Rows: Use a query that selects students in pairs, one in an odd row and the other in the subsequent even row.\n",
    "    Construct New Assignments: Use conditional logic to generate the new seating assignments based on their original positions.\n",
    "    Ensure Last Student is Unchanged: If there is an odd number of students, make sure the last student’s seat remains unchanged.\n",
    "    \n",
    "    \n",
    "Edge Cases\n",
    "\n",
    "    Single Student: If only one student is present, no exchanges will occur.\n",
    "    Even Number of Students: All students will successfully exchange seats.\n",
    "    Odd Number of Students: The last student's seat will remain unchanged.\n",
    "\n",
    "Complexity Analysis\n",
    "\n",
    "    Time Complexity:  O(N), where N is the number of rows in the Seat table. Each row is processed in a single pass.\n",
    "    Space Complexity: O(1) since we do not use additional space that scales with input size.\n",
    "\n",
    "Follow-up Questions and Answers\n",
    "\n",
    "What if we want to maintain the original order of students?\n",
    "\n",
    "    The output should still reflect the new seating arrangement, but the original IDs can be kept intact. The query can be adjusted to simply select the id alongside the newly assigned student names.\n",
    "How can we handle names that might be the same?\n",
    "\n",
    "    If names are identical, the logic for seat exchange remains unchanged, but the output will show the same names for different IDs. The query handles the logic based on positions, not names.\n",
    "What if we want to allow for more complex seating arrangements?\n",
    "\n",
    "    If the seating arrangement becomes more complex, consider adding more conditions or possibly creating a more sophisticated procedure to handle dynamic changes in seat allocation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789b746b",
   "metadata": {},
   "outputs": [],
   "source": [
    "SELECT \n",
    "    ROW_NUMBER() OVER () AS id,\n",
    "    CASE \n",
    "        WHEN ROW_NUMBER() OVER () % 2 = 1 THEN \n",
    "            case when LEAD(student) OVER (ORDER BY id) is null then student else LEAD(student) OVER (ORDER BY id) end -- Get the next student's name if the current is odd\n",
    "        ELSE \n",
    "            LAG(student) OVER (ORDER BY id)   -- Get the previous student's name if the current is even\n",
    "    END AS student\n",
    "FROM Seat\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa99aa53",
   "metadata": {},
   "source": [
    "# Compute the Rank as a Percentage\n",
    " \n",
    "Table: Students\n",
    "\n",
    "    +---------------+------+\n",
    "    | Column Name   | Type |\n",
    "    +---------------+------+\n",
    "    | student_id    | int  |\n",
    "    | department_id | int  |\n",
    "    | mark          | int  |\n",
    "    +---------------+------+\n",
    "    student_id contains unique values.\n",
    "    Each row of this table indicates a student's ID, the ID of the department in which the student enrolled, and their mark in the exam.\n",
    "\n",
    "\n",
    "    Write a solution to report the rank of each student in their department as a percentage, where the rank as a percentage is computed using the following formula: (student_rank_in_the_department - 1) * 100 / (the_number_of_students_in_the_department - 1). The percentage should be rounded to 2 decimal places. student_rank_in_the_department is determined by descending mark, such that the student with the highest mark is rank 1. If two students get the same mark, they also get the same rank.\n",
    "\n",
    "    Return the result table in any order.\n",
    "\n",
    "    The result format is in the following example.\n",
    "\n",
    " \n",
    "\n",
    "Example 1:\n",
    "\n",
    "Input: \n",
    "Students table:\n",
    "\n",
    "    +------------+---------------+------+\n",
    "    | student_id | department_id | mark |\n",
    "    +------------+---------------+------+\n",
    "    | 2          | 2             | 650  |\n",
    "    | 8          | 2             | 650  |\n",
    "    | 7          | 1             | 920  |\n",
    "    | 1          | 1             | 610  |\n",
    "    | 3          | 1             | 530  |\n",
    "    +------------+---------------+------+\n",
    "Output: \n",
    "\n",
    "    +------------+---------------+------------+\n",
    "    | student_id | department_id | percentage |\n",
    "    +------------+---------------+------------+\n",
    "    | 7          | 1             | 0.0        |\n",
    "    | 1          | 1             | 50.0       |\n",
    "    | 3          | 1             | 100.0      |\n",
    "    | 2          | 2             | 0.0        |\n",
    "    | 8          | 2             | 0.0        |\n",
    "    +------------+---------------+------------+\n",
    "Explanation: \n",
    "\n",
    "    For Department 1:\n",
    "     - Student 7: percentage = (1 - 1) * 100 / (3 - 1) = 0.0\n",
    "     - Student 1: percentage = (2 - 1) * 100 / (3 - 1) = 50.0\n",
    "     - Student 3: percentage = (3 - 1) * 100 / (3 - 1) = 100.0\n",
    "    For Department 2:\n",
    "     - Student 2: percentage = (1 - 1) * 100 / (2 - 1) = 0.0\n",
    "     - Student 8: percentage = (1 - 1) * 100 / (2 - 1) = 0.0\n",
    "      \n",
    "\n",
    "Problem: Compute the Rank as a Percentage\n",
    "\n",
    "    You are given a table named Students with three columns: student_id, department_id, and mark. The task is to compute the rank of each student in their department as a percentage. The rank percentage is calculated using the formula:\n",
    "\n",
    "\n",
    "    percentage= (student_rank_in_the_department−1)×100 / (number_of_students_in_the_department−1) \n",
    "\n",
    "    Where: student_rank_in_the_department is determined by descending marks. The student with the highest mark has rank 1. If two students have the same mark, they share the same rank.\n",
    "    \n",
    "Explanation of SQL Query\n",
    "\n",
    "RANK() Window Function:\n",
    "\n",
    "    RANK() OVER (PARTITION BY department_id ORDER BY mark DESC) calculates the rank of each student within their department based on their marks in descending order. Students with the same mark receive the same rank.\n",
    "COUNT() Window Function:\n",
    "\n",
    "    COUNT(*) OVER (PARTITION BY department_id) counts the total number of students in each department. This value is used to calculate the percentage.\n",
    "Percentage Calculation:\n",
    "\n",
    "    The percentage is calculated using the formula provided, rounding the result to two decimal places using the ROUND() function.\n",
    "    \n",
    "Edge Cases\n",
    "\n",
    "    All Students with the Same Marks: If all students in a department have the same mark, they will all have a rank of 1, resulting in 0.0% for everyone in that department.\n",
    "    Single Student in a Department: If there is only one student in a department, they will also have a percentage of 0.0%.\n",
    "    No Records: If the table is empty, the output should also be empty.\n",
    "    \n",
    "Complexity Analysis\n",
    "\n",
    "    Time Complexity: O(NlogN) due to the sorting involved in the RANK() function, where N is the number of records in the Students table.\n",
    "    Space Complexity: O(N) for storing intermediate rank and count data.\n",
    "\n",
    "Follow-up Questions and Answers\n",
    "\n",
    "How would you modify the query if the department_id was not provided?\n",
    "\n",
    "    You would need to remove the PARTITION BY department_id clauses and calculate the rank across the entire table instead.\n",
    "Can you handle ties in marks differently?\n",
    "\n",
    "    Yes, you can use DENSE_RANK() instead of RANK() if you want to assign consecutive ranks without gaps.\n",
    "What if you need to compute additional statistics?\n",
    "\n",
    "    You can add more columns in the SELECT statement by using additional window functions as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2adc009f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your MySQL query statement below\n",
    "SELECT student_id, department_id,\n",
    "       coalesce (\n",
    "        ROUND(\n",
    "             (RANK() OVER (PARTITION BY department_id ORDER BY mark DESC) - 1) * 100.0 / \n",
    "             ifnull((COUNT(*) OVER (PARTITION BY department_id) - 1), 0)\n",
    "             , 2)\n",
    "             , 0) AS percentage\n",
    "FROM Students\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9951430a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your PostgreSQL query statement below \n",
    "SELECT student_id, department_id,\n",
    "       coalesce (\n",
    "        ROUND(\n",
    "             (RANK() OVER (PARTITION BY department_id ORDER BY mark DESC) - 1) * 100.0 / \n",
    "             NULLIF((COUNT(*) OVER (PARTITION BY department_id) - 1), 0)\n",
    "             , 2)\n",
    "             , 0) AS percentage\n",
    "FROM Students\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d791f5",
   "metadata": {},
   "source": [
    "# Second Degree Follower\n",
    " \n",
    "Table: Follow\n",
    "\n",
    "    +-------------+---------+\n",
    "    | Column Name | Type    |\n",
    "    +-------------+---------+\n",
    "    | followee    | varchar |\n",
    "    | follower    | varchar |\n",
    "    +-------------+---------+\n",
    "    (followee, follower) is the primary key (combination of columns with unique values) for this table.\n",
    "    Each row of this table indicates that the user follower follows the user followee on a social network.\n",
    "    There will not be a user following themself.\n",
    "\n",
    "\n",
    "    A second-degree follower is a user who:\n",
    "\n",
    "    follows at least one user, and\n",
    "    is followed by at least one user.\n",
    "    Write a solution to report the second-degree users and the number of their followers.\n",
    "\n",
    "    Return the result table ordered by follower in alphabetical order.\n",
    "\n",
    "    The result format is in the following example.\n",
    "\n",
    " \n",
    "\n",
    "Example 1:\n",
    "\n",
    "Input: \n",
    "Follow table:\n",
    "\n",
    "    +----------+----------+\n",
    "    | followee | follower |\n",
    "    +----------+----------+\n",
    "    | Alice    | Bob      |\n",
    "    | Bob      | Cena     |\n",
    "    | Bob      | Donald   |\n",
    "    | Donald   | Edward   |\n",
    "    +----------+----------+\n",
    "Output: \n",
    "\n",
    "    +----------+-----+\n",
    "    | follower | num |\n",
    "    +----------+-----+\n",
    "    | Bob      | 2   |\n",
    "    | Donald   | 1   |\n",
    "    +----------+-----+\n",
    "Explanation: \n",
    "\n",
    "    User Bob has 2 followers. Bob is a second-degree follower because he follows Alice, so we include him in the result table.\n",
    "    User Donald has 1 follower. Donald is a second-degree follower because he follows Bob, so we include him in the result table.\n",
    "    User Alice has 1 follower. Alice is not a second-degree follower because she does not follow anyone, so we don not include her in the result table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd34440",
   "metadata": {},
   "outputs": [],
   "source": [
    "SELECT followee AS follower, COUNT(follower) AS num\n",
    "FROM Follow\n",
    "WHERE followee IN (\n",
    "    SELECT follower\n",
    "    FROM Follow\n",
    "    GROUP BY follower\n",
    "    HAVING COUNT(followee) >= 1\n",
    ")\n",
    "GROUP BY followee\n",
    "HAVING COUNT(follower) >= 1\n",
    "ORDER BY follower;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18df2f02",
   "metadata": {},
   "source": [
    "Query Breakdown\n",
    "Inner Query:\n",
    "  \n",
    "    SELECT follower\n",
    "    FROM Follow\n",
    "    GROUP BY follower\n",
    "    HAVING COUNT(followee) >= 1\n",
    "\n",
    "    This subquery identifies all users (follower) who follow at least one other user (followee).\n",
    "    It groups the results by follower and uses the HAVING clause to ensure that only those followers with one or more outgoing connections are selected.\n",
    "    \n",
    "Outer Query:\n",
    " \n",
    "    SELECT followee AS follower, COUNT(follower) AS num\n",
    "    FROM Follow\n",
    "    WHERE followee IN (...)\n",
    "    \n",
    "    The outer query selects followee (renamed as follower for output clarity) and counts how many followers each followee has.\n",
    "    It includes a WHERE clause that filters the results to only include followee users who are in the list produced by the inner query. This ensures that we only consider users who themselves follow someone.\n",
    "    \n",
    "Grouping and Counting:\n",
    "\n",
    "    GROUP BY followee\n",
    "    HAVING COUNT(follower) >= 1\n",
    "\n",
    "    The outer query groups the results by followee and checks with the HAVING clause that each followee has at least one follower, confirming they meet the criteria of being a second-degree follower.\n",
    "\n",
    "Ordering:\n",
    " \n",
    "    ORDER BY follower;\n",
    "    \n",
    "    Finally, the results are sorted alphabetically by follower to present the output in an organized manner.\n",
    "    \n",
    "    \n",
    "Complexity Analysis\n",
    "\n",
    "    Time Complexity: The query primarily involves two scans of the Follow table, leading to a time complexity of O(n), where n is the number of entries in the Follow table.\n",
    "    Space Complexity: The space complexity is O(k), where k is the number of unique followers since we may need to store them temporarily in the result set.\n",
    "\n",
    "Follow-Up Questions\n",
    "\n",
    "What if the data has duplicate entries?\n",
    "\n",
    "    The primary key constraint (followee, follower) ensures there are no duplicates.\n",
    "How would you modify this query to include only followers with more than a specified number of followers?\n",
    "\n",
    "    You could add an additional HAVING clause in the outer query to filter results based on the count of followers.\n",
    "Could this logic be adapted for a different level of follower, such as third-degree followers?\n",
    "\n",
    "    Yes, by modifying the inner query to look for followers who have followees that themselves are followed by others.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87242a1b",
   "metadata": {},
   "source": [
    "# Customer Purchasing Behavior Analysis\n",
    " \n",
    "Table: Transactions\n",
    "\n",
    "    +------------------+---------+\n",
    "    | Column Name      | Type    |\n",
    "    +------------------+---------+\n",
    "    | transaction_id   | int     |\n",
    "    | customer_id      | int     |\n",
    "    | product_id       | int     |\n",
    "    | transaction_date | date    |\n",
    "    | amount           | decimal |\n",
    "    +------------------+---------+\n",
    "    transaction_id is the unique identifier for this table.\n",
    "    Each row of this table contains information about a transaction, including the customer ID, product ID, date, and amount spent.\n",
    "Table: Products\n",
    "\n",
    "    +-------------+---------+\n",
    "    | Column Name | Type    |\n",
    "    +-------------+---------+\n",
    "    | product_id  | int     |\n",
    "    | category    | varchar |\n",
    "    | price       | decimal |\n",
    "    +-------------+---------+\n",
    "    product_id is the unique identifier for this table.\n",
    "    Each row of this table contains information about a product, including its category and price.\n",
    "    Write a solution to analyze customer purchasing behavior. For each customer, calculate:\n",
    "\n",
    "        The total amount spent.\n",
    "        The number of transactions.\n",
    "        The number of unique product categories purchased.\n",
    "        The average amount spent. \n",
    "        The most frequently purchased product category (if there is a tie, choose the one with the most recent transaction).\n",
    "        A loyalty score defined as: (Number of transactions * 10) + (Total amount spent / 100).\n",
    "    Round total_amount, avg_transaction_amount, and loyalty_score to 2 decimal places.\n",
    "\n",
    "    Return the result table ordered by loyalty_score in descending order, then by customer_id in ascending order.\n",
    "\n",
    "    The query result format is in the following example.\n",
    "\n",
    " \n",
    "\n",
    "Example:\n",
    "\n",
    "Input:\n",
    "\n",
    "Transactions table:\n",
    "\n",
    "    +----------------+-------------+------------+------------------+--------+\n",
    "    | transaction_id | customer_id | product_id | transaction_date | amount |\n",
    "    +----------------+-------------+------------+------------------+--------+\n",
    "    | 1              | 101         | 1          | 2023-01-01       | 100.00 |\n",
    "    | 2              | 101         | 2          | 2023-01-15       | 150.00 |\n",
    "    | 3              | 102         | 1          | 2023-01-01       | 100.00 |\n",
    "    | 4              | 102         | 3          | 2023-01-22       | 200.00 |\n",
    "    | 5              | 101         | 3          | 2023-02-10       | 200.00 |\n",
    "    +----------------+-------------+------------+------------------+--------+\n",
    "Products table:\n",
    "\n",
    "    +------------+----------+--------+\n",
    "    | product_id | category | price  |\n",
    "    +------------+----------+--------+\n",
    "    | 1          | A        | 100.00 |\n",
    "    | 2          | B        | 150.00 |\n",
    "    | 3          | C        | 200.00 |\n",
    "    +------------+----------+--------+\n",
    "Output:\n",
    "\n",
    "    +-------------+--------------+-------------------+-------------------+------------------------+--------------+---------------+\n",
    "    | customer_id | total_amount | transaction_count | unique_categories | avg_transaction_amount | top_category | loyalty_score |\n",
    "    +-------------+--------------+-------------------+-------------------+------------------------+--------------+---------------+\n",
    "    | 101         | 450.00       | 3                 | 3                 | 150.00                 | C            | 34.50         |\n",
    "    | 102         | 300.00       | 2                 | 2                 | 150.00                 | C            | 23.00         |\n",
    "    +-------------+--------------+-------------------+-------------------+------------------------+--------------+---------------+\n",
    "Explanation:\n",
    "\n",
    "For customer 101:\n",
    "\n",
    "    Total amount spent: 100.00 + 150.00 + 200.00 = 450.00\n",
    "    Number of transactions: 3\n",
    "    Unique categories: A, B, C (3 categories)\n",
    "    Average transaction amount: 450.00 / 3 = 150.00\n",
    "    Top category: C (Customer 101 made 1 purchase each in categories A, B, and C. Since the count is the same for all categories, we choose the most recent transaction, which is category C on 2023-02-10)\n",
    "    Loyalty score: (3 * 10) + (450.00 / 100) = 34.50\n",
    "    \n",
    "For customer 102:\n",
    "\n",
    "    Total amount spent: 100.00 + 200.00 = 300.00\n",
    "    Number of transactions: 2\n",
    "    Unique categories: A, C (2 categories)\n",
    "    Average transaction amount: 300.00 / 2 = 150.00\n",
    "    Top category: C (Customer 102 made 1 purchase each in categories A and C. Since the count is the same for both categories, we choose the most recent transaction, which is category C on 2023-01-22)\n",
    "    Loyalty score: (2 * 10) + (300.00 / 100) = 23.00\n",
    "Note: The output is ordered by loyalty_score in descending order, then by customer_id in ascending order.\n",
    "\n",
    "Initial Ideas\n",
    "\n",
    "    To analyze customer purchasing behavior, we need to gather and compute several metrics from the Transactions and Products tables, such as total amount spent, transaction count, unique categories purchased, average transaction amount, the most frequently purchased product category, and a loyalty score.\n",
    "\n",
    "Steps\n",
    "\n",
    "    Join the Tables: Combine Transactions and Products tables to access both transaction details and product categories.\n",
    "    Aggregate Data: For each customer, calculate:\n",
    "        Total amount spent.\n",
    "        Number of transactions.\n",
    "        Number of unique product categories.\n",
    "        Average transaction amount.\n",
    "        Loyalty score using the given formula.\n",
    "    Determine Top Category: Identify the most frequently purchased category for each customer, resolving ties by the most recent transaction date.\n",
    "    Final Selection: Return the desired columns ordered by loyalty score and customer ID.\n",
    "    \n",
    "Edge Cases\n",
    "\n",
    "    No Transactions: Ensure customers without any transactions are not included in the result.\n",
    "    Single Transaction: Handle customers who only have one transaction properly.\n",
    "    Identical Amounts: Ensure ties in transaction amounts are handled correctly, particularly for average calculations.\n",
    "\n",
    "Complexity\n",
    "\n",
    "    Time Complexity: O(n log n) due to sorting operations, where n is the number of transactions. The joins and aggregations are linear with respect to the number of transactions.\n",
    "    Space Complexity: O(n) for storing joined results and aggregated values.\n",
    "\n",
    "Follow-Up Questions\n",
    "\n",
    "How would you handle customers with no transactions?\n",
    "\n",
    "    Customers with no transactions will not appear in the final output since we're only aggregating data for those who have made purchases.\n",
    "What if product categories were changed after transactions?\n",
    "\n",
    "    We would need to ensure that the transaction data reflects the current product categories at the time of analysis, potentially necessitating historical records.\n",
    "How would you scale this solution for a very large dataset?\n",
    "\n",
    "    We could utilize indexing on customer_id and product_id to improve join performance, as well as consider partitioning the data by date or customer if needed.\n",
    "How would you modify the query to include customer demographics?\n",
    "\n",
    "    We would need to join the Transactions table with an additional Customers table that contains demographic information based on customer_id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71df01f6",
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "WITH joined AS (\n",
    "    SELECT \n",
    "        t.transaction_id,\n",
    "        t.customer_id,\n",
    "        p.product_id,\n",
    "        t.transaction_date,\n",
    "        t.amount,\n",
    "        p.category,\n",
    "        p.price\n",
    "    FROM \n",
    "        transactions t\n",
    "    INNER JOIN \n",
    "        products p ON t.product_id = p.product_id\n",
    "),\n",
    "\n",
    "amount_count AS (\n",
    "    SELECT \n",
    "        customer_id,\n",
    "        ROUND(SUM(amount), 2) AS total_amount,\n",
    "        COUNT(transaction_id) AS transaction_count,\n",
    "        COUNT(DISTINCT category) AS unique_categories,\n",
    "        ROUND(SUM(amount)/COUNT(transaction_id), 2) AS avg_transaction_amount,\n",
    "        ROUND((COUNT(transaction_id) * 10) + (SUM(amount) / 100), 2) AS loyalty_score\n",
    "    FROM \n",
    "        joined\n",
    "    GROUP BY \n",
    "        customer_id\n",
    "),\n",
    "\n",
    "top_category AS (\n",
    "    SELECT \n",
    "        customer_id,\n",
    "        category,\n",
    "        DENSE_RANK() OVER (PARTITION BY customer_id ORDER BY COUNT(*) DESC, MAX(transaction_date) DESC) AS rn\n",
    "    FROM \n",
    "        joined\n",
    "    GROUP BY \n",
    "        customer_id, category\n",
    ")\n",
    "\n",
    "SELECT \n",
    "    ac.customer_id, \n",
    "    ac.total_amount, \n",
    "    ac.transaction_count, \n",
    "    ac.unique_categories, \n",
    "    ac.avg_transaction_amount, \n",
    "    tc.category AS top_category, \n",
    "    ac.loyalty_score\n",
    "FROM \n",
    "    amount_count ac\n",
    "LEFT JOIN \n",
    "    top_category tc ON ac.customer_id = tc.customer_id\n",
    "WHERE \n",
    "    tc.rn = 1\n",
    "ORDER BY \n",
    "    ac.loyalty_score DESC, ac.customer_id ASC;"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
